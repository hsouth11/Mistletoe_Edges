---
title: "modelling"
author: "Hanno Southam"
date: "`r Sys.Date()`"
output: html_document
editor_options: 
  chunk_output_type: console
---
##############
READ ME
This script fits ordinal models that predict DMR from tree level variables. 
Originally, the intent was to build a model that tested the significance and 
predictive ability of of tree (dbh, canopy class, seed load, distance from the 
edge) and site (e.g. stem density, climate vars) variables and combinations. 
Quickly, we ran into model instabilities and had to go with a simpler approach. 
In the simpler version:
(1) The modelling objective is only inferential (not predictive)
(2) DMR is collapsed to a subset of the 6 levels (to treat problems of data 
scarcity);
(3) only tree level predictors are considered;
(4) and site level predictors are all wrapped up into a random site effect. 

The starting object for this is the 'trees_sl.csv' object that came out of the 
seed load script (05_seed_load.Rmd).

References
Fagerland, M. W., & Hosmer, D. W. (2013). A goodness-of-fit test for the proportional odds regression model. Statistics in Medicine, 32(13), 2235–2249. https://doi.org/10.1002/sim.5645

Fagerland, M. W., & Hosmer, D. W. (2016). Tests for goodness of fit in ordinal logistic regression models. Journal of Statistical Computation and Simulation, 86(17), 3398–3418. https://doi.org/10.1080/00949655.2016.1156682
##############

#Prep
Load packages
```{r}
#Unload loaded packages in R session
library(pacman)
p_loaded()
p_unload(p_loaded(), character.only = T)

#Load packages used in this script. Unloading then loading avoids potential
#package conflicts
library(here)
library(ggbiplot)
library(GGally)
library(ordinal)
library(ggeffects)
library(emmeans)
library(generalhoslem)
library(vcd)
library(yardstick)
library(tidyverse)
library(gt)
library(ggpubr)
library(cowplot)
library(RColorBrewer)
```

Set the session seed so results are reproducible
```{r}
set.seed(11)
```

Read in the data. 
```{r}
rm(list = ls(all = TRUE))

#Tree data
trees <- read_csv(here("./data/workflow/trees_sl.csv"))

#Residual tree data
resid <- read_csv(here("./data/cleaned/resid_tree_data.csv"))
```

Filter the data. The trees that are the target of modelling
are live Hw regen trees within 50m of the edge. This group includes a few 
putative residual trees (infected regen trees that had qualitative signs of
being a legacy of the pre-harvest stand). Remove these because the analysis is
asking what infection patterns result in regen trees that establish after 
harvest occurs. 
```{r}
#Define a subset of trees that make up the modelling dataset
#Filter to the live, regen, Hw trees
modelling <- trees %>% 
  filter(tree_type == "regen" &
           status %in% c("LS", "LL", "LF") &
           spp == "Hw")
nrow(modelling) #1102 observations

#Filter to trees within 50m of the edge. This removes only a few trees at the
#cr_3 site
modelling <- modelling %>% 
  filter(dist_y_h <= 50)
nrow(modelling) #1098 observations

#Remove residual trees
#How many residual trees are there? 
nrow(resid) #10

#How many are on a regen transect?
resid %>% filter(str_starts(regen_tree_id, "r")) %>% nrow() #5

#Lets remove these from the modelling dataset
resid_rm <- resid %>% filter(str_starts(regen_tree_id, "r")) %>% 
  pull(regen_tree_id)

#Add column to modelling dataset that identifies which trees are residuals
modelling <- modelling %>% 
  mutate(resid = if_else(tree_id %in% resid_rm, "Y", "N"))
modelling %>% select(resid) %>% table()

#Filter out residual trees
modelling <- modelling %>% filter(resid == "N")
nrow(modelling) #1093 observations
```

#Variable definition
The response variable is DMR (dmr_f). Infection in higher severity classes was 
rare in the data. This created a data scarcity problem that led to model 
convergence issues. Multiple collapsed versions of DMR are created in this 
chunk to deal with this issue. 

Four tree level predictors were considered:
(1) Distance from the edge (dist_y_h)
- Logic: Mature trees were the infection source. Infection severity should 
decline with increasing distance from the infection source.
- Some exponentiated versions of this variable were also trialed. 

(2) Seed load (sl_i_tot_rm)
- Logic: Regen trees exposed to more HDM seed from infected mature source trees
should have higher levels of infection.
- This variable is colinear with distance from the edge, but we predicted it
would explain additional variation in the model. 
- The version of seed load that only considers mature source trees and includes
interception was selected. Other versions weren't tested because of time
constraints (but are in the dataframe and could be). 

(3) DBH (dbh)
- Logic: Larger trees are bigger targets for HDM seed, occupy canopy positions
that make them more exposed to HDM seed and may be older than smaller trees 
(and thus have been exposed to HDM for longer). 

(4) Crown class (crown_class and crown_class_2)
- Logic: same as DBH
- DBH and crown class are colinear. They are not equivalent in a silvics
context, but for the purpose of this analysis, they contain very similar
information.

Inspect and define these response and predictor variables. 
```{r}
#Inspect variables
str(modelling)

#Make factor variables factors
modelling <- modelling %>% 
  mutate(across(c(site_id, 
                  crown_class,
                  crown_class_2,
                  dmr_f), ~as.factor(.)))

#Response variable is dmr, an ordinal variable
#Check its levels
levels(modelling$dmr_f)
#Only 0, 1, 2, 3, 4, 5 and IBLC are represented

#Reorder the levels 
modelling <- modelling %>% 
  mutate(dmr_f = as.character(dmr_f)) %>% 
  mutate(dmr_f = factor(dmr_f, levels = c("0", "IBLC", "1", "2", "3",
                                          "4", "5")))

#See how many trees there are in each dmr class
modelling %>% select(dmr_f) %>% 
  table()

#Initial models aren't converging. Collapsing dmr helped resolve
#the issue. Define three new response variables to try, one with 6 levels, one
#with 4 and one with 3 that will be used in modelling. 
modelling <- modelling %>% 
  mutate(dmr_f_2 = case_when(dmr_f %in% c("4", "5") ~ "4-5",
                             .default = dmr_f),
         dmr_f_3 = case_when(dmr_f %in% c("3", "4", "5") ~ "3-5",
                             dmr_f %in% c("1", "2") ~ "1-2",
                             .default = dmr_f),
          dmr_f_4 = case_when(dmr_f %in% c("3", "4", "5") ~ "3-5",
                             dmr_f %in% c("IBLC", "1", "2") ~ "IBLC-2",
                             .default = dmr_f)) %>% 
  mutate(dmr_f_2 = factor(dmr_f_2, levels = c("0", "IBLC", "1", "2", 
                                              "3", "4-5")),
         dmr_f_3 = factor(dmr_f_3, levels = c("0", "IBLC", "1-2", 
                                              "3-5")),
         dmr_f_4 = factor(dmr_f_4, levels = c("0", "IBLC-2", 
                                              "3-5")))

#Check these:
levels(modelling$dmr_f_2)
modelling %>% select(dmr_f_2) %>% 
  table()

levels(modelling$dmr_f_3)
modelling %>% select(dmr_f_3) %>% 
  table()

levels(modelling$dmr_f_4)
modelling %>% select(dmr_f_4) %>% 
  table()

#Redefine crown class variables so the are in logical order:
modelling <- modelling %>% 
  mutate(crown_class = 
           factor(crown_class, levels = c("S", "I", "C", "D")),
         crown_class_2 = 
           factor(crown_class_2, levels = c("S", "I", "C")))
levels(modelling$crown_class)
levels(modelling$crown_class_2)

#See how many trees there are in each crown class
modelling %>% select(crown_class) %>% 
  table()
modelling %>% select(crown_class_2) %>% 
  table()

#Distance from the edge likely has an exponential decay shape. Try adding 
#distance^2 and distance^4 as predictors
modelling <- modelling %>% 
  mutate(dist_y_h.2 = dist_y_h^2,
         dist_y_h.4 = dist_y_h^4)
```

##Define some colours to plot with
```{r}
#DMR 7 levels
levels(modelling$dmr_f)
col_dmr_7 <- c("#A6CEE3", brewer.pal(n = 6, name = "Oranges"))

#DMR 3 levels
levels(modelling$dmr_f_4)
col_dmr3 <- c("#A6CEE3", "#FDBE85", "#A63603")
```

#Exploratory data analysis
##Get a sense of the dataset
Things of note:
- Higher DMR (>=3) was rarely observed
- Seed load has an extremely right skewed distribution. I thought this may have
contributed to some of the model convergence issues that came up initially. 
Other remedies stabilized the models, something to keep in mind. 
```{r}
#How many trees? 
nrow(modelling)

#How many simulated, how many measured? 
modelling %>% select(sim_tree) %>% 
  table()

#How are they distributed across DMR?
#Show this across all four of the dmr variables we generated
x <- modelling %>%
  pivot_longer(cols = starts_with("dmr_f"), values_to = "dmr_val", 
               names_to = "dmr_ver")
ggplot(x, aes(x = dmr_val)) + geom_bar(stat = "count") +
  geom_text(stat =  "count", aes(label = after_stat(count), vjust = 1, 
                                 colour = "white")) + 
  facet_wrap(~dmr_ver, scales = "free_x")

#How are they distributed across distance from the edge
ggplot(modelling, aes(x = dist_y_h)) + geom_histogram()

#Across seed load? 
ggplot(modelling, aes(x = sl_i_tot_rm)) + geom_histogram()

#Across dbh?
ggplot(modelling, aes(x = dbh)) + geom_histogram()

#Across canopy class? 
ggplot(modelling, aes(x = crown_class)) + geom_bar(stat = "count")
```

##Summarize predictor variables across dmr levels
```{r}
#Table 1: mean seed load, distance from the edge, dbh and percent of each 
#crown class by dmr level

#Create table, then transpose it so DMR levels are the columns
tb1 <- modelling %>%
  select(dmr_f, sl_i_tot_rm, dist_y_h, dbh, crown_class) %>% 
  group_by(dmr_f) %>% 
  summarise("Seed load" = mean(sl_i_tot_rm),
            "Distance from edge (m)" = mean(dist_y_h),
            "DBH (cm)" = mean(dbh),
            "D" = sum(crown_class == "D"),
            "C" = sum(crown_class == "C"),
            "I" = sum(crown_class == "I"),
            "S" = sum(crown_class == "S")) %>% 
  mutate("% of dominant" = (D/sum(D))*100, 
         "% of codominant" = (C/sum(C))*100,
         "% of intermediate" = (I/sum(I))*100,
         "% of suppressed" = (S/sum(S))*100) %>% 
  select(-c(D, C, I, S)) %>% 
  mutate(across(where(is.numeric), ~ round(.x, 1))) %>% 
  t() %>% 
  as.data.frame()

#Make dmr levels the column names, then remove that row
colnames(tb1) <- tb1[1,]
tb1 <- tb1[-1,]

# #Make the rownames their own column
tb1 <- tb1 %>%
   rownames_to_column(var = "Predictor")

#Convert to a gt object, then colour the cells in a rowwise direction on 
#independent scales. Will show if the explanatory variable tends to be larger 
#or smaller, depending on the dmr.
sum_tb1 <- tb1 %>% 
  gt() %>% 
  data_color(columns = -Predictor,
    direction = "row",
    palette = "Reds")

#Show the table:
sum_tb1
```

###Construct a table for writing
Going to recreate the table above but with a bit more detail. Goal is to 
summarize the modelling dataset that went into thesis/publication.

Rows:
- all trees
- DMR

Columns: 
- total sample size
- sample size of measured trees
- sample size of simulated trees
- distance from the edge
- seed load
- dbh

Start by summarizing these variables across all trees
```{r}
tb2 <- modelling %>% 
  summarise(n_tot = n(),
            n_meas = sum(sim_tree == "N"),
            n_sim = sum(sim_tree == "Y"),
            dist_mean = mean(dist_y_h),
            dist_min = min(dist_y_h),
            dist_max = max(dist_y_h),
            sl_mean = mean(sl_i_tot_rm),
            sl_min = min(sl_i_tot_rm),
            sl_max = max(sl_i_tot_rm),
            dbh_mean = mean(dbh),
            dbh_min = min(dbh),
            dbh_max = max(dbh))

#Add a column at the front specifying the group
tb2 <- tb2 %>% 
  mutate(group = "All")
```

Then summarize these variables across dmr classes
```{r}
tb3 <- modelling %>%
  select(dmr_f, sim_tree, dist_y_h, sl_i_tot_rm, dbh) %>% 
  group_by(dmr_f) %>% 
  summarise(n_tot = n(),
            n_meas = sum(sim_tree == "N"),
            n_sim = sum(sim_tree == "Y"),
            dist_mean = mean(dist_y_h),
            dist_min = min(dist_y_h),
            dist_max = max(dist_y_h),
            sl_mean = mean(sl_i_tot_rm),
            sl_min = min(sl_i_tot_rm),
            sl_max = max(sl_i_tot_rm),
            dbh_mean = mean(dbh),
            dbh_min = min(dbh),
            dbh_max = max(dbh)) %>% 
  rename(group = dmr_f)

#Combine these tables
tb3 <- rbind(tb2, tb3)

#Relocate the group variable so it is the first column
tb3 <- tb3 %>% relocate(group, .before = everything())

#Take a look at it
view(tb3)
```

Export final table
```{r}
# write_csv(tb3, here("./tables/model_dtset_sum.csv"))
```

##Plot dmr against tree level predictors
Start witth plotting it against continuous predictors
```{r}
#DISTANCE FROM THE EDGE
#Boxplot comparing dmr to distance from the edge
dmr_pred1 <- ggplot(modelling, aes(x = dist_y_h, 
                      y = dmr_f)) + 
  geom_jitter(height = 0.2, colour = "grey", alpha = 0.5) +
  geom_boxplot(fill = NA, outliers = FALSE) +
  labs(y = "DMR", x = "Distance from edge (m)") +
  theme_classic() +
  theme(axis.text = element_text(size = 11, family = "Times New Roman"),
        axis.title = element_text(size = 11, family = "Times New Roman",
                                  face = "bold"))
dmr_pred1
      
#SEED LOAD
#Boxplot comparing dmr_f to seed load
dmr_pred2 <- ggplot(modelling, aes(x = sl_i_tot_rm, 
                      y = dmr_f)) + 
  geom_jitter(height = 0.2, colour = "grey", alpha = 0.5) +
  geom_boxplot(fill = NA, outliers = FALSE) +
  labs(y = "DMR", x = "Seed load (no units)") +
  theme_classic() +
  theme(axis.text = element_text(size = 11, family = "Times New Roman"),
        axis.title = element_text(size = 11, family = "Times New Roman",
                                  face = "bold"))
dmr_pred2

#DBH
#Boxplot comparing dmr to tree dbh
dmr_pred3 <- ggplot(modelling, aes(x = dbh, 
                      y = dmr_f)) + 
  geom_jitter(height = 0.2, colour = "grey", alpha = 0.5) +
  geom_boxplot(fill = NA, outliers = FALSE) +
  labs(y = "DMR", x = "DBH (cm)") +
  theme_classic() +
  theme(axis.text = element_text(size = 11, family = "Times New Roman"),
        axis.title = element_text(size = 11, family = "Times New Roman",
                                  face = "bold"))
dmr_pred3
```

Then plot it against crown class
```{r}
#Find # trees in each DMR class within each crown class
x <- modelling %>% 
  group_by(dmr_f, crown_class) %>% 
  summarise(n_trees = n())

#Find total # of trees in each crown class
x1 <- modelling %>% 
  group_by(crown_class) %>% 
  summarise(tot_trees = n())

#Join these tables, then calculate the percent of trees in each dmr class 
#within each crown class
x <- left_join(x, x1, by = "crown_class")
x <- x %>% 
  mutate(p_trees = 100*n_trees/tot_trees)

#Check these sum to 100
x %>% group_by(crown_class) %>% summarise(sum(p_trees))

#Add fake values to the x1 dataframe so it can be added to the plot to show the
#total sample size in each crown class
x1 <- x1 %>% 
  mutate(p_trees = 105,
         dmr_f = NA)

#Plot this: 
dmr_pred4 <- ggplot(x, aes(x = crown_class, y = p_trees, fill = dmr_f)) + 
  geom_bar(position = position_stack(reverse =  TRUE), stat = "identity") +
  scale_fill_manual(values = col_dmr_7, 
                    na.translate = FALSE, 
                    guide = guide_legend(reverse = TRUE)) + 
  geom_text(data = x1, aes(x=crown_class, 
                           y = p_trees, 
                           label = tot_trees),
            family = "Times New Roman",
            show.legend = FALSE) + 
  labs(x = "Crown class", y = "Percent of trees (%)", fill = "DMR") + 
  theme_classic() +
  theme(legend.background = element_rect(fill = "lightgrey"),
        legend.key = element_rect(fill = "lightgrey", color = NA),
        legend.title = element_text(size = 11, family = "Times New Roman",
                                    face = "bold"),
        legend.text = element_text(size = 11, family = "Times New Roman"),
        axis.text = element_text(size = 11, family = "Times New Roman"),
        axis.title = element_text(size = 11, family = "Times New Roman",
                                  face = "bold"))
dmr_pred4
```

###Compile plot for thesis
```{r}
dmr_pred <- ggarrange(dmr_pred1, dmr_pred2, dmr_pred3, dmr_pred4,
                      nrow = 2, ncol = 2, labels = "AUTO",
                      font.label = list(size = 13, family = "Times New Roman",
                                        face = "bold"))
dmr_pred

#Export
# ggsave(here("./figures/dmr_t_pred.svg"), plot = dmr_pred, device = "svg",
#        width = 6.5, height = 5, units = "in")
```

##Pairs plot
Generate pairs plot to see multicolinearity between tree level predictors. As 
expected, multicolinearity occurs between: 
- seed load and distance from the edge
- dbh and crown class
```{r}
#Subset dataframe to just the tree level predictors
x <- modelling %>% 
  select(sl_i_tot_rm, dist_y_h, dbh, crown_class)

#Transform distance from the edge to make correlation between seed load and 
#distance from the edge clear
x <- x %>% 
  mutate(dist_y_h_4 = dist_y_h^(1/4))

#Generate the plot. Uses ggpairs() fucntion from {GGally} package
##Diagonal shows the density (continuous vars) or a historgram (categorical 
##vars)
##Lower off diagonal shows a scatter plot for two continuous variables or a 
##histogram for each category of categorical variable for continuous x 
##categorical combinations. 
##Upper off diagonal shows a scatterplot for two either Pearson's correlation 
##coefficient (two continuous vars) or a boxplot for continuousx categorical 
##combinations
ggpairs(x)
```

###Pairs plot for thesis
Make a simple pairs plot to include in thesis
```{r}
#Subset modelling dataframe to tree level modelling variables
x <- modelling %>% 
  select(sl_i_tot_rm, dist_y_h, dbh, crown_class)

#Make each plot individually
#Distance vs seed load
pair1 <- ggplot(x, aes(x = dist_y_h, y = sl_i_tot_rm)) + 
  geom_point(color = "grey") + 
  theme_classic() + 
  labs(x = "Distance from the edge (m)",
       y = "Seed load (no units)") +
  theme(axis.text = element_text(size = 10, family = "Times New Roman"),
        axis.title = element_text(size = 11, family = "Times New Roman",
                                  face = "bold"))
pair1

#Distance vs dbh
pair2 <- ggplot(x, aes(x = dist_y_h, y = dbh)) + 
  geom_point(color = "grey") + 
  theme_classic() + 
  labs(x = "Distance from the edge (m)",
       y = "DBH (cm)") +
  theme(axis.text = element_text(size = 11, family = "Times New Roman"),
        axis.title = element_text(size = 11, family = "Times New Roman",
                                  face = "bold"))
pair2

#Distance vs crown class
pair3 <- ggplot(x, aes(x = crown_class, y = dist_y_h)) + 
  geom_jitter(width = 0.1, height = 0, color = "grey", alpha = 0.5) + 
  geom_boxplot(fill = NA, outliers = F) +
  theme_classic() + 
  labs(x = "Crown class",
       y = "Distance from the edge (m)") +
  theme(axis.text = element_text(size = 11, family = "Times New Roman"),
        axis.title = element_text(size = 11, family = "Times New Roman",
                                  face = "bold"))
pair3

#DBH vs seed load
pair4 <- ggplot(x, aes(x = dbh, y = sl_i_tot_rm)) + 
  geom_point(color = "grey") +
  theme_classic() + 
  labs(x = "DBH (cm)",
       y = "Seed load (no units)") +
  theme(axis.text = element_text(size = 11, family = "Times New Roman"),
        axis.title = element_text(size = 11, family = "Times New Roman",
                                  face = "bold"))
pair4

#Crown class vs seed load
pair5 <- ggplot(x, aes(x = crown_class, y = sl_i_tot_rm)) + 
  geom_jitter(width = 0.1, height = 0, color = "grey", alpha = 0.5) + 
  geom_boxplot(fill = NA, outliers = F) +
  theme_classic() + 
  labs(x = "Crown class",
       y = "Seed load (no units)") +
  theme(axis.text = element_text(size = 11, family = "Times New Roman"),
        axis.title = element_text(size = 11, family = "Times New Roman",
                                  face = "bold"))
pair5

#Crown class vs dbh
pair6 <- ggplot(x, aes(x = crown_class, y = dbh)) + 
  geom_jitter(width = 0.1, height = 0, color = "grey", alpha = 0.5) + 
  geom_boxplot(fill = NA, outliers = F) +
  theme_classic() + 
  labs(x = "Crown class",
       y = "DBH (cm)") +
  theme(axis.text = element_text(size = 11, family = "Times New Roman"),
        axis.title = element_text(size = 11, family = "Times New Roman",
                                  face = "bold"))
pair6

#Arrange the plots together
pairs_the <- ggarrange(pair1, pair2, pair3, pair4, pair5, pair6, 
                       ncol=2, nrow = 3)
pairs_the

#Export
# ggsave(here("./figures/mod_vars_pairs.svg"), plot = pairs_the, device = "svg",
#        width = 6.5, height = 8, units = "in")
```

#Demonstration model
Sort of mini tutorial I used to get oriented to ordinal models and the 
packages I was going to use. 

##Model specification
The {ordinal} package was used for all the modelling. 
```{r}
?ordinal
```

Two demonstration models are specified: one without a random effect (a 
cumulative link model) and one without (a cumulative link mixed model). 
```{r}
#Model: dmr ~ distance from edge
d1 <- clm(dmr_f_2 ~ dist_y_h, data=modelling, link = "logit")

#Model: dmr ~ distance from edge with site random effect
d2 <- clmm(dmr_f_2 ~ dist_y_h + (1|site_id),
           data = modelling,
           link = "logit")
```

##What is in the summary output?
- Coefficient associated with the predictor (distance from edge). This is
the log odds value change in dmr_f corresponding to a one unit increase in 
distance. Or rather, for every one unit increase in distance, the likelihood
of a dmr_f = 4, versus dmr_f = 1-3, decreases by 0.118 on a log odds scale. 
Because of the central assumption of ordinal regression modelling is that the 
jump between any two levels (j) has the same probability, the coefficient can
be interpreted more generally as likelihood of dmr_f = "anything" versus a 
dmr_f = anything-1, decreases by 0.118 on a log odds scale. 
- "Threshold coefficients" are the intercepts for each of the logit functions
fitted by the model. 
-These two things (a slope and the intercept) can be used to estimate the 
response (DMR). This estimation can be done in terms of: (1) log odds or odds,
(2) odds ratios  or (3) probabilities. 
- The Hessian condition number (cond.H) is a measure of model identifiability. 
The package guidance indicates that numbers > 10^4 are problematic. For these
examples, this would flag the model with the random effect as potentially
problematic. 
```{r}
#Model: dmr ~ distance from the edge
summary(d1)

#Model: dmr ~ distance from the edge with site random effect
summary(d2)

#Check convergence. Note that for some reason the convergence function 
#doesn't work with clmm models
convergence(d1)

#Example: look at odds of dmr_f = 0 vs IBLC, 1, 2, 3, 4, 5 for distance
#values of 0, 10 and 25
#Increases, which makes sense. dmr_f = 0 more likely farther away from edge
o_0 <- exp(d1$alpha[1] - d1$beta[1]*0)
o_10 <- exp(d1$alpha[1] - d1$beta[1]*10)
o_25 <- exp(d1$alpha[1] - d1$beta[1]*25)
o_0; o_10; o_25

#Express these as probabilities
#plogis function does the conversion of the log odds to probabilities
lo_0 <- d1$alpha[1] - d1$beta[1]*0
lo_10 <- d1$alpha[1] - d1$beta[1]*10
lo_25 <- d1$alpha[1] - d1$beta[1]*25
plogis(lo_0)
plogis(lo_10)
plogis(lo_25)
```

##ggeffects
The ggeffects package can get predictions for many values of a predictor. 
- A dataframe is generated with values of a predictor (in this case distance) 
and corresponding probability of each dmr_f level. Each predictor 
value-response level combination is its own row. 
- The "terms" term specifies which variables you are interested in 
predicted values for.
- The margin term specifies how to treat variables that aren't of interest
(i.e. not identified in the "terms" term). In this case, "mean_mode" is 
specified, which uses the mean (for numeric values) and the mode (= most 
frequent value for factor and character values. 
```{r}
?ggeffect

#Generate the predictions
pre_d1 <- predict_response(d1, terms = "dist_y_h", margin = "mean_mode")

#response.level identifies dmr_f but its values correspond to the levels of
#the factor, not the values that correspond to those levels. Reset those
levels_dmr_f <- c("0", "IBLC", "1", "2", "3", "4", "5")
pre_d1$response.level <- factor(pre_d1$response.level)
levels(pre_d1$response.level) <- levels_dmr_f

#Rename the variables
pre_d1 <- pre_d1 %>%
  rename(seed_load = x,
         dmr_f = response.level)

#Plot
ggplot(pre_d1, aes(x = seed_load, y = predicted, fill = dmr_f)) +
  geom_bar(stat = "identity", position = position_stack()) +
  scale_fill_viridis_d()
```

##Tests of variable significance
-Need likelihood ratio tests to compare models (=test the 
significance of variables by comparing models that differ by one variable)
```{r}
#anova() {stats package}, performs the appropriate test (LR or F-test) 
#comparing two models
?anova()

#drop1() {stats package}, given a model (e.g. y ~ x1 + x2 + x3), drops each
#predictor (x1, x2, x3) from a model and compares that to the full model where
#no variables are dropped. If only wanting to test specific terms, can 
#specify those with the scope argument. 
?drop1()
```

##Assessing goodness of fit
There are three statistics that test for goodness of fit (Fagerland & Hosmer, 
2013; 2016)
- Lipsitz test
- Hosmer-Lemeshow test
- Pulkstenis-Robinson test

None of these ended up being particularly informative in this analysis, but I 
have kept them here in case they are useful in the future. 
```{r}
#All three test statistics are in the generalhoslem package
?generalhoslem

#Lipsitz test
?lipsitz.test()

#Hosmer-Lemeshow test
#Seems like the most general one. Less power than Lipsitz and 
#Pulkstenis-Robinson but can detect more types of lack of fit.
?logitgof()

#Pulkstenis-Robinson tests
#Two tests, on that is an extension of the Chi-squared test statistic and
#another that is a decivance test statistic. Both follow a chi-squared 
#distribution
?pulkrob.chisq()
?pulkrob.deviance()
```

#Modelling
The actual model building process begins here. 

##Track likelihood, AIC and LR tests
Create dataframes to track model fitting. One dataframe that has likelihood and 
AIC and one that has likelihood ratio tests comparing two models. 
```{r}
tb_mfit <- data.frame("Model" = NA, "logLikelihood" = NA, "AIC" = NA)
tb_lr <- data.frame("Comparison" = NA, "dAIC" = NA, "LR stat" = NA,
                    "df" = NA, "p" = NA)
```

##Null Model
Fit the null model. Use DMR collapsed to three levels. Has good 
interpretability and increases sample size in rarely represented categories. 
```{r}
#Model 1
##Null model. DMR with levels IBLC-2 and 3-5 collapsed is the response.
m1 <- clm(dmr_f_4 ~ 1, 
           data = modelling,
           link = "logit",
           threshold = "flexible")
summary(m1)

#Save model fit stats
tb_mfit[1,] <- c("m1", as.numeric(m1$logLik), AIC(m1))
```

##Univariate models
Build univariate models testing the significance of each of the tree level 
predictors: distance from edge (including squared and quadratic forms), seed
load, dbh and crown class. 
```{r}
#Model 2
##Predictor: distance from the edge
##SIGNIFICANT.
m2 <- clm(dmr_f_4 ~ dist_y_h, 
           data = modelling,
           link = "logit",
           threshold = "flexible")
summary(m2)
lr2_1 <- anova(m2, m1)
lr2_1

#Model 3
##Predictor: distance from the edge^2
##SIGNIFICANT.
m3 <- clm(dmr_f_4 ~ dist_y_h.2, 
           data = modelling,
           link = "logit",
           threshold = "flexible")
summary(m3)
lr3_1 <- anova(m3, m1)
lr3_1

#Model 4
##Predictor: distance from the edge^4
##SIGNIFICANT.
m4 <- clm(dmr_f_4 ~ dist_y_h.2, 
           data = modelling,
           link = "logit",
           threshold = "flexible")
summary(m4)
lr4_1 <- anova(m4, m1)
lr4_1

#Compare Hessian condition and AICs of different distance predictors
#Quadratic terms don't reduce AIC and make Hessian condition large
AIC(m2); AIC(m3); AIC(m4)
m2$cond.H; m3$cond.H; m4$cond.H

#Model 5
##Predictor: seed load
##SIGNIFICANT.
m5 <- clm(dmr_f_4 ~ sl_i_tot_rm, 
           data = modelling,
           link = "logit",
           threshold = "flexible")
summary(m5)
lr5_1 <- anova(m5, m1)
lr5_1

#Compare model with seed load to model with distance
#Distance produces model with lower AIC
AIC(m2); AIC(m5)

#Model 6
##Predictor: dbh
##SIGNIFICANT.
m6 <- clm(dmr_f_4 ~ dbh, 
           data = modelling,
           link = "logit",
           threshold = "flexible")
summary(m6)
lr6_1 <- anova(m6, m1)
lr6_1

#Model 7
##Predictor: crown class
##SIGNIFICANT.
m7 <- clm(dmr_f_4 ~ crown_class, 
           data = modelling,
           link = "logit",
           threshold = "flexible")
summary(m7)
lr7_1 <- anova(m7, m1)
lr7_1

#Compare AIC of models with dbh vs crown class
#They are indistinguishable
AIC(m6); AIC(m7)
```

Compile model fit stats and LR tests
```{r}
#Model fit
names(tb_mfit)
mod <- c("m2", "m3", "m4", "m5", "m6", "m7")
ll <- c(m2$logLik, m3$logLik, m4$logLik, m5$logLik, m6$logLik, m7$logLik)
aic <- c(AIC(m2), AIC(m3), AIC(m4), AIC(m5), AIC(m6), AIC(m7))
df <- data.frame("Model" = mod, "logLikelihood" = ll, "AIC" = aic)
tb_mfit <- rbind(tb_mfit, df)

#LR tests
names(tb_lr)
comp <- c("m2-m1", "m3-m1", "m4-m1", "m5-m1", "m6-m1", "m7-m1")
dAIC <- aic - AIC(m1)
lrstat <- c(lr2_1$LR.stat[2], lr3_1$LR.stat[2], lr4_1$LR.stat[2],
            lr5_1$LR.stat[2], lr6_1$LR.stat[2], lr7_1$LR.stat[2])
df <- rep(1, 6)
p <- c(lr2_1$`Pr(>Chisq)`[2], lr3_1$`Pr(>Chisq)`[2], lr4_1$`Pr(>Chisq)`[2],
            lr5_1$`Pr(>Chisq)`[2], lr6_1$`Pr(>Chisq)`[2], lr7_1$`Pr(>Chisq)`[2])
df <- data.frame("Comparison" = comp, "dAIC" = dAIC,
                 "LR.stat" = lrstat,  "df" = df, "p" = p)
tb_lr <- rbind(tb_lr, df)
```

##Two variable models
All tree level predictors are significant but need to assess colinearity. 
Drop crown class because DBH contains similar information but working with a
continuous variable is simpler. In models with distance and seed load, look at 
standard error estimates of the coefficients. Do they become inflated when both 
variables are included?

Model: distance and dbh
```{r}
#Model 8
##Predictor: distance from the edge and dbh
##Interpretation: both are significant, standard errors are reasonable
m8 <- clm(dmr_f_4 ~ dist_y_h + dbh, 
           data = modelling,
           link = "logit",
           threshold = "flexible")
summary(m8)

#Use likelihood ratio tests to test if these are significantly better than the
#univariate models
#Both support the model with both variables
lr8_2 <- anova(m2, m8)
lr8_2
lr8_6 <- anova(m6, m8)
lr8_6

#Use AIC to compare model fit of model with both variables to univariate models
#Model with both variables has the lowest AIC
AIC(m2); AIC(m6); AIC(m8)
```

Now test second possible two variable model: distance and seed load.
```{r}
#Model 9
##Predictor: distance from the edge and seed load
##Interpretation: both are significant, standard errors are reasonable, maybe
##slightly large for seed load
m9 <- clm(dmr_f_4 ~ dist_y_h + sl_i_tot_rm, 
           data = modelling,
           link = "logit",
           threshold = "flexible")
summary(m9)

#Use likelihood ratio tests to test if these are significantly better than the
#univariate models
#Both support the model with both variables
lr9_2 <- anova(m2, m9)
lr9_2
lr9_5 <- anova(m5, m9)
lr9_5

#Use AIC to compare model fit of model with both variables to univariate models
#Model with both variables has the lowest AIC
AIC(m2); AIC(m5); AIC(m9)
```

Test third possible two variable model: seed load and dbh
```{r}
#Model 10
##Predictor: seed load and dbh
##Interpretation: both are significant, standard errors are reasonable
m10 <- clm(dmr_f_4 ~ sl_i_tot_rm + dbh, 
           data = modelling,
           link = "logit",
           threshold = "flexible")
summary(m10)

#Use likelihood ratio tests to test if these are significantly better than the
#univariate models
#Both support the model with both variables
lr10_5 <- anova(m5, m10)
lr10_5
lr10_6 <- anova(m6, m10)
lr10_6

#Use AIC to compare model fit of model with both variables to univaraite models
AIC(m5); AIC(m6); AIC(m10)
```

##Three variable model
Test model with all three: distance, seed load and dbh
```{r}
#Model 11
##Predictor: distance from the edge,  seed load and dbh
##Interpretation: all variables are significant, standard errors are reasonable
m11 <- clm(dmr_f_4 ~ dist_y_h + sl_i_tot_rm + dbh, 
           data = modelling,
           link = "logit",
           threshold = "flexible")
summary(m11)

#Use likelihood ratio tests to test if these are significantly better than the
#two variable models
##All three tests support the model with three variables
lr11_8 <- anova(m8, m11)
lr11_8
lr11_9 <- anova(m9, m11)
lr11_9
lr11_10 <- anova(m10, m11)
lr11_10

#Use AIC to compare model fit of model with all variables to two variable
#models
##Three varaible model has the lowest AIC
AIC(m8); AIC(m9); AIC(m10); AIC(m11)
```

Compile model fit and LR test info
```{r}
#Model fit
names(tb_mfit)
mod <- c("m8", "m9", "m10", "m11")
ll <- c(m8$logLik, m9$logLik, m10$logLik, m11$logLik)
aic <- c(AIC(m8), AIC(m9), AIC(m10), AIC(m11))
df <- data.frame("Model" = mod, "logLikelihood" = ll, "AIC" = aic)
tb_mfit <- rbind(tb_mfit, df)

#LR tests
names(tb_lr)
comp <- c("m8-m2", "m8-m6", "m9-m2", "m9-m5", "m10-m5", "m10-m6",
          "m11-m8", "m11-m9", "m11-m10")
dAIC <- c(AIC(m8)-AIC(m2), AIC(m8)-AIC(m5), AIC(m9)-AIC(m2), AIC(m9)-AIC(m5),
          AIC(m10)-AIC(m5), AIC(m10)-AIC(m6), AIC(m11)-AIC(m8), 
          AIC(m11)-AIC(m9), AIC(m11)-AIC(m10))
lrstat <- c(lr8_2$LR.stat[2], lr8_6$LR.stat[2], lr9_2$LR.stat[2],
            lr9_5$LR.stat[2], lr10_5$LR.stat[2], lr10_6$LR.stat[2],
            lr11_8$LR.stat[2], lr11_9$LR.stat[2], lr11_10$LR.stat[2])
df <- rep(1, 9)
p <- c(lr8_2$`Pr(>Chisq)`[2], lr8_6$`Pr(>Chisq)`[2], lr9_2$`Pr(>Chisq)`[2],
            lr9_5$`Pr(>Chisq)`[2], lr10_5$`Pr(>Chisq)`[2], lr10_6$`Pr(>Chisq)`[2],
            lr11_8$`Pr(>Chisq)`[2], lr11_9$`Pr(>Chisq)`[2], lr11_10$`Pr(>Chisq)`[2])
df <- data.frame("Comparison" = comp, "dAIC" = dAIC,
                 "LR.stat" = lrstat,  "df" = df, "p" = p)
tb_lr <- rbind(tb_lr, df)
```

##First order interactions
Now test for first order interactions. Three to test: distance x seed load, 
distance x dbh and seed load x dbh. 

Start with distance x seed load. 
```{r}
#Model 12
##Predictor: distance from the edge, seed load, dbh and distance x seedload
##interaction
##Interpretation: interaction significant and seed load becomes insignificant.
##Standard errors are reasonable. 
m12 <- clm(dmr_f_4 ~ dist_y_h*sl_i_tot_rm + dbh, 
           data = modelling,
           link = "logit",
           threshold = "flexible")
summary(m12)

#Use LR test to test whether interaction term is significant
##Interpretation: significant
lr12_11 <- anova(m11, m12)
lr12_11

#Compare AIC of two models
##Reasonably large AIC reduction (~25)
AIC(m11); AIC(m12)
```

Now test distance x dbh interaction
```{r}
#Model 13
##Predictor: distance from the edge, seed load, dbh and distance x dbh
##interaction
##Interpretation: interaction significant, standard errors reasonable
m13 <- clm(dmr_f_4 ~ dist_y_h*dbh + sl_i_tot_rm, 
           data = modelling,
           link = "logit",
           threshold = "flexible")
summary(m13)

#Use LR test to test whether interaction term is significant. Also look at AICs
##Interpretation: interaction significant and small reduction in AIC (~7)
lr13_11 <- anova(m11, m13)
lr13_11
```

Finally, test seed load x dbh interaction
```{r}
#Model 14
##Predictor: distance from the edge, seed load, dbh and seed load x dbh
##interaction
##Interpretation: interaction significant, but effect is relatively small and
##model is "nearly unidentifiable". Seed load becomes insignificant. 
m14 <- clm(dmr_f_4 ~ dist_y_h + dbh*sl_i_tot_rm, 
           data = modelling,
           link = "logit",
           threshold = "flexible")
summary(m14)

#Use LR test to test whether interaction term is significant. Also look at AICs
##Interpretation: interaction significant and reasonable reduction in AIC (~15)
lr14_11 <- anova(m11, m14)
lr14_11

#Compare AICs of model without interaction and those with one second order 
#interaction
AIC(m11); AIC(m12); AIC(m13); AIC(m14)
```

Compile model fit and lr tests again
```{r}
#Model fit
names(tb_mfit)
mod <- c("m12", "m13", "m14")
ll <- c(m12$logLik, m13$logLik, m14$logLik)
aic <- c(AIC(m12), AIC(m13), AIC(m14))
df <- data.frame("Model" = mod, "logLikelihood" = ll, "AIC" = aic)
tb_mfit <- rbind(tb_mfit, df)

#LR tests
names(tb_lr)
comp <- c("m12-m11", "m13-m11", "m14-m11")
dAIC <- aic - AIC(m11)
lrstat <- c(lr12_11$LR.stat[2], lr13_11$LR.stat[2], lr14_11$LR.stat[2])
df <- rep(1, 3)
p <- c(lr12_11$`Pr(>Chisq)`[2], lr13_11$`Pr(>Chisq)`[2], 
       lr14_11$`Pr(>Chisq)`[2])
df <- data.frame("Comparison" = comp, "dAIC" = dAIC,
                 "LR.stat" = lrstat,  "df" = df, "p" = p)
tb_lr <- rbind(tb_lr, df)
```

Okay, seems like all three interaction terms are significant. Build all three 
models with two interactions and compare AICs. 
```{r}
#Model 15
##Predictor: distance from the edge, seed load, dbh, distance x seed load int
##and seed load x dbh interaction
m15 <- clm(dmr_f_4 ~ dist_y_h + dbh + sl_i_tot_rm + 
             dist_y_h:sl_i_tot_rm + sl_i_tot_rm:dbh, 
           data = modelling,
           link = "logit",
           threshold = "flexible")
summary(m15)
lr15_12 <- anova(m15, m12)
lr15_12
lr15_14 <- anova(m15, m14)
lr15_14

#Model 16
##Predictor: distance from the edge, seed load, dbh, distance x seed load int
##and distance x dbh interaction
m16 <- clm(dmr_f_4 ~ dist_y_h + dbh + sl_i_tot_rm + 
             dist_y_h:sl_i_tot_rm + dist_y_h:dbh, 
           data = modelling,
           link = "logit",
           threshold = "flexible")
summary(m16)
lr16_13 <- anova(m16, m13)
lr16_13
lr16_12 <- anova(m16, m12)
lr16_12

#Model 17
##Predictor: distance from the edge, seed load, dbh, seed load int x dbh
##and distance x dbh interaction
m17 <- clm(dmr_f_4 ~ dist_y_h + dbh + sl_i_tot_rm + 
             sl_i_tot_rm:dbh + dist_y_h:dbh, 
           data = modelling,
           link = "logit",
           threshold = "flexible")
summary(m17)
lr17_13 <- anova(m17, m13)
lr17_13
lr17_14 <- anova(m17, m14)
lr17_14
```

Also build a model with all three interactions. 
```{r}
#Model 18
##Predictor: distance from the edge, seed load, dbh and all second order
##interactions
##Interpretation: distance x dbh interaction become non-significant model 
##converges but is nearly unidentifiable
m18 <- clm(dmr_f_4 ~ dist_y_h + dbh + sl_i_tot_rm + 
             dist_y_h:dbh + dist_y_h:sl_i_tot_rm + sl_i_tot_rm:dbh, 
           data = modelling,
           link = "logit",
           threshold = "flexible")
summary(m18)
lr18_15 <- anova(m18, m15)
lr18_15
lr18_16 <- anova(m18, m16)
lr18_16
lr18_17 <- anova(m18, m17)
lr18_17
```

Compare AICs.
```{r}
#Make some AIC comparisons. Models 12, 13 and 14 have one second order 
#interaction. Models 15, 16 and 17 have two. Model 18 has all three. 
##Interpretation: Model 15 (seed load x distance and seed load x dbh 
##interactions) performs best. Go with this one. 
AIC(m12); AIC(m13); AIC(m14); AIC(m15); AIC(m16); AIC(m17); AIC(m18)
```

Compile model fit and LR test info
```{r}
#Model fit
names(tb_mfit)
mod <- c("m15", "m16", "m17", "m18")
ll <- c(m15$logLik, m16$logLik, m17$logLik, m18$logLik)
aic <- c(AIC(m15), AIC(m16), AIC(m17), AIC(m18))
df <- data.frame("Model" = mod, "logLikelihood" = ll, "AIC" = aic)
tb_mfit <- rbind(tb_mfit, df)

#LR tests
names(tb_lr)
comp <- c("m15-m12", "m15-m14", "m16-m12", "m16-m13", "m17-m13", "m17-m14",
          "m18-m15", "m18-m16", "m18-m17")
dAIC <- c(AIC(m15)-AIC(m12), AIC(m15)-AIC(m14), AIC(m16)-AIC(m12), 
          AIC(m16)-AIC(m13), AIC(m17)-AIC(m13), AIC(m17)-AIC(m14), 
          AIC(m18)-AIC(m15), AIC(m18)-AIC(m16), AIC(m18)-AIC(m17))
lrstat <- c(lr15_12$LR.stat[2], lr15_14$LR.stat[2], lr16_12$LR.stat[2],
            lr16_13$LR.stat[2], lr17_13$LR.stat[2], lr17_14$LR.stat[2],
            lr18_15$LR.stat[2], lr18_16$LR.stat[2], lr18_17$LR.stat[2])
df <- rep(1, 9)
p <- c(lr15_12$`Pr(>Chisq)`[2], lr15_14$`Pr(>Chisq)`[2], lr16_12$`Pr(>Chisq)`[2],
            lr16_13$`Pr(>Chisq)`[2], lr17_13$`Pr(>Chisq)`[2], lr17_14$`Pr(>Chisq)`[2],
            lr18_15$`Pr(>Chisq)`[2], lr18_16$`Pr(>Chisq)`[2], lr18_17$`Pr(>Chisq)`[2])
df <- data.frame("Comparison" = comp, "dAIC" = dAIC,
                 "LR.stat" = lrstat,  "df" = df, "p" = p)
tb_lr <- rbind(tb_lr, df)
```

##Random effect
Okay we now have a working model with 5 terms, its complex. Is it possible to
add a random effect to this model? 
```{r}
#Refit model 
#Model 19
##Predictor: distance from the edge, seed load, dbh, distance x seed load int
##and seed load x dbh interaction
##Random effect: site
##Interpretation: get warning messages
m19 <- clmm(dmr_f_4 ~ dist_y_h + dbh + sl_i_tot_rm + 
             dist_y_h:sl_i_tot_rm + sl_i_tot_rm:dbh + (1|site_id), 
           data = modelling,
           link = "logit",
           threshold = "flexible")
summary(m19)
lr19_15 <- anova(m19, m15)
lr19_15
```

This will make interpreting the variables harder, but try rescaling the 
variables. 
```{r}
modelling <- modelling %>% 
  mutate(dist_y_h.s = as.numeric(scale(dist_y_h)),
         dbh.s = as.numeric(scale(dbh)),
         sl_i_tot_rm.s = as.numeric(scale(sl_i_tot_rm)))

#Model 20
##Same as Model 19 but with variables scaled. 
##Predictor: distance from the edge, seed load, dbh, distance x seed load int
##and seed load x dbh interaction
##Random effect: site
##Interpretation: no warning messages all variables significant
m20 <- clmm(dmr_f_4 ~ dist_y_h.s + dbh.s + sl_i_tot_rm.s + 
             dist_y_h.s:sl_i_tot_rm.s + sl_i_tot_rm.s:dbh.s + (1|site_id), 
           data = modelling,
           link = "logit",
           threshold = "flexible")
summary(m20)

#Compare AIC of this model against the one where the variables are not scaled. 
#There should be NO DIFFERENCE. We haven't added any information to the model
#we have just eased made it easier for the model to get to a ML solution.
AIC(m19); AIC(m20)
```

Compile model fit and LR test info
```{r}
#Model fit
names(tb_mfit)
mod <- c("m19", "m20")
ll <- c(m19$logLik, m20$logLik)
aic <- c(AIC(m19), AIC(m20))
df <- data.frame("Model" = mod, "logLikelihood" = ll, "AIC" = aic)
tb_mfit <- rbind(tb_mfit, df)

#LR tests
names(tb_lr)
comp <- c("m19-m15")
dAIC <- c(AIC(m19)-AIC(m15))
lrstat <- c(lr19_15$LR.stat[2])
df <- 1
p <- c(lr19_15$`Pr(>Chisq)`[2])
df <- data.frame("Comparison" = comp, "dAIC" = dAIC,
                 "LR.stat" = lrstat,  "df" = df, "p" = p)
tb_lr <- rbind(tb_lr, df)
```

##Proportional odds assumption
Okay, this is a good working model. We need to test the proportional odds
assumption for each of the five variables. 

The goal is to compare predictions from models where parameter estimates are 
unique for each logit (partial proportional odds) to those where they are the 
same for all logits (proportional odds). For reference, if there are j levels 
in the response, j-1 logits (which are sort of like submodels) are fit in an 
ordinal model. Each logit predicts the cumulative logit odds of P<= j. In the 
proportional odds version, we assume the effect of each predictor is the same 
across all logits, which is the same as saying across all j. In the partial 
proportional odds models, a unique coefficient is fit for each logit for each 
predictor that is allowed to vary (allowed to have nominal effects). In 
practice, this means that the probability of transitioning between two levels 
of j, depends on j (e.g. the coefficient that predicts the cumulative odds 
relating DMR = 0 to DMR = IBLC-2 is significantly different from the one that
relates DMR = IBLC-2 to DMR = 3-5). 

###Statistical tests of assumption
One predictor at a time we will fit a partial proportional odds model that 
allows it to vary and holds the other predictors to the proportional odds 
assumption. In the oridnal package this is called allowing the variable to have
nominal effects. We will test the significance of the additional parameters 
with likelihood ratio tests comparing against model 20 that restricts all of 
the predictors to proportional odds. In our case just one more parameter is
needed - response (DMR) has 3 levels, so 2 logits are fit in nominal effects 
model, each with a distinct parameter estimate. 

Start with the distance from the edge
```{r}
#Model 21
##Same as Model 20 but fit with clmm2, which allows for nominal effects
##Allows us to run likelihood ratio tests comparing to clmm2 objects
m21 <- clmm2(dmr_f_4 ~ dist_y_h.s + dbh.s + sl_i_tot_rm.s + 
             dist_y_h.s:sl_i_tot_rm.s + sl_i_tot_rm.s:dbh.s,
             random = site_id,
             data = modelling,
             link = "logistic",
             threshold = "flexible",
             Hess = TRUE)
summary(m21)

#Model 22
##Predictor: distance from the edge, seed load, dbh, distance x seed load int
##and seed load x dbh interaction
##Nominal effect: distance from edge
##Random effect: site
m22 <- clmm2(dmr_f_4 ~ dbh.s + sl_i_tot_rm.s + 
             dist_y_h.s:sl_i_tot_rm.s + sl_i_tot_rm.s:dbh.s,
             nominal = ~dist_y_h.s,
             random = site_id, 
             data = modelling,
             link = "logistic", 
             threshold = "flexible", 
             Hess = TRUE)
summary(m22)

#Perform likelihood ratio test against model without nominal effect. The model
#without the nominal effect that makes the proportional odds assumption is 
#nested in the model with the nominal effect.
##Interpretation: nominal effect sigfnificant
lr22_20 <- anova(m21, m22)
lr22_20

#Compare AICs of these two models. Small reduction
AIC(m21); AIC(m22)
```

Then test seed load
```{r}
#Model 23
##Predictor: distance from the edge, seed load, dbh, distance x seed load int
##and seed load x dbh interaction
##Nominal effect: seed load
##Random effect: site
m23 <- clmm2(dmr_f_4 ~ dbh.s + + dist_y_h.s +
             dist_y_h.s:sl_i_tot_rm.s + sl_i_tot_rm.s:dbh.s,
             nominal = ~sl_i_tot_rm.s,
             random = site_id, 
             data = modelling,
             link = "logistic", 
             threshold = "flexible", 
             Hess = TRUE)
summary(m23)

#Perform likelihood ratio test against model without nominal effect. The model
#without the nominal effect that makes the proportional odds assumption is 
#nested in the model with the nominal effect.
##Interpretation: nominal effect NOT sigfnificant
lr23_20 <- anova(m21, m23)
lr23_20

#Compare AICs of these two models. Nominal effect increases AIC
AIC(m21); AIC(m23)
```

Then test dbh
```{r}
#Model 24
##Predictor: distance from the edge, seed load, dbh, distance x seed load int
##and seed load x dbh interaction
##Nominal effect: dbh
##Random effect: site
m24 <- clmm2(dmr_f_4 ~ dist_y_h.s + sl_i_tot_rm.s +
             dist_y_h.s:sl_i_tot_rm.s + sl_i_tot_rm.s:dbh.s,
             nominal = ~dbh.s,
             random = site_id, 
             data = modelling,
             link = "logistic", 
             threshold = "flexible", 
             Hess = TRUE)
summary(m24)

#Perform likelihood ratio test against model without nominal effect. The model
#without the nominal effect that makes the proportional odds assumption is 
#nested in the model with the nominal effect.
##Interpretation: nominal effect NOT sigfnificant
lr24_20 <- anova(m21, m24)
lr24_20

#Compare AICs of these two models. Nominal effect increases AIC
AIC(m21); AIC(m24)
```

Then the seed load x distance interaction
```{r}
#Model 25
##Predictor: distance from the edge, seed load, dbh, distance x seed load int
##and seed load x dbh interaction
##Nominal effect: distance x seed load interaction
##Random effect: site
m25 <- clmm2(dmr_f_4 ~ dist_y_h.s + sl_i_tot_rm.s + dbh.s +
             sl_i_tot_rm.s:dbh.s,
             nominal = ~dist_y_h.s:sl_i_tot_rm.s,
             random = site_id, 
             data = modelling,
             link = "logistic", 
             threshold = "flexible", 
             Hess = TRUE)
summary(m25)

#Perform likelihood ratio test against model without nominal effect. The model
#without the nominal effect that makes the proportional odds assumption is 
#nested in the model with the nominal effect.
##Interpretation: nominal effect NOT sigfnificant
lr25_20 <- anova(m21, m25)
lr25_20

#Compare AICs of these two models. No decrease in AIC
AIC(m21); AIC(m25)
```

Finally, test seed load x dbh interaction
```{r}
#Model 26
##Predictor: distance from the edge, seed load, dbh, distance x seed load int
##and seed load x dbh interaction
##Nominal effect: seed load x dbh interaction
##Random effect: site
m26 <- clmm2(dmr_f_4 ~ dist_y_h.s + sl_i_tot_rm.s + dbh.s +
            dist_y_h.s:sl_i_tot_rm.s,
             nominal = ~sl_i_tot_rm.s:dbh.s,
             random = site_id, 
             data = modelling,
             link = "logistic", 
             threshold = "flexible", 
             Hess = TRUE)
summary(m26)

#Perform likelihood ratio test against model without nominal effect. The model
#without the nominal effect that makes the proportional odds assumption is 
#nested in the model with the nominal effect.
##Interpretation: nominal effect NOT significant
lr26_20 <- anova(m21, m26)
lr26_20

#Compare AICs of these two models. AIC increases with nominal effect
AIC(m21); AIC(m26)
```

Compile model fit and LR test info
```{r}
#Model fit
names(tb_mfit)
mod <- c("m21", "m22", "m23", "m24", "m25", "m26")
ll <- c(m21$logLik, m22$logLik, m23$logLik, m24$logLik, m25$logLik,
        m26$logLik)
aic <- c(AIC(m21), AIC(m22), AIC(m23), AIC(m24), AIC(m25), AIC(m26))
df <- data.frame("Model" = mod, "logLikelihood" = ll, "AIC" = aic)
tb_mfit <- rbind(tb_mfit, df)

#LR tests
names(tb_lr)
comp <- c("m22-m20", "m23-m20", "m24-m20", "m25-m20", "m26-m20")
dAIC <- aic[2:6] - AIC(m20)
lrstat <- c(lr22_20$`LR stat.`[2], lr23_20$`LR stat.`[2], lr24_20$`LR stat.`[2],
            lr25_20$`LR stat.`[2], lr26_20$`LR stat.`[2])
df <- rep(1, 5)
p <- c(lr22_20$`Pr(Chi)`[2], lr23_20$`Pr(Chi)`[2], lr24_20$`Pr(Chi)`[2],
            lr25_20$`Pr(Chi)`[2], lr26_20$`Pr(Chi)`[2])
df <- data.frame("Comparison" = comp, "dAIC" = dAIC,
                 "LR.stat" = lrstat,  "df" = df, "p" = p)
tb_lr <- rbind(tb_lr, df)
```

###Graphical tests of assumption
In the tests, only distance from the edge failed to meet the proportional 
odds assumption. Dr. Biljana Stojkova from the Stats group at UBC 
suggested also assessing this assumption graphically. There is a good tutorial 
on the general approach to this from UCLA here: https://stats.oarc.ucla.edu/r/dae/ordinal-logistic-regression/

That tutorial fits single variable separate logit models outside of a larger
proportional odds model for each variable. i.e. a model is fit for P<= 0
and for P<=IBLC-2. We will use the partial proportional odds models fit above
which do the same thing, just wrapped up in a single model. 

Plot 1
- Plot all logits from a model with nominal effects across the range of a focal 
predictor. Meeting the assumption means that the distance between any two 
logits on a graph (e.g. P <= 0 and P <= IBLC-2) should be the same across the 
range of a predictor.

Plot 2
- Plot of difference in predicted probabilities between model with nominal
effects and one with proportional odds. This tells you something about how 
much nominal effects (if present) affect the actual probabilities - if a 
partial proportional odds model is significantly different from a proporitonal
odds one, is it meaningful?

POINTS TO CLARIFY
Do the plotted logits in plot 1 need to be parallel LINEAR lines? I think yes.
```{r}
#Replicate the original data
x <- data.frame(tree_id = modelling$tree_id,
                dmr_f_4 = factor(modelling$dmr_f_4),
                dist_y_h = modelling$dist_y_h,
                sl_i_tot_rm = modelling$sl_i_tot_rm,
                dbh = modelling$dbh,
                dist_y_h.s = modelling$dist_y_h.s,
                sl_i_tot_rm.s = modelling$sl_i_tot_rm.s,
                dbh.s = modelling$dbh.s,
                site_id = modelling$site_id)

#Calculate the raw interaction terms
x <- x %>% 
  mutate(int_dist_sl = sl_i_tot_rm.s*dist_y_h.s,
         int_dbh_sl = sl_i_tot_rm.s*dbh.s)

#Save the predicted probabilities for each of the models so we can crosscheck 
#manual calculations
x <- x %>% 
  mutate(pred_m21 = predict(m21),
         pred_m22 = predict(m22), 
         pred_m23 = predict(m23),
         pred_m24 = predict(m24),
         pred_m25 = predict(m25),
         pred_m26 = predict(m26)
         )

#Save the model coefficients
coef_m21 <- coefficients(m21)
coef_m22 <- coefficients(m22)
coef_m23 <- coefficients(m23)
coef_m24 <- coefficients(m24)
coef_m25 <- coefficients(m25)
coef_m26 <- coefficients(m26)

#Extract random effects, add them to the dataframe by site_id
ranef_nom_mod <- data.frame(ranef_m21 =m21$ranef,
                            ranef_m22 = m22$ranef,
                            ranef_m23 = m23$ranef,
                            ranef_m24 = m24$ranef,
                            ranef_m25 = m25$ranef,
                            ranef_m26 = m26$ranef,
                        site_id = unique(modelling$site_id))
x <- left_join(x, ranef_nom_mod, by = "site_id")

#Calculate logit odds for P(DMR<=0) and P(DMR<= IBLC-2) for each of the models
x <- x %>% 
  mutate(lo_0_m21 = coef_m21[1] - coef_m21[3]*dist_y_h.s -
           coef_m21[4]*dbh.s - coef_m21[5]*sl_i_tot_rm.s -
           coef_m21[6]*int_dist_sl - coef_m21[7]*int_dbh_sl - ranef_m21,
         lo_IBLC2_m21 = coef_m21[2] - coef_m21[3]*dist_y_h.s -
           coef_m21[4]*dbh.s - coef_m21[5]*sl_i_tot_rm.s -
           coef_m21[6]*int_dist_sl - coef_m21[7]*int_dbh_sl - ranef_m21,
         lo_0_m22 = (coef_m22[1] + coef_m22[3]*dist_y_h.s) - 
           coef_m22[5]*dbh.s - coef_m22[6]*sl_i_tot_rm.s -
           coef_m22[7]*int_dist_sl - coef_m22[8]*int_dbh_sl - ranef_m22,
         lo_IBLC2_m22 = (coef_m22[2] + coef_m22[4]*dist_y_h.s) - 
           coef_m22[5]*dbh.s - coef_m22[6]*sl_i_tot_rm.s -
           coef_m22[7]*int_dist_sl - coef_m22[8]*int_dbh_sl - ranef_m22,
         lo_0_m23 = (coef_m23[1] + coef_m23[3]*sl_i_tot_rm.s) - 
           coef_m23[5]*dbh.s - coef_m23[6]*dist_y_h.s -
           coef_m23[7]*int_dist_sl - coef_m23[8]*int_dbh_sl - ranef_m23,
         lo_IBLC2_m23 = (coef_m23[2] + coef_m23[4]*sl_i_tot_rm.s) - 
           coef_m23[5]*dbh.s - coef_m23[6]*dist_y_h.s -
           coef_m23[7]*int_dist_sl - coef_m23[8]*int_dbh_sl - ranef_m23,
         lo_0_m24 = (coef_m24[1] + coef_m24[3]*dbh.s) - 
           coef_m24[5]*dist_y_h.s - coef_m24[6]*sl_i_tot_rm.s -
           coef_m24[7]*int_dist_sl - coef_m24[8]*int_dbh_sl - ranef_m24,
         lo_IBLC2_m24 = (coef_m24[2] + coef_m24[4]*dbh.s) - 
           coef_m24[5]*dist_y_h.s - coef_m24[6]*sl_i_tot_rm.s -
           coef_m24[7]*int_dist_sl - coef_m24[8]*int_dbh_sl - ranef_m24,
         lo_0_m25 = (coef_m25[1] + coef_m25[3]*int_dist_sl) - 
           coef_m25[5]*dist_y_h.s - coef_m25[6]*sl_i_tot_rm.s -
           coef_m25[7]*dbh.s - coef_m25[8]*int_dbh_sl - ranef_m25,
         lo_IBLC2_m25 = (coef_m25[2] + coef_m25[4]*int_dist_sl) - 
           coef_m25[5]*dist_y_h.s - coef_m25[6]*sl_i_tot_rm.s -
           coef_m25[7]*dbh.s - coef_m25[8]*int_dbh_sl - ranef_m25,
         lo_0_m26 = (coef_m26[1] + coef_m26[3]*int_dbh_sl) - 
           coef_m26[5]*dist_y_h.s - coef_m26[6]*sl_i_tot_rm.s -
           coef_m26[7]*dbh.s - coef_m26[8]*int_dist_sl - ranef_m26,
         lo_IBLC2_m26 = (coef_m26[2] + coef_m26[4]*int_dbh_sl) - 
           coef_m26[5]*dist_y_h.s - coef_m26[6]*sl_i_tot_rm.s -
           coef_m26[7]*dbh.s - coef_m26[8]*int_dist_sl - ranef_m26
         )

#Take the inverse logit to get cumulative probabilities
x <- x %>% 
  mutate(cp_0_m21 = plogis(lo_0_m21),
         cp_IBLC2_m21 = plogis(lo_IBLC2_m21),
         cp_0_m22 = plogis(lo_0_m22),
         cp_IBLC2_m22 = plogis(lo_IBLC2_m22),
         cp_0_m23 = plogis(lo_0_m23),
         cp_IBLC2_m23 = plogis(lo_IBLC2_m23),
         cp_0_m24 = plogis(lo_0_m24),
         cp_IBLC2_m24 = plogis(lo_IBLC2_m24),
         cp_0_m25 = plogis(lo_0_m25),
         cp_IBLC2_m25 = plogis(lo_IBLC2_m25),
         cp_0_m26 = plogis(lo_0_m26),
         cp_IBLC2_m26 = plogis(lo_IBLC2_m26)
         )

#Calculate exact probabilities of each DMR levels from cumulative probabilities
x <- x %>% 
  mutate(p_0_m21 = cp_0_m21,
         p_IBLC_2_m21 = cp_IBLC2_m21 - cp_0_m21,
         p_3_5_m21 = 1 - cp_IBLC2_m21,
         p_0_m22 = cp_0_m22,
         p_IBLC_2_m22 = cp_IBLC2_m22 - cp_0_m22,
         p_3_5_m22 = 1 - cp_IBLC2_m22,
         p_0_m23 = cp_0_m23,
         p_IBLC_2_m23 = cp_IBLC2_m23 - cp_0_m23,
         p_3_5_m23 = 1 - cp_IBLC2_m23,
         p_0_m24 = cp_0_m24,
         p_IBLC_2_m24 = cp_IBLC2_m24 - cp_0_m24,
         p_3_5_m24 = 1 - cp_IBLC2_m24,
         p_0_m25 = cp_0_m25,
         p_IBLC_2_m25 = cp_IBLC2_m25 - cp_0_m25,
         p_3_5_m25 = 1 - cp_IBLC2_m25,
         p_0_m26 = cp_0_m26,
         p_IBLC_2_m26 = cp_IBLC2_m26 - cp_0_m26,
         p_3_5_m26 = 1 - cp_IBLC2_m26
         )

#Compare a few observations to check calculations were right.
#Model 21
x %>% select(tree_id, dmr_f_4, pred_m21, p_0_m21:p_3_5_m21) %>% 
  slice(c(1, 46, 100))
#Model 22
x %>% select(tree_id, dmr_f_4, pred_m22, p_0_m22:p_3_5_m22) %>% 
  slice(c(1, 46, 100))
#Model 23
x %>% select(tree_id, dmr_f_4, pred_m23, p_0_m23:p_3_5_m23) %>% 
  slice(c(1, 46, 100))
#Model 24
x %>% select(tree_id, dmr_f_4, pred_m24, p_0_m24:p_3_5_m24) %>% 
  slice(c(1, 46, 100))
#Model 25
x %>% select(tree_id, dmr_f_4, pred_m25, p_0_m25:p_3_5_m25) %>% 
  slice(c(1, 46, 100))
#Model 26
x %>% select(tree_id, dmr_f_4, pred_m26, p_0_m26:p_3_5_m26) %>% 
  slice(c(1, 46, 100))
```

Plot 1
```{r}
#Plot the logit odds against each focal predictor. Are the lines parallel? 
#This is what the proportional odds assumption is actually testing. 

#Lengthen the data for plotting
x1 <- x %>% pivot_longer(cols = starts_with("lo"), values_to = "lo_val",
                         names_to = c("lo_level", "model"),
                         names_pattern = "lo_(.*)_(.*)")

#Set values for the lo_level variable that are meaningful for plotting
x1 <- x1 %>% 
  mutate(lo_level = case_match(lo_level,
                               "0" ~ "logit(P ≤ 0)",
                               "IBLC2" ~ "logit(P ≤ IBLC-2)")) %>% 
  mutate(lo_level = factor(lo_level, 
                           levels = c("logit(P ≤ IBLC-2)", "logit(P ≤ 0)")))

#Plot the logit odds of each model
x2 <- x1 %>% filter(model == "m22")
po_m22 <- ggplot(x2, aes(x = dist_y_h.s, y = lo_val, colour = lo_level)) + 
  geom_point(alpha = 0.3) + 
  geom_smooth(se = FALSE, method = "lm") + 
  theme_classic() +
  labs(x = "Distance.s", y = "Logit", color = "Logit") +
  theme(legend.background = element_rect(fill = "lightgrey"),
        legend.key = element_rect(fill = "lightgrey", color = NA),
        axis.text = element_text(size = 11, family = "Times New Roman"),
        axis.title = element_text(size = 11, family = "Times New Roman",
                                  face = "bold"),
        legend.text = element_text(size = 11, family = "Times New Roman"),
        legend.title = element_text(size = 11, family = "Times New Roman",
                                  face = "bold"))
#Save the legend
leg <- get_legend(po_m22)
#Drop the legend from the plot
po_m22 <- po_m22 + theme(legend.position = "none")

x2 <- x1 %>% filter(model == "m23")
po_m23 <- ggplot(x2, aes(x = sl_i_tot_rm.s, y = lo_val, colour = lo_level)) + 
  geom_point(alpha = 0.3) + 
  geom_smooth(se = FALSE, method = "lm") + 
  theme_classic() +
  labs(x = "Seed load.s", y = "Logit") +
  theme(legend.position = "none",
        axis.text = element_text(size = 11, family = "Times New Roman"),
        axis.title = element_text(size = 11, family = "Times New Roman",
                                  face = "bold"))

x2 <- x1 %>% filter(model == "m24")
po_m24 <- ggplot(x2, aes(x = dbh.s, y = lo_val, colour = lo_level)) + 
  geom_point(alpha = 0.3) + 
  geom_smooth(se = FALSE, method = "lm") + 
  theme_classic() +
  labs(x = "DBH.s", y = "Logit") +
  theme(legend.position = "none",
        axis.text = element_text(size = 11, family = "Times New Roman"),
        axis.title = element_text(size = 11, family = "Times New Roman",
                                  face = "bold"))

x2 <- x1 %>% filter(model == "m25")
po_m25 <- ggplot(x2, aes(x = int_dist_sl, y = lo_val, colour = lo_level)) + 
  geom_point(alpha = 0.3) + 
  geom_smooth(se = FALSE, method = "lm") + 
  theme_classic() +
  labs(x = "Distance.s x Seed load.s", y = "Logit") +
  theme(legend.position = "none",
        axis.text = element_text(size = 11, family = "Times New Roman"),
        axis.title = element_text(size = 11, family = "Times New Roman",
                                  face = "bold"))

x2 <- x1 %>% filter(model == "m26")
po_m26 <- ggplot(x2, aes(x = int_dbh_sl, y = lo_val, colour = lo_level)) + 
  geom_point(alpha = 0.3) + 
  geom_smooth(se = FALSE, method = "lm") + 
  theme_classic() + 
  labs(x = "Seed load.s x DBH.s", y = "Logit") +
  theme(legend.position = "none",
        axis.text = element_text(size = 11, family = "Times New Roman"),
        axis.title = element_text(size = 11, family = "Times New Roman",
                                  face = "bold"))

#Put them all together
prop_odds_1 <- ggarrange(po_m22, po_m23, po_m24, po_m25, po_m26, leg,
          ncol = 3, nrow = 2)
prop_odds_1

#Export
# ggsave(here("./figures/prop_odds_1.svg"), plot = prop_odds_1, device = "svg",
#        width = 6.5, height = 5, units = "in")
```

Plot 2
```{r}
#Calculate the difference between the model with proportional odds (m20/21) and
#the flexible one with nominal effects
##Lengthen so the probability of each DMR level is in a single column
x3 <- x %>% 
  pivot_longer(cols = starts_with("p_"), values_to = "prob",
                         names_to = c("DMR_lev", "model"),
                         names_pattern = "p_(.*)_(.*)")

#Focus on distance from the edge. 
#Create two panels:
#Panel A: probabilities of each DMR level across the range of distance from the 
#edge for the models with and without nominal effects (m21 and m22)
x4 <- x3 %>% 
  filter(model %in% c("m21", "m22")) %>% 
  mutate(model = case_match(model,
                            "m21" ~ "PO",
                            "m22" ~ "PPO"),
         DMR_lev = case_match(DMR_lev,
                              "0" ~ "0",
                              "3_5" ~ "3-5",
                              "IBLC_2" ~ "IBLC-2")) %>% 
  mutate(DMR_lev = factor(DMR_lev, levels = c("0", "IBLC-2", "3-5")))

prop_odds_2a <- 
  ggplot(x4, aes(x=dist_y_h, y = prob, colour = DMR_lev, shape = model,
                 linetype = model)) + 
  geom_point(alpha = 0.1) +
  geom_line(stat = "smooth", method = "gam", se = F) + 
  theme_classic() +
  labs(x = "Distance from edge (m)", y = "Probability", linetype = "Model",
       shape = "Model") +
  theme(legend.background = element_rect(fill = NA),
        legend.key = element_rect(fill = NA, color = NA),
        axis.text = element_text(size = 11, family = "Times New Roman"),
        axis.title = element_text(size = 11, family = "Times New Roman"),
        legend.text = element_text(size = 11, family = "Times New Roman"),
        legend.title = element_text(size = 11, family = "Times New Roman",
                                  face = "bold"),
        legend.position = "inside",
        legend.position.inside = c(0.8, 0.5)) +
  scale_colour_manual(values = col_dmr3, guide = "none") +
  guides(shape = guide_legend(override.aes = list(alpha = 1)))
prop_odds_2a

#Panel B: difference in probability estimates between proportional odds model 
#and partial proportional odds model across the range of distance from the 
#edge
x5 <- x4 %>% 
  pivot_wider(names_from = model,
              values_from = prob,
              names_prefix = "prob_") %>% 
  mutate(prob_diff = prob_PO - prob_PPO)

prop_odds_2b <- 
  ggplot(x5, aes(x=dist_y_h, y = prob_diff, colour = DMR_lev)) + 
  geom_point(alpha = 0.1) +
  geom_line(stat = "smooth", method = "gam", se = F, size = 1) + 
  theme_classic() +
  labs(x = "Distance from edge (m)", y = expression(Prob[PO]~-~Prob[PPO]),
       colour = "DMR") +
  theme(legend.background = element_rect(fill = "lightgrey"),
        legend.key = element_rect(fill = "lightgrey", color = NA),
        axis.text = element_text(size = 11, family = "Times New Roman"),
        axis.title = element_text(size = 11, family = "Times New Roman"),
        legend.text = element_text(size = 11, family = "Times New Roman"),
        legend.title = element_text(size = 11, family = "Times New Roman",
                                  face = "bold"),
        legend.position = "bottom") +
  scale_colour_manual(values = col_dmr3) +
  guides(color = guide_legend(override.aes = list(alpha = 1)))

#Save the legend
leg <- ggpubr::get_legend(prop_odds_2b)

#Drop the legend from second panel
prop_odds_2b <- 
  ggplot(x5, aes(x=dist_y_h, y = prob_diff, colour = DMR_lev)) + 
  geom_point(alpha = 0.1) +
  geom_line(stat = "smooth", method = "gam", se = F, size = 1) + 
  theme_classic() +
  labs(x = "Distance from edge (m)", y = expression(Prob[PO]~-~Prob[PPO]),
       colour = "DMR") +
  theme(legend.position = "none",
        axis.text = element_text(size = 11, family = "Times New Roman"),
        axis.title = element_text(size = 11, family = "Times New Roman"),
        legend.text = element_text(size = 11, family = "Times New Roman"),
        legend.title = element_text(size = 11, family = "Times New Roman",
                                  face = "bold")) +
  scale_colour_manual(values = col_dmr3) +
  guides(color = guide_legend(override.aes = list(alpha = 1)))
prop_odds_2b

#Put it all together
#Combine the two plots
prop_odds_2 <- ggarrange(prop_odds_2a, prop_odds_2b, ncol = 2,
                         labels = c("A", "B"), 
                         font.label = list(size = 13, 
                                           family = "Times New Roman",
                                           face = "bold"),
                         label.x = 0, label.y = 1)
#Add the DMR legend
prop_odds_2 <- ggarrange(prop_odds_2, leg, nrow = 2, heights = c(10, 1))
prop_odds_2

#Export
#Export the graph
# ggsave(here("./figures/prop_odds_2.svg"), plot = prop_odds_2, device = "svg",
#        width = 6.5, height = 4, units = "in")
```

##Format and export model fit and LR stats
```{r}
#Drop first row of likelihood ratio stats, just NAs and used as a placeholder
tb_lr <- tb_lr[-1,]

#Round numbers to reasonable amount of decimals
tb_mfit <- tb_mfit %>%
  mutate(across(c("logLikelihood", "AIC"), ~ as.numeric(.x))) %>% 
  mutate(across(c("logLikelihood", "AIC"), ~ format(round(.x, 1), nsmall=1)))
tb_lr <- tb_lr %>% 
  mutate(across(c("dAIC", "LR.stat"), ~ format(round(.x, 1), nsmall=1))) %>% 
  mutate(p =format(round(p, 4), nsmall=4)) %>% 
  mutate(p = if_else(p == "0.0000", "<0.0001", p))

#Export
# write_csv(tb_lr, here("./tables/mod_build_lr.csv"))
# write_csv(tb_mfit, here("./tables/mod_build_mfit.csv"))
```

##Final model
The proportional odds assumption seems met well enough for me for distance
from the edge. For the sake of interpretaability, lets stick with the simpler
model that assumes proportional odds. That means our working models is:
$$
\text{logit}\left(P(Y \leq j)\right) = \tau_j - \left( \beta_1 \cdot \text{dist_y_h.s} + \beta_2 \cdot \text{dbh.s} + \beta_3 \cdot \text{sl_i_tot_rm.s} + \beta_4 \cdot \text{dist_y_h.s} \times \text{sl_i_tot_rm.s} + \beta_5 \cdot \text{sl_i_tot_rm.s} \times \text{dbh.s} \right) + u_{\text{site_id}}
$$

```{r}
summary(m20)
```

###Compile table of final model for thesis
```{r}
#Convert coefficients and estimates to a table
tbl_m20_sum <- tidy(m20)

#Format the rounding
str(tbl_m20_sum)
tbl_m20_sum <- tbl_m20_sum %>% 
  mutate(across(c("estimate", "std.error",
                  "statistic", "p.value"), 
                ~ format(round(.x, 4), nsmall=4))) %>% 
  mutate(p.value = if_else(p.value == "0.0000", "<0.0001", p.value))

# write_csv(tbl_m20_sum, here("./tables/m20_sum.csv"))
```

#Understanding variable effects
The goal of this section is to understand how each predictor influences the 
response. The {ggeffects} package is designed for doing this and is used for 
most of the plots here. A predict() function isn't available for clmm objects
yet and that is required for the {ggeffects} options that allow summaries of
random effects; so the effect of random effects is done manually, following 
the tutorial on the {ordinal} package webpage. 

Four plots are created:
(1) The first one shows all variable combinations. It is complicated and got 
rejected as not that useful for a reader in the feedback from my committee. 
I've kept it here because it is a true representation of the model behaviour  
across all the variable combinations represented in the data. 

(2) The second uses a single DBH value (the mean of dominant/codominant 
trees). These are the future crop trees and the goal of the figure is to show 
how the probability of infection changes with distance from the edge in a 
seed-load dependent way. 

(3) The third focuses on the effect of DBH. Two panels are created. One at a 
fixed distance (7.5 m from the edge), where DBH and seed load interact. The
second shows predicted probabilities from 20-50 m where, seed load = 0, for 
different DBH values; the goals of the second panel is to compare the effects
of DBH and distance. 

(4) Shows the magnitude of the random site effect. It generates probabilities 
for an average tree in average, high infection and low infection sites as a
function of distance from the edge. 

##Plot 1
###Select meaningful values of predictors
The first step is to choose what values of each predictor we want to get 
predictions of the response at. These should be meaningful values, representing
the range, or some low, medium, high like scale. Also, only combinations of 
predictor variables that exist in the data (or are realistic) should appear in 
the final product. 

Two kinds of value sets are created for each predictor, one set for when it is 
the focal predictor that has relatively more values and one set for when it 
is secondary predictor that has relatively fewer values and serves the function 
of being a grouping or faceting variable. 

The model is fit on scaled versions of the variables. The value sets are created
using logic about the variable on the original scale and then are transformed to
the scaled scale. 

Different options choosing and specifying values in {ggeffects} are described 
in this vignette: https://strengejacke.github.io/ggeffects/articles/introduction_effectsatvalues.html 

####Distance from the edge values
Distance from the edge is easy. For its set as a focal predictor, do 5m 
intervals. For its sets a secondary predictor do: 5, 25 and 45m for the dbh
plots and 2.5, 7.5 and 12.5m for the seed load plots
```{r}
#Generate vectors of distances
val_d1 <- seq(from = 0, to = 50, by = 5)
val_d2 <- c(5, 25, 45)
val_d3 <- c(2.5, 7.5, 12.5)

#Scale these values using mean and sd of distance from modelling dataset
dist_mean <- mean(modelling$dist_y_h)
dist_sd <- sd(modelling$dist_y_h)
val_d1 <- (val_d1 - dist_mean)/dist_sd
val_d2 <- (val_d2 - dist_mean)/dist_sd
val_d3 <- (val_d3 - dist_mean)/dist_sd

#Compare ranges to check this worked as expected. Look good.
val_d1
val_d2
val_d3
range(modelling$dist_y_h.s)
```

####Seed load values
Seed load is trickier. Its own frequency distribution is severely left skewed 
because it has so many zeros. And it is structurally related to distance from
the edge. It is only > 0 for distances < 20m. The model will generate estimates
for the whole distance range, but the combinations that are actually 
representative of the data are constrained. 

For its set as a focal predictor: generate a sequence of 50unit interval across
its range. For its set as a secondary predictor: select values 
corresponding to 0, a moderate value and a high value. 

With both of these, make sure to remove combinations from final plots that 
don't exist or are unrealistic in the data. 
```{r}
#Plot histogram of seed load
##Interpretation: set high value at 300 and moderate value at 100 for set when
##seed load is non-focal predictor
ggplot(modelling, aes(x = sl_i_tot_rm)) + 
  geom_histogram(bins = 50)

#Plot seed load against distance from the edge
##Interpretation: High values only exist at distances <10m and moderate values 
##at distances <15m. 
range(modelling$sl_i_tot_rm)
ggplot(modelling, aes(x = dist_y_h, y = sl_i_tot_rm)) + 
  geom_point()

#Plot DBH vs seed load
##Interpretation: high values ren't observed for trees with dbh > 
##25cm but there is no logical/ecological reason for this. I think its just
##chance. So get predictions for all combinations. 
ggplot(modelling, aes(x = dbh, y = sl_i_tot_rm)) + 
  geom_point()

#Generate vectors of values
range(modelling$sl_i_tot_rm)
val_sl1 <- seq(0, 550, by = 50)
val_sl2 <- c(0, 100, 300)

#Scale these to feed them into the model
sl_mean <- mean(modelling$sl_i_tot_rm)
sl_sd <- sd(modelling$sl_i_tot_rm)
val_sl1 <- (val_sl1 - sl_mean)/sl_sd
val_sl2 <- (val_sl2 - sl_mean)/sl_sd

#Compare ranges to check this worked as expected. Look good.
val_sl1
val_sl2
range(modelling$sl_i_tot_rm.s)
```

####DBH values
DBH has a fairly standard distribution. For its focal value set, can use one 
of the defaults in {ggeffects} which selects its min, max and quartiles. For 
when its a non-focal predictor, use the mean value of suppressed, 
intermediate and codominant trees. 
```{r}
#Plot a historgram of DBH
ggplot(modelling, aes(x=dbh)) + 
  geom_histogram()

#Generate vectors of values. Only need non-focal set because we can generate 
#focal set with built in defaults in {ggeffects}
val_dbh2 <- modelling %>% 
  group_by(crown_class_2) %>% 
  summarise(mean_dbh = mean(dbh)) %>% 
  pull(mean_dbh)

#Scale these to feed them into the model
dbh_mean <- mean(modelling$dbh)
dbh_sd <- sd(modelling$dbh)
val_dbh2 <- (val_dbh2 - dbh_mean)/dbh_sd

#Compare ranges to check this worked as expected. Look good.
val_dbh2
range(modelling$dbh.s)
```

###Generate predictions
Predictions are the probability of each DMR class at each unique combination of 
predictors. For each focal variable, we will get predictions across its full 
value range across each combination of the two non-focal predictors. In 
practice, this will result in three facet plot. The facet will capture the 
different levels in one of the non-focal predictors. Shape/line type will 
capture the different levels in the other non-focal predictor. Colour will 
differentiate the different DMR levels. All of these predictions are for the 
population average (i.e. assume random effect is 0).

####Distance from the edge predictions
Distance from the edge shows up in two places in the model - on its own and in
interaction with seed load. Because it doesn't interact with dbh, the pattern
should be the same across the three panels of dbh. But, dbh will change the 
where each DMR level is centred on the y axis. 
```{r}
#Focal predictor: distance from edge
#Non-focal: seed load, dbh
#Margin: NA (all variables in model are included in 'terms' argument)
pr1 <- predict_response(m20, 
                        terms = c("dist_y_h.s [val_d1]", 
                                  "sl_i_tot_rm.s[val_sl2]",
                                  "dbh.s [val_dbh2]"),
                        margin = "mean_mode") 
pr1 <- as.data.frame(pr1)

#Create named version of DMR for plotting
pr1 <- pr1 %>%  
  mutate(DMR = case_match(response.level,
                          "1" ~ "0",
                          "2" ~ "IBLC-2",
                          "3" ~ "3-5")) %>% 
  mutate(DMR = factor(DMR, levels = c("0", "IBLC-2", "3-5")))

#Backtransform distance from the edge so it is on the original scale
pr1 <- pr1 %>% 
  mutate(dist_y = x*dist_sd + dist_mean)

#Create descriptive version of seed load for plotting
sl_lev <- levels(pr1$group)
pr1 <- pr1 %>% 
  mutate(group = as.character(group)) %>% 
  mutate(sl = case_match(group,
                         sl_lev[1] ~ "0",
                        sl_lev[2] ~ "moderate",
                        sl_lev[3] ~ "high")) %>% 
   mutate(sl = factor(sl, levels = c("0", "moderate", "high")))

#Similarly, transform dbh to real values on original scale
pr1 <- pr1 %>%
  mutate(dbh = as.character(facet)) %>% 
  mutate(dbh = round((as.numeric(dbh)*dbh_sd + dbh_mean), 1))

#Create a dbh factor for plotting
dbh_lev <- unique(pr1$dbh)
pr1 <- pr1 %>%
  mutate(
    dbh_f = case_match(dbh,
      dbh_lev[1] ~ paste0("dbh = ", dbh, " (S)"),
      dbh_lev[2] ~ paste0("dbh = ", dbh, " (I)"),
      dbh_lev[3] ~ paste0("dbh = ", dbh, " (D/C)")))
dbh_f_lev <- unique(pr1$dbh_f)
pr1 <- pr1 %>% 
  mutate(dbh_f = factor(dbh_f, levels = dbh_f_lev))
levels(pr1$dbh_f)

#The high level of seed load only occurs <=10m from edge and the moderate level
#<=15m. Remove points beyond that for these two groups. 
pr1 <- pr1 %>% 
  filter(!(sl == "high" & dist_y > 10.5)) %>% 
  filter(!(sl == "moderate" & dist_y > 15.5))

#Plot this
g_pr1 <- 
  ggplot(pr1, aes(x = dist_y, y = predicted, color = DMR, shape = sl)) +
  geom_line(aes(linetype = sl), linewidth = 0.5) +
  facet_wrap(~dbh_f, ncol = 3) +
  theme_classic() + 
  labs(x = "Distance from the edge (m)",
       y = "Probability",
       linetype = "Seed load",
       color = "DMR") + 
  scale_color_manual(values = col_dmr3) +
  scale_linetype_manual(values = c("solid", "dashed", "dotted"))+
  theme(legend.background = element_rect(fill = "lightgrey"),
        legend.key = element_rect(fill = "lightgrey", color = NA),
        legend.title = element_text(size = 20),
        legend.text = element_text(size = 16),
        axis.text = element_text(size = 16),
        axis.title = element_text(size = 20),
        strip.text = element_text(size = 16),
        panel.spacing = unit(0.05, "npc"),
        plot.margin = unit(c(0, 0, 0.1, 0), "npc"))
g_pr1
```

####DBH predictions
DBH is similar to distance from the edge. It exists on its own and in an 
interaction with seed load in the model. Its pattern shouldn't change across 
panels of distance from the edge, but distance from the edge will change where 
the pattern is centered on the y axis. 
```{r}
#Focal predictor: dbh
#Interactions: seed load, distance from the edge
#Margin: mean/mode
pr2 <- predict_response(m20, 
                        terms = c("dbh.s [quart]", 
                                  "sl_i_tot_rm.s [val_sl2]",
                                  "dist_y_h.s [val_d2]")) 
pr2 <- as.data.frame(pr2)

#Create named version of DMR for plotting
pr2 <- pr2 %>%  
  mutate(DMR = case_match(response.level,
                          "1" ~ "0",
                          "2" ~ "IBLC-2",
                          "3" ~ "3-5")) %>% 
  mutate(DMR = factor(DMR, levels = c("0", "IBLC-2", "3-5")))

#Backtransform dbh so it is on the original scale
pr2 <- pr2 %>% 
  mutate(dbh = x*dbh_sd + dbh_mean)

#Create descriptive version of seed load for plotting
sl_lev <- levels(pr2$group)

pr2 <- pr2 %>% 
  mutate(group = as.character(group)) %>% 
  mutate(sl = case_match(group,
                         sl_lev[1] ~ "0",
                        sl_lev[2] ~ "moderate",
                        sl_lev[3] ~ "high")) %>% 
   mutate(sl = factor(sl, levels = c("0", "moderate", "high")))

#Similarly, transform distance from edge to real values on original scale
pr2 <- pr2 %>%
  mutate(dist_y = as.character(facet)) %>% 
  mutate(dist_y = round((as.numeric(dist_y)*dist_sd + dist_mean), 1))

#Create a distance factor for plotting
dist_lev <- unique(pr2$dist_y)
pr2 <- pr2 %>%
  mutate(
    dist_f = case_match(dist_y,
      dist_lev[1] ~ paste0("dist = ", dist_y, "m"),
      dist_lev[2] ~ paste0("dist = ", dist_y, "m"),
      dist_lev[3] ~ paste0("dist = ", dist_y, "m")))
dist_f_lev <- unique(pr2$dist_f)
pr2 <- pr2 %>% 
  mutate(dist_f = factor(dist_f, levels = dist_f_lev))
levels(pr2$dist_f)

#The high level of seed load only occurs <=10m from edge and the moderate level
#<=15m. That means plotting the high and moderate levels for the 25 and 45m 
#distances isn't representative. Remove these 
pr2 <- pr2 %>% 
  filter(!(sl %in% c("high", "moderate") & 
             dist_f %in% c(dist_f_lev[2], dist_f_lev[3]))) 

#Generate the plot
g_pr2 <- 
  ggplot(pr2, aes(x = dbh, y = predicted, color = DMR)) + 
  geom_line(aes(linetype = sl), linewidth = 0.5) +
  facet_wrap(~dist_f, ncol = 3) +
  theme_classic() + 
  labs(x = "DBH (cm)",
       y = "Probability",
       linetype = "Seed load",
       color = "DMR") + 
  scale_color_manual(values = col_dmr3) +
  scale_linetype_manual(values = c("solid", "dashed", "dotted")) +
  theme(legend.background = element_rect(fill = "lightgrey"),
        legend.key = element_rect(fill = "lightgrey", color = NA),
        legend.title = element_text(size = 20),
        legend.text = element_text(size = 16),
        axis.text = element_text(size = 16),
        axis.title = element_text(size = 20),
        strip.text = element_text(size = 16))
g_pr2
```

####Seed load
Seed load is the hardest predictor to interpret. It appears in the model on its
own and in interactions with distance from the edge and dbh. Seed load is only
non-zero for distances < 25m so its only relevant to plot it for predictor 
combinations in that range. 
```{r}
#Focal predictor: seed load
#Interactions: distance from the edge, dbh
pr3 <- predict_response(m20, 
                        terms = c("sl_i_tot_rm.s [val_sl1]",
                                  "dbh.s [val_dbh2]",
                                  "dist_y_h.s [val_d3]")) 
pr3 <- as.data.frame(pr3)

#Create named version of DMR for plotting
pr3 <- pr3 %>%  
  mutate(DMR = case_match(response.level,
                          "1" ~ "0",
                          "2" ~ "IBLC-2",
                          "3" ~ "3-5")) %>% 
  mutate(DMR = factor(DMR, levels = c("0", "IBLC-2", "3-5")))

#Backtransform seed load so it is on the original scale
pr3 <- pr3 %>% 
  mutate(sl = x*sl_sd + sl_mean)

#Transform distance from edge to real values on original scale
pr3 <- pr3 %>%
  mutate(dist_y = as.character(facet)) %>% 
  mutate(dist_y = round((as.numeric(dist_y)*dist_sd + dist_mean), 1))

#Create a distance factor for plotting
dist_lev <- unique(pr3$dist_y)
pr3 <- pr3 %>%
  mutate(
    dist_f = case_match(dist_y,
      dist_lev[1] ~ paste0("dist = ", dist_y, "m"),
      dist_lev[2] ~ paste0("dist = ", dist_y, "m"),
      dist_lev[3] ~ paste0("dist = ", dist_y, "m")))
dist_f_lev <- unique(pr3$dist_f)
pr3 <- pr3 %>% 
  mutate(dist_f = factor(dist_f, levels = dist_f_lev))
levels(pr3$dist_f)

#Do the same for dbh. Transform it to real values on original scale then make
#a factor
pr3 <- pr3 %>%
  mutate(dbh = as.character(group)) %>% 
  mutate(dbh = round((as.numeric(dbh)*dbh_sd + dbh_mean), 1))

dbh_lev <- unique(pr3$dbh)
pr3 <- pr3 %>%
  mutate(
    dbh_f = case_match(dbh,
      dbh_lev[1] ~ paste0(dbh, " (S)"),
      dbh_lev[2] ~ paste0(dbh, " (I)"),
      dbh_lev[3] ~ paste0(dbh, " (D/C)")))
dbh_f_lev <- unique(pr3$dbh_f)
pr3 <- pr3 %>% 
  mutate(dbh_f = factor(dbh_f, levels = dbh_f_lev))
levels(pr3$dbh_f)

#Again, we have to filter seed load to only include combinations that exist in 
#the data. At 2.5m, the full range of seed load values is represented. At 7.5
#only 0-400 are represented. At 12.5 only 0-200 are represented. 
pr3 <- pr3 %>% 
  filter(!(dist_f == dist_f_lev[2] & sl > 400)) %>% 
  filter(!(dist_f == dist_f_lev[3] & sl > 200))

#Generate the plot
g_pr3 <- 
  ggplot(pr3, aes(x = sl, y = predicted, color = DMR)) + 
  geom_line(aes(linetype = dbh_f), linewidth = 0.5) +
  facet_wrap(~dist_f, ncol = 3) +
  theme_classic() + 
  labs(x = "Seed load (no units)",
       y = "Probability",
       linetype = "DBH (cm)",
       color = "DMR") + 
  scale_color_manual(values = col_dmr3) +
  scale_linetype_manual(values = c("solid", "dashed", "dotted")) +
  theme(legend.background = element_rect(fill = "lightgrey"),
        legend.key = element_rect(fill = "lightgrey", color = NA),
        legend.title = element_text(size = 20),
        legend.text = element_text(size = 16),
        axis.text = element_text(size = 16),
        axis.title = element_text(size = 20),
        strip.text = element_text(size = 16))
g_pr3
```

###Combine plots for three predictor variables
Here, I'm considering each three panel plot for a predictor variable one plot. 
The plots share a DMR legend but have a distinct secondary aesthetic. Strategy:
make each plot a row, create a shared colour legend to put on top and have a 
distinct legend at the right of each plot. 
```{r}
#Save the DMR colour legend:
leg_dmr <- ggpubr::get_legend(
  ggplot(pr3, aes(x = sl, y = predicted, color = DMR)) +
  geom_point() + 
  geom_line(linewidth = 2.5) +
  theme_classic() +
  scale_color_manual(values = col_dmr3) +
  theme(legend.position = "top",
        legend.background = element_rect(fill = "lightgrey"),
        legend.key = element_rect(fill = "lightgrey", color = NA),
        legend.title = element_text(size = 20),
        legend.text = element_text(size = 16)),
  position = "top")

#Recreate the plots but without the colour legend item and adding a 
#legend justification argument that ensures they are aligned in the combined 
#plot
g_pr1 <- g_pr1 + guides(color = "none") + 
  theme(legend.justification = c(0, 0.5))
g_pr2 <- g_pr2 + guides(color = "none") + 
  theme(legend.justification = c(0, 0.5))
g_pr3 <- g_pr3 + guides(color = "none") + 
  theme(legend.justification = c(0, 0.5))

#Combine the plots
g_pr4 <- plot_grid(g_pr1, g_pr2, g_pr3, 
          nrow = 3, ncol = 1,
          align = "hv",
          labels = "AUTO",
          label_size = 20,
          hjust = -0.8,
          vjust = -0.5)
g_pr4
?plot_grid

#Add the colour legend
g_pr5 <- plot_grid(leg_dmr, g_pr4, 
          nrow = 2, ncol = 1, rel_heights = c(1, 15))
g_pr5

#Export the graph
# pdf(here("./figures/var_effects.pdf"), width = 8.5, height = 11)
# g_pr5
# dev.off()
```

##Plot 2
Select some representative values for predictors
```{r}
#For distance from the edge go from 0-50m in 1m steps
#Generate vectors of distances
val_d4 <- seq(from = 0, to = 50, by = 1)
#Scale these values using mean and sd of distance from modelling dataset
val_d4 <- (val_d4 - dist_mean)/dist_sd

#For seed load, use the three values selected above, representing 0, low and
#high seed load
val_sl2

#For dbh, use mean of dominant/codominant trees
val_dbh3 <- val_dbh2[3]
```

Generate predictions, then reformat the data frame for plotting
```{r}
#Generate predictions
pr5 <- predict_response(m20, 
                        terms = c("dist_y_h.s [val_d4]", 
                                  "sl_i_tot_rm.s[val_sl2]",
                                  "dbh.s [val_dbh3]"),
                        margin = "mean_mode")

#Rename variables and transform them back to their original scale
x <- pr5 %>% 
  as_tibble() %>% 
  mutate(sl = as.character(group)) %>% 
  mutate(sl = as.numeric(sl),
         DMR = case_match(response.level,
                          "1" ~ "0",
                          "2" ~ "IBLC-2",
                          "3" ~ "3-5")) %>% 
  mutate(dist_m = x*dist_sd + dist_mean,
         sl = round(sl*sl_sd + sl_mean, 1),
         DMR = factor(DMR, levels = c("0", "IBLC-2", "3-5"))) %>%
  mutate(sl = factor(sl))

levels(x$sl)
#Remove combinations of variables that aren't represented in the data
x <- x %>% 
  mutate(var_comb_real = case_when(
    sl %in% c("100", "300") & dist_m > 20 ~ "N",
    .default = "Y")) %>% 
  filter(var_comb_real == "Y")
```

Plot it all
```{r}
#Plot
p1 <- ggplot(x, aes(x = dist_m, y = predicted, color = DMR, 
                linetype = sl)) + 
  geom_line() +
  theme_classic() +
  scale_color_manual(values = col_dmr3) +
  scale_linetype_manual(values = c("solid", "dashed", "dotted")) +
  labs(x = "Distance from edge (m)", y = "Predicited probability",
       linetype = "Seed load") +
  theme(legend.position = "inside",
        legend.position.inside = c(0.8, 0.5),
        legend.background = element_rect(fill = "lightgrey", colour = NA),
        legend.box.background = element_rect(fill = "lightgrey", 
                                             colour = NA), 
        legend.spacing.y = unit(0, "cm"),
        legend.key.height = unit(0.3, "cm"),
        legend.key.width = unit(1, "cm"),
        legend.key = element_rect(fill = "lightgrey"),
        axis.text = element_text(size = 11, family = "Times New Roman"),
        axis.title = element_text(size = 11, family = "Times New Roman",
                                  face = "bold"),
        legend.text = element_text(size = 11, family = "Times New Roman"),
        legend.title = element_text(size = 11, family = "Times New Roman",
                                  face = "bold"))
p1

#Generate a second plot of seed load x distance from the edge to show
#why we only display data up to 20m from edge
x1 <- modelling %>% 
  filter(crown_class_2 == "C")

p2 <- ggplot(x1, aes(x = dist_y_h, y = sl_i_tot_rm)) +
  geom_point(color = "grey") +
  theme_classic() +
  labs(x = "Distance from edge (m)", y = "Seed load (unitless)") +
  theme(axis.text = element_text(size = 11, family = "Times New Roman"),
        axis.title = element_text(size = 11, family = "Times New Roman",
                                  face = "bold"),
        legend.text = element_text(size = 11, family = "Times New Roman"),
        legend.title = element_text(size = 11, family = "Times New Roman",
                                  face = "bold"))
p2

p3 <- ggarrange(p1, p2, nrow = 2, align = "v", 
                labels = "AUTO", font.label = list(size = 13, 
                                          family = "Times New Roman",
                                          face = "bold"))
p3

#Export this
# ggsave(here("./figures/var_eff_dist.svg"), plot = p3, device = "svg",
#        width = 5, height = 5, units = "in")
```

##Plot 3: DBH focus
Vision: two panel plot
Panel 1: x = DBH (across range), y = Probabilities, colour = DMR class,
linetype = seed load. All of this located at 7.5m from edge. 
Panel 2: x = distance from edge (from 20-50m), y = Probabilities, colour = 
DMR class, linetype = DBH. All of this at seed load = 0. 

Select some representative values for predictors
```{r}
#For distance from the edge: panel 1 = 7.5 m, panel 2 = 20-50 m in 1 m 
#intervals
val_d5 <- 7.5
val_d6 <- seq(from = 20, to = 50, by = 1)
#Scale these values using mean and sd of distance from modelling dataset
val_d5 <- (val_d5 - dist_mean)/dist_sd
val_d6 <- (val_d6 - dist_mean)/dist_sd

#For seed load: panel 1 = three values representing 0, low and high seed load; 
#panel 2 = 0
val_sl2 <- c(0, 100, 300)
val_sl3 <- c(0)
#Scale these values
val_sl2 <- (val_sl2 - sl_mean)/sl_sd
val_sl3 <- (val_sl3 - sl_mean)/sl_sd

#For dbh: panel 1 = ; for 
#panel 2 = values corresponding to mean of each crown class
range(modelling$dbh)
val_dbh4 <- seq(from = 4, to = 40, by = 1)
val_dbh2_orig <- modelling %>% 
  group_by(crown_class_2) %>% 
  summarise(mean_dbh = mean(dbh)) %>% 
  pull(mean_dbh)
#Scale these
val_dbh4 <- (val_dbh4 - dbh_mean)/dbh_sd
val_dbh2 <- (val_dbh2_orig - dbh_mean)/dbh_sd
```

Generate predictions, then reformat the data frame for plotting
```{r}
#Generate predictions
#Panel 1
pr6 <- predict_response(m20, 
                        terms = c("dbh.s [val_dbh4]", 
                                  "sl_i_tot_rm.s [val_sl2]",
                                  "dist_y_h.s [val_d5]"),
                        margin = "mean_mode")

#Panel 2
pr7 <- predict_response(m20, 
                        terms = c("dist_y_h.s [val_d6]", 
                                  "dbh.s [val_dbh2]",
                                  "sl_i_tot_rm.s [val_sl3]"),
                        margin = "mean_mode")

#Rename variables and transform them back to their original scale
#Panel 1
x <- pr6 %>% 
  as_tibble() %>% 
  mutate(sl = as.character(group)) %>% 
  mutate(sl = as.numeric(sl),
         DMR = case_match(response.level,
                          "1" ~ "0",
                          "2" ~ "IBLC-2",
                          "3" ~ "3-5")) %>% 
  mutate(dbh = x*dbh_sd + dbh_mean,
         sl = round(sl*sl_sd + sl_mean, 1),
         DMR = factor(DMR, levels = c("0", "IBLC-2", "3-5"))) %>%
  mutate(sl = factor(sl))

#Panel 2
dbh_lev <- levels(pr7$group)
x1 <- pr7 %>% 
  as_tibble() %>% 
  mutate(DMR = case_match(response.level,
                          "1" ~ "0",
                          "2" ~ "IBLC-2",
                          "3" ~ "3-5"),
         dbh_f = case_match(group,
                            dbh_lev[1] ~ paste0(round(val_dbh2_orig[1], 1), 
                                                " (S)"),
                            dbh_lev[2] ~ paste0("11.0", " (I)"),
                            dbh_lev[3] ~ paste0(round(val_dbh2_orig[3], 1), 
                                                " (D/C)"))) %>% 
  mutate(dist_m = x*dist_sd + dist_mean,
         DMR = factor(DMR, levels = c("0", "IBLC-2", "3-5")))
dbh_lev <- unique(x1$dbh_f)
x1 <- x1 %>% 
  mutate(dbh_f = factor(dbh_f, levels = dbh_lev))
```

Plot it all
```{r}
#Panel 1
p1 <- ggplot(x, aes(x = dbh, y = predicted, color = DMR, 
                linetype = sl)) + 
  geom_line() +
  theme_classic() +
  scale_color_manual(values = col_dmr3) +
  scale_linetype_manual(values = c("solid", "dashed", "dotted")) +
  labs(x = "DBH (cm)", y = "Predicited probability",
       linetype = "Seed load") +
  theme(legend.position = "top",
        legend.position.inside = c(0.9, 0.5),
        legend.background = element_rect(fill = "lightgrey", colour = NA),
        legend.box.background = element_rect(fill = "lightgrey", 
                                             colour = NA),
        legend.key.width = unit(0.75, "cm"),
        legend.margin = margin(r = 5, l = 5, unit = "pt"),
        legend.key = element_rect(fill = "lightgrey"),
        axis.text = element_text(size = 11, family = "Times New Roman"),
        axis.title = element_text(size = 11, family = "Times New Roman",
                                  face = "bold"),
        legend.text = element_text(size = 8, family = "Times New Roman"),
        legend.title = element_text(size = 8, family = "Times New Roman",
                                  face = "bold")) +
  guides(color = "none")
p1

#Panel 2
p2 <- ggplot(x1, aes(x = dist_m, y = predicted, color = DMR, 
                linetype = dbh_f)) + 
  geom_line() +
  theme_classic() +
  scale_color_manual(values = col_dmr3) +
  scale_linetype_manual(values = c("solid", "dashed", "dotted")) +
  labs(x = "Distance from the edge (m)", y = "Predicited probability",
       linetype = "DBH") +
  theme(legend.position = "top",
        legend.position.inside = c(0.9, 0.5),
        legend.background = element_rect(fill = "lightgrey", colour = NA),
        legend.box.background = element_rect(fill = "lightgrey", 
                                             colour = NA),
        legend.key.width = unit(0.75, "cm"),
        legend.spacing = unit(0.3, "cm"),
        legend.margin = margin(r = 5, l = 5, unit = "pt"),
        legend.key = element_rect(fill = "lightgrey"),
        axis.text = element_text(size = 11, family = "Times New Roman"),
        axis.title = element_text(size = 11, family = "Times New Roman",
                                  face = "bold"),
        legend.text = element_text(size = 8, family = "Times New Roman"),
        legend.title = element_text(size = 8, family = "Times New Roman",
                                  face = "bold")) +
  guides(colour = "none")
p2

#Generate a plot with a colour legend for DMR and save that
p3 <- ggplot(x, aes(x = dbh, y = predicted, color = DMR)) + 
  geom_line(size = 2) +
  theme_classic() +
  scale_color_manual(values = col_dmr3) +
  labs(x = "DBH (cm)", y = "Predicited probability") +
  theme(legend.position = "right",
        legend.position.inside = c(0.9, 0.5),
        legend.background = element_rect(fill = "lightgrey", colour = NA),
        legend.box.background = element_rect(fill = "lightgrey", 
                                             colour = NA),
        legend.key = element_rect(fill = "lightgrey"),
        axis.text = element_text(size = 11, family = "Times New Roman"),
        axis.title = element_text(size = 11, family = "Times New Roman",
                                  face = "bold"),
        legend.text = element_text(size = 11, family = "Times New Roman"),
        legend.title = element_text(size = 11, family = "Times New Roman",
                                  face = "bold"))
p3

leg_dmr <- ggpubr::get_legend(p3, position = "right")

#Put to panels together
p4 <- ggarrange(p1, p2, nrow = 2, align = "v", 
                labels = "AUTO", font.label = list(size = 13, 
                                          family = "Times New Roman",
                                          face = "bold"))
p4

#Add the DMR legend
p5 <- plot_grid(p4, leg_dmr, 
          nrow = 1, ncol = 2, rel_widths = c(15, 3))
p5

#Export
# ggsave(here("./figures/var_eff_dbh.svg"), plot = p5, device = "svg",
#        width = 5, height = 6, units = "in")
```

##Plot 4: Random effects
Variation between sites is large in this dataset. Going to quantify it here by
estimating site effects and then plotting how the distance from edge effect 
changes with different site effects. I am roughly following this tutorial on 
the ordinal web page: https://rdrr.io/cran/ordinal/f/inst/doc/clmm2_tutorial.pdf 

Start by estimating the effect for each site. In the tutorial they note: "The 
judge effects, u(judgei) are not parameters, so they cannot be estimated in the 
conventional sense, but a “best guess” is provided by the conditional modes. 
Similarly the conditional variance provides an uncertainty measure of the 
conditional modes".
```{r}
#Extract random effects and conditional variance (estimate of variance around
#each random effect (= conditonal mode))
ran_ef <- tibble(ranef = m20$ranef, cond_var = m20$condVar, 
                 site = unique(modelling$site_id))

#Calculate confidence interval based on the conditional variance
ran_ef <- ran_ef %>% 
  mutate(ci = ranef + qnorm(0.975) * sqrt(cond_var) %o% c(-1, 1))

#Arrange from low to high for plotting
ran_ef <- ran_ef %>% arrange(ranef) %>% 
  mutate(site = factor(site, levels = unique(ran_ef$site)))

#Calculate extreme judge effects (used in the plot below too) and add them as
#horizontal lines in this plot
summary(m20)
#5th percentile
re_5p <- qnorm(0.95)*-1*1.986
#95th percentile
re_95p <- qnorm(0.95)*1*1.986

g_re1 <- ggplot(ran_ef, aes(x = site, y = ranef)) + 
  geom_point(color = "grey") + 
  geom_linerange(aes(ymin = ci[, 1], ymax = ci[, 2]), color = "grey") + 
  geom_hline(yintercept = 0, color = "grey", linetype = 1) +
  geom_hline(yintercept = re_5p, color = "grey", linetype = 3) +
  geom_hline(yintercept = re_95p, color = "grey", linetype = 2) +
  annotate("text", x = 12, y = re_5p + 0.3, label = "High infection site",
           family = "Times New Roman", size = 3) +
  annotate("text", x = 12, y = re_95p + 0.3 , label = "Low infection site",
           family = "Times New Roman", size = 3) +
  annotate("text", x = 12, y = 0.3, label = "Average site",
           family = "Times New Roman", size = 3) +
  theme_classic() + 
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5),
        axis.text = element_text(size = 11, family = "Times New Roman"),
        axis.title = element_text(size = 11, family = "Times New Roman",
                                  face = "bold"),
        legend.text = element_text(size = 11, family = "Times New Roman"),
        legend.title = element_text(size = 11, family = "Times New Roman",
                                  face = "bold"),
        plot.margin = unit(c(.5, 2, .5, .5), "cm"),) +
  labs(x = "Site",
       y = "Random effect estimate") +
  coord_cartesian(clip = "off")
g_re1

#Save this plot
# ggsave(here("./figures/ran_effect_est.svg"), plot = g_re1, device = "svg",
#         width = 5, height = 3, units = "in")
```

The next step is more complex because {ggeffects} and {ordinal} don't work 
together yet to get predictions under differ random effects. So need to 
calculate predictions manually. Use the distance from the edge effect as the 
example because that is most intuitive. The general steps were: create a
dataset where distance from the edge varies (0-50), seed load is set at its
mean and dbh is set at the mean for dominant/codominant trees; scale so they 
match the model inputs; estimate the average (random effect = 0) and extreme 
(random effect = 95% CI limits) random effects; manually calcualte 
probabilities of each response; then plot. 
```{r}
#Generate a data set with the three predictors
##Distance from the edge varies, seed load and dbh are at their mean
dbh_cd <- modelling %>% 
  filter(crown_class_2 == "C") %>% 
  summarise(dbh = mean(dbh)) %>% 
  pull(dbh)
ran_ef2 <- data.frame(dist_y_h = rep(seq(0, 50, 5), 3),
                      dbh = rep(dbh_cd, 33),
                      sl_i_tot_rm = rep(sl_mean, 33))

#Scale the predictors
ran_ef2 <- ran_ef2 %>% 
  mutate(dist_y_h.s = (dist_y_h - dist_mean)/dist_sd,
         dbh.s = (dbh - dbh_mean)/dbh_sd,
         sl_i_tot_rm.s = (sl_i_tot_rm - sl_mean)/sl_sd)

#Calculate the raw interaction terms
ran_ef2 <- ran_ef2 %>% 
  mutate(int_dist_sl = dist_y_h.s*sl_i_tot_rm.s,
         int_dbh_sl = dbh.s*sl_i_tot_rm.s)

#Estimate extreme random effects
summary(m20)
re <- qnorm(0.95)*c(-1, 1)*1.986

#Add the random effects to the dataframe
#Also add a factor version describing the random effect for plotting
ran_ef2 <- ran_ef2 %>% 
  mutate(ranef = c(rep(0, 11), rep(re[1], 11), rep(re[2], 11)),
         ranef_f = factor(c(rep("Average", 11), rep("Low infection", 11), 
                     rep("High infection", 11)), 
                     levels = c("Low infection", 
                                "Average", 
                                "High infection"))) 

#Calculate logit odds for P(DMR<=0) and P(DMR<= IBLC-2) 
coef_m20 <- coef(m20)
ran_ef2 <- ran_ef2 %>% 
  mutate(lo_0 = coef_m20[1] - coef_m20[3]*dist_y_h.s - 
           coef_m20[4]*dbh.s - coef_m20[5]*sl_i_tot_rm.s -
           coef_m20[6]*int_dist_sl - coef_m20[7]*int_dbh_sl - ranef,
         lo_IBLC2 = coef_m20[2] - coef_m20[3]*dist_y_h.s - 
           coef_m20[4]*dbh.s - coef_m20[5]*sl_i_tot_rm.s -
           coef_m20[6]*int_dist_sl - coef_m20[7]*int_dbh_sl - ranef)

#Take the inverse logit to get cumulative probabilities
ran_ef2 <- ran_ef2 %>% 
  mutate(cp_0 = plogis(lo_0),
         cp_IBLC2 = plogis(lo_IBLC2))

#Calculate exact probabilities of each DMR levels from cumulative probabilities
ran_ef2<- ran_ef2 %>% 
  mutate(p_0 = cp_0,
         p_IBLC_2 = cp_IBLC2 - cp_0,
         p_3_5 = 1 - cp_IBLC2)

#Lengthen to show the different probabilities
x <- ran_ef2 %>% 
  pivot_longer(cols = starts_with("p_"),
               values_to = "prob",
               names_to = "DMR",
               names_prefix = "p_") %>% 
  mutate(DMR = case_match(DMR,
                          "0" ~ "0",
                          "3_5" ~ "3-5",
                          "IBLC_2" ~ "IBLC-2")) %>% 
  mutate(DMR = factor(DMR, levels = c("0", "IBLC-2", "3-5")))

g_re2 <- ggplot(x, aes(x = dist_y_h, y=prob)) +
  geom_line(aes(color = DMR, linetype = ranef_f)) + 
  theme_classic() +
  scale_linetype_manual(values = c(3, 1, 2)) +
  scale_color_manual(values = col_dmr3) +
  labs(x = "Distance from the edge (m)",
       y = "Probability",
       linetype = "Site type") +
  theme(legend.position = "right",
        legend.background = element_rect(fill = "lightgrey", colour = NA),
        legend.box.background = element_rect(fill = "lightgrey", 
                                             colour = NA),
        legend.key = element_rect(fill = "lightgrey"),
        legend.key.height = unit(0.1, "cm"),
        axis.text = element_text(size = 11, family = "Times New Roman"),
        axis.title = element_text(size = 11, family = "Times New Roman",
                                  face = "bold"),
        legend.text = element_text(size = 11, family = "Times New Roman"),
        legend.title = element_text(size = 11, family = "Times New Roman",
                                  face = "bold")) +
  guides(colour = guide_legend(order = 1, override.aes = list(size = 2)),
         linetype = guide_legend(order = 2, override.aes = list(lwd = 0.5)))
g_re2

#Export the graph
# ggsave(here("./figures/ran_effect_dmr.svg"), plot = g_re2, device = "svg",
#         width = 6.5, height = 4, units = "in")
```

END