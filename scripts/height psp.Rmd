---
title: "height predictions"
author: "Hanno Southam"
date: "`r Sys.Date()`"
output: html_document
---
##############
READ ME
Idea here is to calculate some metrics capturing the size class distribution and amount of Hw on each site and combine those with the properties of each site visit (site index, age of leading canopy layer, height of dominant/codominant Hw trees), then use those metrics in a PCA to identify similar pairs of psp - hdm sites.
################

TO DO/SORT OUT
-What are we going to do with site where balsam fir is a signifcant host?

Start by loading packages
```{r}
rm(list=ls(all=TRUE))

#library
library(here)
library(tidyverse)
library(ggpubr)
library(viridis)
library(nlme)

#Not using, but did in old code
# library(ggbiplot) #for PCA biplots
```

#Load and process the HDM data
```{r}
########################################
####Dataset 1: hdm site data 
#This contains variables at the site level
site <- read_csv(here("./data/cleaned/site data.csv"))
str(site)
summary(site)

#Create a variable that combines site_id, bec, and regen age 
site <- site %>% unite(col = bec, sep = "", 
                       c("bec_z", "bec_sz", "bec_var"), 
                       remove = FALSE) %>% 
  mutate(bec = factor(bec))

#Convert date_surveyed to date format
site <- site %>% rename(date_sur_char = date_surveyed) %>% 
  mutate(date_sur = dmy(date_sur_char))
#Extract year
site <- site %>% mutate(yr_sur = year(date_sur))
#Recalculate age column
site <- site %>% mutate(age = yr_sur - yr_har)

########################################
####Dataset 2: vri data
#Attributes from vri polygons that are representative of the mature and regen
#components of each site.
#1 or 2 polygons represent a regen OR mature component at each site
#When there is 2, the component captures a change in forest type
#Going to use this dataset here to get estimates of:
# (1) site index, (2) age of leading species at site and 
# (3) co/dominant Hw tree height 
#for the mature and regen component at each site.

#Note: We actually have a better site age estimate (the year harvested) for the
#regen components, so we won't use the vri one, but will calculate it anyway.
#Also, we have co/dominant tree Hw tree height estimates from a sampling of 
#trees in both mature and regen components at most sites. We will just use vri
#to fill in missing gaps. 

#Read in data
vri <- read_csv(here("data/raw/vri_hdm_sites.csv"))

#Variables we may use are:
#site_id (corresponds to site_id in HDM sites)
#tree_type: mature or regen
#SITE_INDEX: site index
#SPECIES_CD_1 and SPECIES_CD_2: codes of leading and second species
#PROJ_AGE_1 and PROJ_AGE_2: projected ages of first and second species
#PROJ_HEIGHT_1 and PROJ_HEIGHT_2: projected heights of of the first and second
#species
variable.names(vri)

#Subset dataset to just these variables
vri <- vri %>% select(POLYGON_ID, site_id, tree_type, 
                      SITE_INDEX, 
                      SPECIES_CD_1,SPECIES_CD_2, 
                      PROJ_AGE_1, PROJ_AGE_2, 
                      PROJ_HEIGHT_1, PROJ_HEIGHT_2)


#Take a look at these variables
summary(vri)

#Sort by site_id then look at it manually
vri <- vri %>% arrange(site_id)
#Problem sites: 
#mk_1 regen - missing all values
#mk_3 regen - missing evrything but site index. Actually okay because we will
#get age data from year harvested and we have some measured heights.

#Values for mk_1 regen are in the MKRF vri. Update them here.
#Note: MKRF vri is projected to 2016, so adjusted age estimate to be for 2023
#when site was measured. Haven't included height estimates because those would
#be for 2016 and can't be easily adjusted. Luckily we have height measurements
#for this component so don't need vri estimates anyway. 
mk_1 <- c(62, "mk_1", "regen", 35, "HW", "FDC", 34, 34, NA, NA)
vri <- vri %>% filter(!(site_id == "mk_1" & tree_type =="regen")) %>%
  rbind(mk_1)
vri %>% filter(site_id == "mk_1", tree_type == "regen")

#Okay, all sites components have at least one row that contains a value for
#SITE_INDEX. If they are missing data for age or ht, that can come from
#another source. 

#Calculate a single value for site index, age and codominant/dominant Hw 
#height for each component at each site. 
#Going to take the average when there are two vri polygons that represent
#a component. 
#For age, only going to use PROJ_AGE_1 (the leading species)

str(vri)
#All variables are currently stored as characters, not sure why 
#Make numerics numeric and factors factors 
vri <- vri %>% 
  mutate(across(c(POLYGON_ID, SITE_INDEX, PROJ_AGE_1:PROJ_HEIGHT_2), 
                ~as.numeric(.)))

#First pull out the height value for codominant/dominant hemlocks into a 
#single column
vri <- vri %>% mutate(ht_hw = case_when(SPECIES_CD_1 == "HW" ~ PROJ_HEIGHT_1,
                              SPECIES_CD_2 == "HW" ~ PROJ_HEIGHT_2,
                              .default = NA))
#Then calculate the metrics
vri <- vri %>% group_by(site_id, tree_type) %>% 
  summarise(SITE_INDEX = mean(SITE_INDEX, na.rm = T),
            age_vri = mean(PROJ_AGE_1, na.rm = T),
            ht_hw_vri = mean(ht_hw, na.rm=T))

########################################
####Dataset 3: tree data
#This contains data for each measured tree (mature and regen trees). 
#Treats assessed_by var as a logical for some reason and throws up 
#an error. Not a problem and not going to use this var
t_hdm <- read_csv(here("data/workflow/trees_mapped.csv"))
arrange(t_hdm, tree_id)
str(t_hdm)
summary(t_hdm)

#Convert factor vars to factors: 
t_hdm <- t_hdm %>% mutate(across(
  c(site_id, spp, status, hdm_pa, b_lc, 
    broom_pa, broom_pos, stem_pa, crown_class, crown_cond, outside_10, 
    assessed_by, tree_type, dmr_f),
  ~as.factor(.)))

#Convert plot_id and dmrs to integers
t_hdm <- t_hdm %>% mutate(across(
  c(plot_id, dmr_l, dmr_m, dmr_u, dmr), ~as.integer(.)))

str(t_hdm)

#Create a dataset that is comparable between sites. Need to do two things: 
##At a few sites we mapped mature trees up to 15m from the edge, when the standard was 10m. Need to remove extra trees mapped outside 10m. 
##Regen transects are variable length. Filter to just trees within 15m (the shortest transect) so that we are comparing the same transect footprint at each site
t_hdm_comp <- t_hdm %>% filter(outside_10 =="N" | is.na(outside_10)) %>%
  filter(dist_y_h<=15 | is.na(dist_y_h))

#Subdivide data into mature and regen components
##Mature
t_hdm_mat <- t_hdm_comp %>% filter(tree_type=="mature") #mature trees
##Regen
t_hdm_reg <- t_hdm_comp %>% filter(tree_type == "regen") #regen trees 

#Create factors to represent these trees on a per-hectare basis
#factor = 1/plot area (ha)
#regen = 0.0225ha (3 15x5m transects)
#mature = 0.055 (10x55m area)
t_hdm_reg <- t_hdm_reg %>% mutate(PHF_TREE = 1/0.0225)
t_hdm_mat <- t_hdm_mat %>% mutate(PHF_TREE = 1/0.055)

#Create bins of diameter classes from dbh
##Default is for intervals to be half-open. They include the upper bound but 
##not the lower bound. e.g. (15,20] includes 20 but (20, 25] does not
##https://stackoverflow.com/questions/41304960/how-to-create-breaks-using-the-cut-function-without-numbers-overlapping
##dbh cutoff for mature trees is 9cm so start bottom bin there
##dbh cutoff for regen trees is 4cm so start bottom bin for those there
##Created just one bin for dbh>200cm
max(t_hdm$dbh)
t_hdm_reg <- t_hdm_reg %>% 
  mutate(dbh_bin = cut(dbh, breaks = c(4, 10, 15, 20, 25, 30, 35, 40, 45,
                                       50, 55, 60, 65, 70, 75, 80,
                                       85, 90, 95, 100, 105, 110, 115, 120,
                                       125, 130, 135, 140, 145, 150, 155, 
                                       160, 165, 170, 175, 180, 185, 190, 
                                       195, 200, 500), 
                                        include.lowest = TRUE))
t_hdm_mat <- t_hdm_mat %>% 
  mutate(dbh_bin = cut(dbh, breaks = c(9, 15, 20, 25, 30, 35, 40, 45,
                                       50, 55, 60, 65, 70, 75, 80,
                                       85, 90, 95, 100, 105, 110, 115, 120,
                                       125, 130, 135, 140, 145, 150, 155, 
                                       160, 165, 170, 175, 180, 185, 190, 
                                       195, 200, 500), 
                                        include.lowest = TRUE))
levels(t_hdm_reg$dbh_bin)
levels(t_hdm_mat$dbh_bin)

########################################
#Dataset 4: Co-dominant hemlock height data
#Mostly this is just a summary of trees with measured height from t_hdm dataset
#When there weren't enough codominant hemlock trees on a regen transect, 
#adjacent codominant/dominant hemlock trees were measured. Those are recorded
#in a separate dataset that we will integrate here.
#At a few sites we didn't have time to measure any tree heights. For those, 
#we will use the vri estimates. 
#Use the ht_corr variable. This is the height after correcting for the 
#difference in height measurement protocols between us and the psp plots. psp
#plots measure to apex of apical droop, we estimated the lengt of the droop
#and added that to the measurment. 

#Filter trees dataset to those with height recorded
ht_hdm <- t_hdm %>% filter(!is.na(ht_corr))

#Read in dataset with extra heights
#All of these are from regen trees
ht_hdm_extra <- read_csv(here("./data/cleaned/regen_extra_ht_c.csv"))
summary(ht_hdm_extra)

#Create variable in ht_hdm_extra that identifies it as all regen trees
ht_hdm_extra <- ht_hdm_extra %>% mutate(tree_type = "regen")

#Merge the two datasets
#Only keep variables present in both
ht_comm_var <- intersect(names(ht_hdm), names(ht_hdm_extra))
ht_hdm <- ht_hdm %>% select(all_of(ht_comm_var))
ht_hdm_extra <- ht_hdm_extra %>% select(all_of(ht_comm_var))
#Bind datasets
ht_hdm <- rbind(ht_hdm, ht_hdm_extra)
ht_hdm
str(ht_hdm)

#The protocol we used to measure height differed from the provincial ground
#sampling procedures. We added height to accommodate the apical droop of Hw. 
#Prov procedures measure to top of apical droop. 
#Corrected by subtracting standard amount for each component/crown class.
#Intermediate/suppressed crown classes only measured at one site, but still 
#corrected them. Corrections: 
#Mature: if codominant/dominant = 1m; intermediate = 0.75, suppressed = 0.5m
#Regen: codominant = 0.5m; intermediate = 0.4m, suppressed = 0.3m
#Corrections happened in height cleaning script. Use ht_corr variable

#Check how many height measurements there are per site component
ht_hdm %>% group_by(site_id, tree_type) %>% 
  summarise(n_ht_meas = n())
#Missing height data from: mi_2 and the mature component of ph_2
#Will add this in from vri at end 

#Filter to just codominant and dominant heights
#Other crown classes were only measured at one site (cr_3)
ht_hdm <- ht_hdm %>% mutate(crown_class = as.factor(crown_class))
levels(ht_hdm$crown_class)
ht_hdm <- ht_hdm %>% filter(crown_class %in% c("C", "D")) %>%  
  mutate(crown_class = as.character(crown_class)) %>% 
  mutate(crown_class = as.factor(crown_class))
levels(ht_hdm$crown_class) #good, filtered correctly

#Summarise height data for each site component with three variables: mean, 
#median and standard deviation. Also calculate the mean dbh and ht:dbh ratio
#of the codominant/dominant height trees. 
ht_hdm_sum <- ht_hdm %>% 
  mutate(r_cd_hw_ht_dbh = ht_corr/dbh) %>% 
  group_by(site_id, tree_type) %>% 
  summarise(mean_cd_hw_ht = mean(ht_corr),
            median_cd_hw_ht = median(ht_corr),
            sd_cd_hw_ht = sd(ht_corr))
summary(ht_hdm_sum)

#Now pull in vri data for site components with missing data
mis_ht <- vri %>% filter(site_id == "mi_2" | (site_id == "ph_2" & 
                                                tree_type == "mature"))
#Rename variables so they align with ht_hdm_sum
#Set mean and median equal for these components
#Set standard deviation to mean standard deviation across a tree type. 
#vri components only have one measurement so we can't calculate a sd
reg_ht_sd <- mean(ht_hdm_sum$sd_cd_hw_ht[ht_hdm_sum$tree_type == "regen"], 
                  na.rm = TRUE)
mat_ht_sd <- mean(ht_hdm_sum$sd_cd_hw_ht[ht_hdm_sum$tree_type == "mature"], 
                  na.rm = TRUE)
mis_ht <- mis_ht %>% select(site_id, tree_type, ht_hw_vri) %>% 
  rename(mean_cd_hw_ht = ht_hw_vri) %>% 
  mutate(median_cd_hw_ht = mean_cd_hw_ht, 
         sd_cd_hw_ht = case_when(tree_type == "regen" ~ reg_ht_sd,
                              tree_type == "mature" ~ mat_ht_sd,
                              .default = NA))

#Bind this to the ht_hdm_sum dataset
ht_hdm_sum <- rbind(ht_hdm_sum, mis_ht)

#Break this apart into regen and mature components
ht_hdm_reg <- ht_hdm_sum %>% filter(tree_type =="regen") %>% 
  select(site_id, mean_cd_hw_ht:sd_cd_hw_ht)
ht_hdm_mat <- ht_hdm_sum %>% filter(tree_type =="mature") %>% 
  select(site_id, mean_cd_hw_ht:sd_cd_hw_ht)
####DONE. 
```

#Load, process and and filter the permanent sample plot data
Data from downloaded from here on 24 Jul 2024: https://catalogue.data.gov.bc.ca/dataset/forest-inventory-ground-plot-data-and-interactive-map 
data dictionary: ./data/raw/psp/PSP_data_dictionary_20240125.xlsx
```{r}
########Read in four datasets
#t_psp: tree level data
#Note, this is big dataset, a filtered dataset is loaded in the code because
#we don't need every tree in every psp plot in bc
#v_psp:attributes of visit to a site
#p_psp: attributes of each plot
#s_psp: attributes of each site

# t_psp <- read_csv(here("./data/raw/psp/psp_tree.csv")) 
t_psp <- read_csv(here("./data/workflow/psp_tree_cwh.csv"))
v_psp <- read_csv(here("./data/raw/psp/faib_sample_byvisit.csv"))
p_psp <- read_csv(here("./data/raw/psp/faib_plot_header.csv")) 
s_psp <- read_csv(here("./data/raw/psp/faib_header.csv"))

#Inspect the site, visit and plot level data 
#(will look at the tree level data when its a bit smaller)
summary(v_psp)
summary(s_psp)
summary(p_psp)

#########################
######Filter to sites by proximity, bec zone and measurement completeness
#Filter the sites that are: 
#BEC = CWH subzones that are represented in the hdm sites
#TSAs close to or containing one of our research sites

#Create a single variable for BEC zone
s_psp <- s_psp %>% unite(col = bec, sep = "", 
                       c("BEC_ZONE", "BEC_SBZ", "BEC_VAR"), 
                       remove = FALSE) %>% 
  mutate(bec = str_replace_all(bec, "NA", "-")) %>% 
  mutate(bec = as.factor(bec))

#Filter to sites in BEC zones that the HDM sites are in
#Code calls the variable in HDM site dataframe directly
s_psp <- s_psp %>% filter(bec %in% site$bec) %>% 
  mutate(bec = as.character(bec)) %>% 
  mutate(bec = as.factor(bec))
levels(s_psp$bec)

#Filter to sites in TSAs that contain or are close to our sites
s_psp <- s_psp %>% mutate(TSA_DESC = as.factor(TSA_DESC))
levels(s_psp$TSA_DESC)
s_psp <- s_psp %>% 
  filter(TSA_DESC %in% c("Arrowsmith TSA", "Fraser TSA", "North Island TSA", 
                         "Pacific TSA", "Strathcona TSA", "Sunshine Coast TSA"))

#This leaves us with 924 sites (but sites can be visited multiple times so
#so our potential sample is bigger than this). 

#Filter the other psp datasets to just these sites
t_psp <- t_psp %>% semi_join(s_psp, by="SITE_IDENTIFIER")
v_psp <- v_psp %>% semi_join(t_psp, by = "CLSTR_ID")
p_psp <- p_psp %>% semi_join(t_psp, by = "CLSTR_ID")

#Save this as a csv so we don't have to load the large file each time
#Added cwh to identify that its been filtered to trees near the hdm sites
#and in the CWH bec zone
# write_csv(t_psp, "./data/workflow/psp_tree_cwh.csv")

#This is a more manageable database to work with. Inspect the tree level data
dim(t_psp)
summary(t_psp)

#Understanding the ID variables
#Sites are identified by SITE_IDENTIFIER but there can be multiple plots 
#per site. Not sure what multiple plots would look like because all plots 
#are anchored on the site centre.
nplotcheck <- t_psp %>% group_by(SITE_IDENTIFIER) %>% 
  summarise(nplots = n_distinct(PLOT)) %>% filter(nplots>1)
nplotcheck
#Only one site with more than one plot. Can just remove this site. 
t_psp <- t_psp %>% anti_join(nplotcheck, by="SITE_IDENTIFIER")

#This means that the variable CLSTR_ID should be a unique identifier for each 
#visit to each site (which is equivalent to plot now that all sites only 
#contain one plot). 
#Because we aren't looking to build height equations over multiple visits to a 
#single site, but instead are looking to find sites that looked like ours at
#some point in time, we can treat CLSTR_ID as equivalent to at the site 
#components in the hdm dataset. Summarize results to this grouping variable. 

#Check if there are any NA in PHF_TREE variable
any(is.na(t_psp$PHF_TREE)) 
phf_na <- t_psp %>% filter(is.na(t_psp$PHF_TREE)) #340 trees
dim(phf_na)
head(phf_na)
head(phf_na$MEAS_INTENSE)
#All of these trees have measurement intensity = "OUT_OF_PLOT". Data dictionary
#defines as "=sample tree within the 5.64m radius sample tree plot, but not a
#tagged tree)
#Make sure this really is the psp dataset
v_psp <- v_psp %>% 
  mutate(SAMPLE_SITE_PURPOSE_TYPE_CODE = 
           as.factor(SAMPLE_SITE_PURPOSE_TYPE_CODE))
v_psp %>% select(SAMPLE_SITE_PURPOSE_TYPE_CODE) %>% summary()

#DÃ©a also not sure what these trees are. Only 340 trees (out of 486000). 
#Just remove them for now
t_psp <- t_psp %>% filter(!is.na(PHF_TREE))
any(is.na(t_psp$PHF_TREE))

#Check which CLSTR_ID have:
# >30% Hw
# complete height data (ht_cmplt)
# all height data from field measurements (all_fm)
# complete height to live crown measurements (ht_brch_cmplt)
# complete crown class data

#First make HEIGHT_SOURCE and SPECIES factors
t_psp <- t_psp %>% mutate(across(c(HEIGHT_SOURCE, SPECIES), ~as.factor(.)))
levels(t_psp$HEIGHT_SOURCE); levels(t_psp$SPECIES)

#Create summary table with binary variables checking for completeness
psp.meas.check <- t_psp %>% group_by(CLSTR_ID) %>% 
  summarise(hw_lead = if_else((sum(PHF_TREE[SPECIES == "HW"]))/
                                (sum(PHF_TREE)) > 0.3, "Y", "N"), 
            ht_cmplt = if_else(any(is.na(HEIGHT)), "N", "Y"), 
            all_fm = if_else(any(HEIGHT_SOURCE != "Field measured"), "N", "Y"),
            ht_brch_cmplt = if_else(any(is.na(HT_BRCH)), "N", "Y"),
            cr_cl_cmplt = if_else(any(is.na(CR_CL)), "N", "Y"))

#Count how many psp site visits have all of these things
#How many meet all of these conditions?
psp.meas.check %>% filter(hw_lead == "Y" &
                            ht_cmplt == "Y" &
                            all_fm == "Y" & 
                            ht_brch_cmplt == "Y"& 
                            cr_cl_cmplt == "Y") %>% dim() # 1 site visit
#How many have all have all ht?
psp.meas.check %>% filter(ht_cmplt == "Y") %>%  dim() # 4110 site vists
#How many have all field measured hts?
psp.meas.check %>% filter(ht_cmplt == "Y" & all_fm == "Y") %>%  dim() # 6 visits
#How many have all height to live crown data
psp.meas.check %>% filter(ht_brch_cmplt == "Y") %>% dim() # 7 visits
#How many have complete crown class data
psp.meas.check %>% filter(cr_cl_cmplt == "Y") %>% dim() #1213 visits

#Limitation is in field measured heights and height to live crown data. 
#Try a different approach. For each site calculate:
#proportion of trees that are Hw
#proportion of Hw that have field measured height
#proportion of Hw that have height to live crown
#proportion of Hw that have crown class
#All metrics computed on a per hectare basis because plots have variable 
#radii. 
#Use PHF_TREE (variable that represents trees on per hectare basis)

#Calculate the number of trees (on a per hectare basis) meeting each condition
psp.meas.check <- t_psp %>% group_by(CLSTR_ID) %>% 
  summarise(n_stem_rawcount = n(), #number of trees, not on per hectare
            n_stem = sum(PHF_TREE),
            n_hw = sum(PHF_TREE[SPECIES == "HW"]),
            n_fm_ht = sum(PHF_TREE[HEIGHT_SOURCE == "Field measured" &
                                  SPECIES == "HW"]),
            n_ht_br = sum(PHF_TREE[!is.na(HT_BRCH) & 
                                         SPECIES == "HW"]), 
            n_cr_cl = sum(PHF_TREE[!is.na(CR_CL) & 
                                    SPECIES == "HW"]))

#Calculate proportions of trees at each site visit meeting each criteria
psp.meas.check <- psp.meas.check %>% 
  mutate(prop_hw = n_hw/n_stem,
         prop_fm_ht = n_fm_ht/n_stem,
         prop_ht_br = n_ht_br/n_stem,
         prop_cr_cl = n_cr_cl/n_stem)
summary(select(psp.meas.check, n_stem_rawcount, n_stem, prop_hw, 
               prop_fm_ht, prop_ht_br, prop_cr_cl))
#Most site visits (>50%) have:
#more than 90 measured trees
#>50% hemlock (by stem count)
#on average, 8% of Hw trees with field measured heights (~7 trees)
#no height to live crown data for Hw trees
#~50% of Hw trees with crown class data

#Check how many site visits have >30% Hw, >15% field measured heights for Hw,
#50% of Hw trees with crown class data and height to crown base data for
#for at least some Hw
psp.meas.check %>% filter(prop_hw > 30, prop_fm_ht > 0.15, 
                          prop_ht_br > 0, prop_cr_cl > 0.5) %>% 
  dim() #0 visits

#Check how many just meet the >30% Hw, >15% of Hw trees with field measured 
#heights and >50% of Hw with crown class data 
psp.meas.check %>% filter(prop_hw > 0.3, prop_fm_ht > 0.15,
                          prop_cr_cl > 0.5) %>% dim() #957 sites
#Okay, for now, let restrict the sites based on these last criteria
#Will have to find a way to estimate crown base some other way
meas.check.sites <- psp.meas.check %>% 
  filter(prop_hw > 0.3, prop_fm_ht > 0.15,
                          prop_cr_cl > 0.5)
t_psp <- t_psp %>% semi_join(meas.check.sites, by = "CLSTR_ID")

#Keep other psp datasets up to date by removing filtered sites from them too
s_psp <- s_psp %>% semi_join(t_psp, by = "SITE_IDENTIFIER")
v_psp <- v_psp %>% semi_join(t_psp, by = "CLSTR_ID")
p_psp <- p_psp %>% semi_join(t_psp, by = "CLSTR_ID")

#leaves us with this many site visits:
dim(v_psp)

##########################
####Calculate age and site index estimates for each CLSTR_ID
#Age and site index data are made on a subset of trees called sample trees
#at each psp site
#They are supposed to only be codominant and dominant trees
#The variable TH_TREE, identifies the type of samples tree

#Start by inspecting the samples trees
#How many trees have an age estimate per site visit?
summary(t_psp$AGE_TOT) #max age is 791, crazy
t_psp %>% group_by(CLSTR_ID) %>%
  summarise(n_age_tr = sum(!is.na(AGE_TOT))) %>% summary(n_age_tr)
#Between 1 and 37 trees per site_visit. No site visits with no age trees

#Look at a number of age trees by crown class
t_psp %>% group_by(CR_CL) %>%
  summarise(n_age_tr = sum(!is.na(AGE_TOT)))
#Most but not all are codominant and dominant trees

#Make TH_TREE a factor
t_psp <- t_psp %>% mutate(TH_TREE = as.factor(TH_TREE))

#Get a count of the number of trees in each TH_TREE class
t_psp %>% group_by(TH_TREE) %>% summarise(n_sam_tree = n())
#T = Top height tree. The largest (by dbh) tree in the plot
#Use this tree as an leading age and site index estimate
#Not sure what N means, not applicable maybe

#How many top trees does every site visit have (should be one)
t_psp %>% group_by(CLSTR_ID) %>%
  summarise(n_T_tree = sum(TH_TREE == "T", na.rm = T)) %>%
  summary(n_T_tree)
#Some sites have as many as 10 top trees, weird
#Check how that all top trees are codominant/dominant
t_psp %>% group_by(CR_CL) %>%
  summarise(n_T_tree = sum(TH_TREE == "T", na.rm = T))
#Some intermediate and suppressed

#Filter to just the top trees that are codominant/dominant
toptr_psp <- t_psp %>% filter(TH_TREE == "T") %>%
  filter(CR_CL %in% c("C", "D"))
#Check that all top trees have age and site index values
toptr_psp %>% filter(is.na(SI_TREE) & is.na(AGE_TOT)) %>% dim()
#That gives us: 
dim(toptr_psp)

#Look at how many site visits are represented in those:
length(unique(toptr_psp$CLSTR_ID)) 
#Look at how much site index and age estimates vary per site visit
si_age_sum <- toptr_psp %>% group_by(CLSTR_ID) %>%
  summarise(si_sd = sd(SI_TREE), si_min = min(SI_TREE),
            si_max = max(SI_TREE), age_sd = sd(AGE_TOT),
            age_min = min(AGE_TOT), age_max = max(AGE_TOT)) %>%
  mutate(si_diff = si_max - si_min, age_diff = age_max-age_min)
si_age_sum %>% select(si_sd, si_diff, age_sd, age_diff) %>% summary()
#Odd results here. Some sites where top tree age difference is huge (>100 yrs)
#and si_index difference is large

#Proceed and assume we just won't pick these sites
#Take avergage of site_index and average of age for each site visit
si_age_psp <- toptr_psp %>% group_by(CLSTR_ID) %>%
  summarise(age = mean(AGE_TOT), SITE_INDEX = mean(SI_TREE))

#If using using age and site index in age, would have to filter psp site visits
#to those in si_age_psp (code to do that below). Because of how many sites are
#lost by doing that, opted instead to run PCA instead without these, but will
#still add them after the the dataframes so we can compare them to the hdm 
#sites after candidate pairs have been identified. 

# #Remove site visits that don't have age and site index from the psp datasets
# t_psp <- t_psp %>% semi_join(si_age_psp, by = "CLSTR_ID")
# s_psp <- s_psp %>% semi_join(t_psp, by = "SITE_IDENTIFIER")
# v_psp <- v_psp %>% semi_join(t_psp, by = "CLSTR_ID")
# p_psp <- p_psp %>% semi_join(t_psp, by = "CLSTR_ID")

# #Leaves us with 301 site visits to try and pair with hdm sites
# dim(v_psp)
  
######################
#######Subset dataframes for integration with hdm data
#HDM dataframes used different dbh cutoffs. Regen cutoff = 4cm. Mature = 9cm. 
#Create two subdatasets from psp data, one to compare with regen sites and 
#one with mature sites
t_psp_reg <- t_psp %>% filter(DBH>=4)
t_psp_mat <- t_psp %>% filter(DBH>=9)

#Some site visits have no Hw trees after filtering for trees >9cm dbh to
#create a t_psp_mat. Filter these out so they don't throw errors later
rm_psp_mat <- t_psp_mat %>% group_by(CLSTR_ID) %>% 
  summarise(n_hw = sum(PHF_TREE[SPECIES == "HW"])) %>% 
  filter(n_hw == 0)
t_psp_mat <- t_psp_mat %>% anti_join(rm_psp_mat, by = "CLSTR_ID")

#Then break dbh up into bins for plotting later
t_psp_reg <- t_psp_reg %>% 
  mutate(dbh_bin = cut(DBH, breaks = 
                         c(4, 10, 15, 20, 25, 30, 35, 40, 45,
                                       50, 55, 60, 65, 70, 75, 80,
                                       85, 90, 95, 100, 105, 110, 115, 120,
                                       125, 130, 135, 140, 145, 150, 155, 
                                       160, 165, 170, 175, 180, 185, 190, 
                                       195, 200, 500),
                       include.lowest = TRUE))
t_psp_mat <- t_psp_mat %>% 
  mutate(dbh_bin = cut(DBH, breaks = 
                         c(9, 15, 20, 25, 30, 35, 40, 45,
                                       50, 55, 60, 65, 70, 75, 80,
                                       85, 90, 95, 100, 105, 110, 115, 120,
                                       125, 130, 135, 140, 145, 150, 155, 
                                       160, 165, 170, 175, 180, 185, 190, 
                                       195, 200, 500),
                       include.lowest = TRUE))

#######################
#######Calculate co-dominant/dominant Hw tree heights for each site visit
#NOTE: For exploring height values, used t_psp dataset that hasn't been broken
#into pieces to compare with mature and regen datasets. When summary metrics
#are calculated in last step, the separate mature/regen datasets are used. 
#First, look at summary of height data from each site visit
#Mean height of codominant and dominant Hw ranges from 4.3m to 67m 
t_psp %>% filter(HEIGHT_SOURCE == "Field measured" 
                 & SPECIES == "HW"
                 & CR_CL %in% c("C", "D")) %>% 
  group_by(CLSTR_ID) %>% 
  summarise(ht_mean = mean(HEIGHT), ht_sd =  sd(HEIGHT)) %>% summary()

#See how many field measured heights of Hw trees there are by crown class
#More than >75% of sites have field measured heights for: 
#1 dominant Hw tree
#3 co dominant Hw trees
#1 intermediate Hw tree
#0 suppressed trees (median is 1)
ht_check_psp <- t_psp %>% group_by(CLSTR_ID) %>% 
  summarise(n_d_hw_ht = sum(CR_CL == "D" & 
                              SPECIES == "HW" & 
                              HEIGHT_SOURCE == "Field measured"),
            n_c_hw_ht = sum(CR_CL == "C" & 
                              SPECIES == "HW" & 
                              HEIGHT_SOURCE == "Field measured"), 
            n_i_hw_ht = sum(CR_CL == "I" & 
                              SPECIES == "HW" & 
                              HEIGHT_SOURCE == "Field measured"), 
            n_s_hw_ht = sum(CR_CL == "S" & 
                              SPECIES == "HW" & 
                              HEIGHT_SOURCE == "Field measured"))
summary(ht_check_psp)

#Summarize height of codominant/dominant hw with mean, median and sd. 
#These stats will be used later to align psp sites with hdm sites

####psp dataset comparing against hdm regen site components
ht_cd_psp_reg <- t_psp_reg %>% 
  filter(CR_CL %in% c("C", "D") & 
           SPECIES == "HW" &
           HEIGHT_SOURCE == "Field measured") %>% 
  group_by(CLSTR_ID) %>% 
  summarise(n_cd_hw_ht = n(),
            mean_cd_hw_ht = mean(HEIGHT), 
            median_cd_hw_ht = median(HEIGHT),
            sd_cd_hw_ht = sd(HEIGHT))
summary(ht_cd_psp_reg)

#Check if there are any NA values
any(is.na(ht_cd_psp_reg$mean_cd_hw_ht))
any(is.na(ht_cd_psp_reg$median_cd_hw_ht))
any(is.na(ht_cd_psp_reg$sd_cd_hw_ht)) #NA values here, 
#These are from site visits with only one measurement
sum(is.na(ht_cd_psp_reg$sd_cd_hw_ht)) #eleven sites visits
filter(ht_cd_psp_reg, is.na(sd_cd_hw_ht))

#Filter to sites with at least 5 height measurements
ht_cd_psp_reg <- ht_cd_psp_reg %>% filter(n_cd_hw_ht >=5)

#Select only variables used later to find psp pairs
ht_cd_psp_reg <- ht_cd_psp_reg %>% select(-(n_cd_hw_ht))

####psp heights for dataset comparing against hdm mature site components
ht_cd_psp_mat <- t_psp_mat %>% 
  filter(CR_CL %in% c("C", "D") & 
           SPECIES == "HW" &
           HEIGHT_SOURCE == "Field measured") %>% 
  group_by(CLSTR_ID) %>% 
  summarise(n_cd_hw_ht = n(),
            mean_cd_hw_ht = mean(HEIGHT), 
            median_cd_hw_ht = median(HEIGHT),
            sd_cd_hw_ht = sd(HEIGHT))
summary(ht_cd_psp_mat)

#Check if there are any NA values
any(is.na(ht_cd_psp_mat$mean_cd_hw_ht))
any(is.na(ht_cd_psp_mat$median_cd_hw_ht))
any(is.na(ht_cd_psp_mat$sd_cd_hw_ht)) #NA values here, 
#Again, same site visits from before
sum(is.na(ht_cd_psp_mat$sd_cd_hw_ht)) #eleven sites visits
filter(ht_cd_psp_mat, is.na(sd_cd_hw_ht))

#Filter to sites with at least 5 height measurements
ht_cd_psp_mat <- ht_cd_psp_mat %>% filter(n_cd_hw_ht >=5)

#Again, select just the variables used later in the workflow
ht_cd_psp_mat <- ht_cd_psp_mat %>% select(-(n_cd_hw_ht))

#This many site visits have data for these height metrics
length(unique(t_psp_reg$CLSTR_ID))
length(unique(t_psp_mat$CLSTR_ID))

#######################
#######Calculate "top height" of Hw tree heights for each site visit
#Here calculating height of the largest codominant, and dominant hw
#Doing this because it appears our measurements generally have a larger
#ht:dbh ratio, indicating there was some bias to select larger trees (or 
#we systematically overestimated height).
#Hoping this version of top heihgt might align better with psp sites. 

#Filter trees in psp dataframe by TH_TREE
#From data dictionary: 
#  "T"-Top Height - in the 0.01 ha plot measured within a 5.64 m radius of the plot center; of the trees that are live and dom/codom, (regardless of species or residual status); the largest DBH tree. 
# "L" Leading Species - in each 0.01 ha quadrant of the 11.28 m plot; of the trees that are of the leading species by basal area, live, dom/codom, and non-residual; the largest DBH tree.
# "S" Second Species - in each 0.01 ha quadrant of the 11.28 m plot; of the trees that are of the second species having more than 20% of the basal area in the plot, live, dom/codom, and non-residual; the largest DBH tree.
levels(t_psp$TH_TREE)

#Here calculate same summary metrics of height above. Also calcualte the
#ht:dbh ratio of these trees.
#TH_TREE categories identified above. 
#Regen tree dataset
ht_th_psp_reg <- t_psp_reg %>% 
  filter(TH_TREE %in% c("T", "L", "S") & 
           CR_CL %in% c("C", "D") & 
           SPECIES == "HW" &
           HEIGHT_SOURCE == "Field measured") %>% 
  mutate(r_th_hw_htdbh = HEIGHT/DBH) %>% 
  group_by(CLSTR_ID) %>% 
  summarise(n_th_hw_ht = n(),
            mean_th_hw_ht = mean(HEIGHT), 
            median_th_hw_ht = median(HEIGHT),
            sd_th_hw_ht = sd(HEIGHT),
            mean_th_hw_dbh = mean(DBH),
            r_th_hw_htdbh = mean(r_th_hw_htdbh))
summary(ht_th_psp_reg)
#Leaves us with non-NA values for this many site visits:
length(unique(ht_th_psp_reg$CLSTR_ID))

#Select just the variables used later in the workflow
ht_th_psp_reg <- ht_th_psp_reg %>% select(-(n_th_hw_ht))

#Mature tree dataset
ht_th_psp_mat <- t_psp_mat %>% 
  filter(TH_TREE %in% c("T", "L", "S") & 
           CR_CL %in% c("C", "D") & 
           SPECIES == "HW" &
           HEIGHT_SOURCE == "Field measured") %>% 
  mutate(r_th_hw_htdbh = HEIGHT/DBH) %>% 
  group_by(CLSTR_ID) %>% 
  summarise(n_th_hw_ht = n(),
            mean_th_hw_ht = mean(HEIGHT), 
            median_th_hw_ht = median(HEIGHT),
            sd_th_hw_ht = sd(HEIGHT),
            mean_th_hw_dbh = mean(DBH),
            r_th_hw_htdbh = mean(r_th_hw_htdbh))
summary(ht_th_psp_mat)
#Leaves us with non-NA values for this many site visits:
length(unique(ht_th_psp_reg$CLSTR_ID))

#Select just the variables used later in the workflow
ht_th_psp_mat <- ht_th_psp_mat %>% select(-(n_th_hw_ht))
```

#Combine datasets
```{r}
#The hdm and psp datasets share variables. Need to rename variables
#or create new ones when they don't exist to get combined datasets to work with.
#Will create two of these, one at the tree level and one at the site level. 

########################################
####Tree level
#Variables: 
#orig_id: CLSTR_ID in psp, site_id in hdm datasets
#dataset: identifies whether it is from psp or hdm dataset
#PHF_TREE: per hectare factor, PHF_TREE in psp, not in hdm
#spp: SPECIES in psp, spp in hdm
#crown_class: CR_CL in psp, crown_class in hdm
#dbh: DBH in psp, dbh in hdm
#dbh_bin: 5cm dbh bins, dbh_bin in both datasets
#ht_m: HEIGHT in psp, ht_corr in hdm
#HEIGHT_SOURCE: HEIGHT_SOURCE in psp, not in hdm
#ex_ht_t: is tree an extra ht tree, only in hdm dataset, N for all psp trees

#Start with hdm data
#Select variables
#Going to add extra height trees; add a variable to identify these
#Add a variable to identify this as from the hdm dataset
#Species codes in psp data are uppercase. Adjust to match 
t_hdm_reg_int <- t_hdm_reg %>% 
  mutate(spp = str_to_upper(spp), 
         ex_ht_t = "N",
         dataset = "hdm",
         HEIGHT_SOURCE = if_else(is.na(ht_corr),NA, "Field measured")) %>% 
  rename(orig_id = site_id,
         ht_m = ht_corr)%>% 
  select(orig_id, dataset, PHF_TREE, spp, crown_class, dbh, dbh_bin, ht_m,
         HEIGHT_SOURCE, ex_ht_t)

#Filter out extra height trees that don't have dbh (because the point is 
#estimating ht-dbh relationships)
#Add variables missing from above then select
ht_hdm_extra_int <- ht_hdm_extra %>% filter(!is.na(dbh)) %>% 
  rename(orig_id = site_id,
         ht_m = ht_corr) %>% 
  mutate(spp = str_to_upper(spp),
         dbh_bin = cut(dbh, breaks = c(4, 10, 15, 20, 25, 30, 35, 40, 45,
                                       50, 55, 60, 65, 70, 75, 80,
                                       85, 90, 95, 100, 105, 110, 115, 120,
                                       125, 130, 135, 140, 145, 150, 155, 
                                       160, 165, 170, 175, 180, 185, 190, 
                                       195, 200, 500), 
                                        include.lowest = TRUE),
         ex_ht_t = "Y",
         dataset = "hdm",
         PHF_TREE = NA,
         HEIGHT_SOURCE = "Field measured") %>% 
  select(orig_id, dataset, PHF_TREE, spp, crown_class, dbh, dbh_bin, ht_m,
         HEIGHT_SOURCE, ex_ht_t)
#Bind extra height tree observations to rest of hdm tree level data
identical(names(t_hdm_reg_int), names(ht_hdm_extra_int))
t_hdm_reg_int <- rbind(t_hdm_reg_int, ht_hdm_extra_int)

#Now format tree level psp data
t_psp_reg_int <- t_psp_reg %>% 
  rename(orig_id = CLSTR_ID, dbh = DBH, spp = SPECIES, ht_m = HEIGHT, 
         crown_class = CR_CL) %>% 
  mutate(ex_ht_t = "N",
         dataset = "psp") %>% 
  select(orig_id, dataset, PHF_TREE, spp, crown_class, dbh, dbh_bin, ht_m,
         HEIGHT_SOURCE, ex_ht_t)

#Bind the datasets
identical(names(t_hdm_reg_int), names(t_psp_reg_int))
t_reg <- rbind(t_hdm_reg_int, t_psp_reg_int)

#Create a binary variable for whether a tree is a Hw
t_reg <- t_reg %>% 
  mutate(hw = if_else(spp == "HW", "HW", "non-HW"))

#Make species and hw variables factors
t_reg <- t_reg %>% mutate(spp = as.factor(spp), hw = as.factor(hw))

#Calculate basal area
t_reg <- t_reg %>% mutate(ba_m2 = pi*((dbh/100)/2)^2)

#Summarize the stem count by diameter class
t_reg_dbh_bin <- t_reg %>% filter(ex_ht_t == "N") %>% 
  group_by(orig_id, hw, dbh_bin) %>% 
  summarise(n_trees_ha = sum(PHF_TREE))

########################################
####Site level dataset

#Calculate some key summary stats at the site level
#stem density (#stems/ha)
#basal area of Hw (m2/ha)
#mean median, 25th/75th percentile and max dbh of all spp and just hw
#mean dbh of codominant/dominant hemlock
#Remove extra height trees that came from hdm dataset because we only want to 
#compare plot trees here
s_reg <- t_reg %>% filter(ex_ht_t == "N") %>%
  group_by(orig_id, dataset) %>% summarise(
  n_stem_ha = sum(PHF_TREE),
  ba_m2_hw = sum(ba_m2[spp == "HW"]*PHF_TREE[spp == "HW"]),
  mean_dbh = mean(dbh),
  median_dbh = median(dbh),
  q25_dbh = quantile(dbh, probs = .25),
  q75_dbh = quantile(dbh, probs = .75),
  max_dbh = max(dbh),
  mean_hw_dbh = mean(dbh[spp == "HW"]),
  median_hw_dbh = median(dbh[spp == "HW"]),
  q25_hw_dbh = quantile(dbh[spp == "HW"], probs = .25),
  q75_hw_dbh = quantile(dbh[spp == "HW"], probs = .75),
  max_hw_dbh = max(dbh[spp == "HW"]),
  mean_cd_hw_dbh = mean(dbh[spp == "HW" & 
                              crown_class %in% c("C", "D")])
  )

#Add height metrics. 
#These were calculated separately above. There are three sets of
#height measurements:
#(1) hdm codominant and dominant tree heights; these were taken for most sites 
#and when absent, the projected height from vri is used
#(2) psp codominant and dominant tree heights
#(3) psp top tree heights; there appears to be a systematic overestimation 
#in our height measurements, hoping these might be closer to ours
#Because of the apparent bias in our data, its unclear whether (1) and (2) are
#equivalent or whether (1) and (3) are equivalent. Will test both combinations
#below

#(1) + (2)
ht_hdm_reg <- ht_hdm_reg %>% rename(orig_id = site_id)
ht_cd_psp_reg <- ht_cd_psp_reg %>% rename(orig_id = CLSTR_ID)
#Bind these together. Treating them as an equivalent variable
ht_cd_reg <- rbind(ht_hdm_reg, ht_cd_psp_reg)
#Join them to the site level dataframe
s_reg <- left_join(s_reg, ht_cd_reg, by = "orig_id")
#Calculate the ht:dbh ratio of the cd hw trees
#Note this is done here and not earlier because of the hdm sites without
#heights made it complicated to do before
s_reg <- s_reg %>% mutate(r_cd_hw_htdbh = mean_cd_hw_ht/mean_cd_hw_dbh)

#(1) and (3) 
#Rename all hdm variables to align with top height variables
ht_th_hdm_reg <- ht_hdm_reg %>% 
  rename(mean_th_hw_ht = mean_cd_hw_ht,
         median_th_hw_ht = median_cd_hw_ht,
         sd_th_hw_ht = sd_cd_hw_ht)
ht_th_hdm_reg <- ht_th_hdm_reg %>% 
  left_join(select(s_reg, orig_id, r_cd_hw_htdbh), by="orig_id") %>%
  rename(r_th_hw_htdbh = r_cd_hw_htdbh)
ht_th_psp_reg <- ht_th_psp_reg %>% rename(orig_id = CLSTR_ID)
#Align psp top height dataset with hdm dataset
ht_th_psp_reg <- ht_th_psp_reg %>% 
  select(-(mean_th_hw_dbh))
#Check they are identical
identical(names(ht_th_psp_reg), names(ht_th_psp_reg))
#Bind them together. Treating them as an equivalent variable
ht_th_reg <- rbind(ht_th_hdm_reg, ht_th_psp_reg)
#Join them to the site level dataframe
s_reg <- left_join(s_reg, ht_th_reg, by = "orig_id")

#Add two more variables: site index AND age of codominant/dominant hw
#For hdm regen sites, age values are derived from year harvested in site 
#dataframe and site index is from vri dataset
#For psp sites, both are estimated from sample trees. Because not all CLSTR_IDs 
#had sample trees, this data is incomplete (i.e. there is not a sample tree to 
#give a site index and age estimate for every CLSTR_ID)
#Still going to add it to be able to look at it manually for CLSTR_IDs where 
#we do have data and to have the option to filter to only these sites. 
si_age_reg_hdm <- site %>% select(site_id, age) %>% 
  rename(orig_id = site_id)
x <- vri %>% filter(tree_type == "regen") %>% 
  select(site_id, SITE_INDEX) %>% rename(orig_id = site_id)
si_age_reg_hdm <- left_join(si_age_reg_hdm, x, by = "orig_id")

si_age_psp <- si_age_psp %>% rename(orig_id = CLSTR_ID)

si_age_reg <- rbind(si_age_reg_hdm, si_age_psp)

s_reg <- s_reg %>% left_join(si_age_reg, by = "orig_id")

#Add BEC zones to help with visualizations
bec_psp <- v_psp %>% select(SITE_IDENTIFIER, CLSTR_ID) %>% 
  left_join(select(s_psp, SITE_IDENTIFIER, bec), by = "SITE_IDENTIFIER") %>% 
  rename(orig_id = CLSTR_ID) %>% select(-(SITE_IDENTIFIER))
bec_hdm <- site %>% select(site_id, bec) %>% rename(orig_id = site_id)
bec <- rbind(bec_hdm, bec_psp)

s_reg <- s_reg %>% left_join(bec, by = "orig_id")

#Sort so that hdm datasets appear first and then by orig_id because that is
#the order used in other scripts
s_reg <- s_reg %>% arrange(dataset, orig_id)

#DONE FOR NOW
##################






# #For hdm mature sites, both are in vri
# vri_si_age_mat <- vri %>% filter(tree_type == "mature") %>% 
#   select(site_id, age_vri, SITE_INDEX) %>% rename(age = age_vri)
# hdm_mat_dbh_stat <- left_join(hdm_mat_dbh_stat, vri_si_age_mat,
#                           by = "site_id")
# 
# 
# #Now do a coarse filter based on DBH to remove psp sites that have no 
# #chance of acting as a pair. We want to remove sites with big trees from
# #comparisons with regen sites. On the flip side, we only want to compare
# #mature sites with sites that have big trees. 
# 
# #For regen sites, use the max DBH
# max_dbh_reg <- pca_stat_reg %>% filter(dataset == "hdm") %>% 
#   pull(max_dbh) %>% max
# max_dbh_reg
# #Filter out sites from the pca dataframe where max dbh >20cm larger than the 
# #max dbh of all regen sites
# pca_stat_reg <- pca_stat_reg %>% filter(max_dbh < (max_dbh_reg + 20))
# #leaves this many sites: 
# dim(pca_stat_reg)
# 
# #For mature sites, look at the ranges of a few dbh measures
# pca_stat_mat %>% filter(dataset == "hdm") %>% 
#   select(mean_dbh, median_dbh, max_dbh) %>% summary()
# #Filter out sites from pca dataframe where max dbh <60cm
# pca_stat_mat <- pca_stat_mat %>% filter(max_dbh>60)
# #leaves this many sites: 
# dim(pca_stat_mat)
# 
# #These are the final dataframes (pca_stat_reg) and (pca_stat_mat) that will
# #feed into the PCAs to identify candidate sites
# 
# #Update the psp datasets:
# t_psp_reg <- t_psp_reg %>% 
#   semi_join(pca_stat_reg, by = join_by(CLSTR_ID == orig_id))
# t_psp_mat <- t_psp_mat %>% 
#   semi_join(pca_stat_mat, by = join_by(CLSTR_ID == orig_id))
```

#Align regen sites, approach 1
```{r}
#########################################
####For first alignment use four variables:
#stem density (#stems/ha)
#top height (mean height of codominant/dominant hemlock trees)
#top height tree ht:dbh ratio (mean heght of c/d hw divided by mean dbh of those trees)
#median dbh of hw trees

#Create a subdataframe to reference and make the code chunks below independent of this one. 
s_reg_a1 <- s_reg

#Filter to remove any observations with NA vlaues in the variables we are
#aligning with
s_reg_a1 <- s_reg_a1 %>% 
  filter_at(vars(n_stem_ha, mean_cd_hw_ht, r_cd_hw_htdbh, median_dbh),
            all_vars(!is.na(.)))

#Graph the variables in relation to eachother. 4 vars, 6 graphs
clrs <- c("chocolate1", "grey")
p1 <- ggplot(s_reg_a1 %>% arrange(desc(dataset)), 
             aes(x = n_stem_ha, y = mean_cd_hw_ht, colour = dataset)) + 
  geom_point() + scale_color_manual(values = clrs)
p2 <- ggplot(s_reg_a1 %>% arrange(desc(dataset)), 
             aes(x=n_stem_ha, y = r_cd_hw_htdbh, colour = dataset)) + 
  geom_point() + scale_color_manual(values = clrs)
p3 <- ggplot(s_reg_a1 %>% arrange(desc(dataset)), 
             aes(x = n_stem_ha, y = median_hw_dbh, colour = dataset)) + 
  geom_point() + scale_color_manual(values = clrs)
p4 <- ggplot(s_reg_a1 %>% arrange(desc(dataset)), 
             aes(x = mean_cd_hw_ht, y = r_cd_hw_htdbh, colour = dataset)) + 
  geom_point() + scale_color_manual(values = clrs)
p5 <- ggplot(s_reg_a1 %>% arrange(desc(dataset)), 
             aes(x = mean_cd_hw_ht, y = median_hw_dbh, colour = dataset)) + 
  geom_point() + scale_color_manual(values = clrs)
p6 <- ggplot(s_reg_a1 %>% arrange(desc(dataset)), 
             aes(x = r_cd_hw_htdbh, y = median_hw_dbh, colour = dataset)) + 
  geom_point() + scale_color_manual(values = clrs)
ggarrange(p1, p2, p3, p4, p5, p6, common.legend = TRUE)

#Looks like we can get rid of a whole bunch of psp sites here. 
#psp sites with top height > 30m aren't going to be good pairs. Remove these. 
s_reg_a1 <- s_reg_a1 %>% filter(mean_cd_hw_ht < 30)

#Plot again
#Graph these in relation to eachother
clrs <- c("chocolate1", "grey")
p1 <- ggplot(s_reg_a1 %>% arrange(desc(dataset)), 
             aes(x = n_stem_ha, y = mean_cd_hw_ht, colour = dataset)) + 
  geom_point() + scale_color_manual(values = clrs)
p2 <- ggplot(s_reg_a1 %>% arrange(desc(dataset)), 
             aes(x=n_stem_ha, y = r_cd_hw_htdbh, colour = dataset)) + 
  geom_point() + scale_color_manual(values = clrs)
p3 <- ggplot(s_reg_a1 %>% arrange(desc(dataset)), 
             aes(x = n_stem_ha, y = median_hw_dbh, colour = dataset)) + 
  geom_point() + scale_color_manual(values = clrs)
p4 <- ggplot(s_reg_a1 %>% arrange(desc(dataset)), 
             aes(x = mean_cd_hw_ht, y = r_cd_hw_htdbh, colour = dataset)) + 
  geom_point() + scale_color_manual(values = clrs)
p5 <- ggplot(s_reg_a1 %>% arrange(desc(dataset)), 
             aes(x = mean_cd_hw_ht, y = median_hw_dbh, colour = dataset)) + 
  geom_point() + scale_color_manual(values = clrs)
p6 <- ggplot(s_reg_a1 %>% arrange(desc(dataset)), 
             aes(x = r_cd_hw_htdbh, y = median_hw_dbh, colour = dataset)) + 
  geom_point() + scale_color_manual(values = clrs)
ggarrange(p1, p2, p3, p4, p5, p6, common.legend = TRUE)

###Observations###
#The ht:dbh ratio in hdm sites is generally higher than psp sites for the top
#height ratio in our sites. 
#Generally, we seem to systematically have larger ht measurements for a given 
#dbh

######
#Calculate scaled Euclidean distance between each pair of these sites based
#on these four variables
#Subset dataframe to the four variables
s_reg_a1_n <- s_reg_a1 %>% as_data_frame() %>% 
  select(n_stem_ha, mean_cd_hw_ht, r_cd_hw_htdbh, median_dbh)
#Calculate distance matrix
dist_a1 <- dist(scale(s_reg_a1_n))
dist_a1 <- as.matrix(dist_a1) %>% as_data_frame()
colnames(dist_a1) <- s_reg$orig_id
dist_a1 <- dist_a1 %>% 
  mutate(orig_id = s_reg_a1$orig_id,
         dataset = s_reg_a1$dataset) %>% 
  relocate(orig_id, dataset)

#Each hdm site is represented by one column
#Select 5 psp plots most similar (smallest dissimilarity/distance values) for
#each hdm sites
#Create a dataframe that has the dissimilarity values for each of the five 
#closest sites. Use this as a proxy of how well each site is represented by
#psp sites relative to other hdm sites. 
#Save the ids of the focal hdm site and the psp sites in a vector, then store
#those vector as a list. It will be a list of lists. 
hdm_ids <- site %>% arrange(site_id) %>% pull(site_id)
results <- list()
cand_ids_a1 <- list()

for (i in hdm_ids) {
#Subset dataframe to id column, dataset column and the column with distance
#values to the hdm focal site (i)
d1 <- dist_a1 %>% select(orig_id, dataset, !!i) %>% 
  filter(dataset == "psp" | (dataset == "hdm" & orig_id == i))

#Sort the dataframe by distance to the focal hdm site
d1 <- arrange(d1, !!sym(i))

#Save the ids of the hdm site and the closest psp sites in a vector
ids <- d1 %>% slice(1:6) %>% pull(orig_id)

#Pull out the distance values of the 5 closest psp sites
d2 <- d1 %>% slice(2:6)

#Rename column to identify that it is a distance measure and add a column 
#to identify the focal site being compared
d2 <- d2 %>% rename(dist_eu = !!i) %>% mutate(focal_hdm = i)

#Save the final results to the list objects created above 
results[[i]] <- d2
cand_ids_a1[[i]] <- ids
}

#Bind the distance values for the candidate psp matches for each hdm site into
#a single dataframe
dist_cand_a1 <- bind_rows(results)
#Find mean distance
dist_cand_a1_sum <- dist_cand_a1 %>% group_by(focal_hdm) %>% 
  summarise(mean_eu_dist = mean(dist_eu))
#Inspect it. Sites with a high distance value, don't have a good psp match
#(At least across these variables)
print(arrange(dist_cand_a1_sum, mean_eu_dist))

#Join this back to the site level dataframe
s_reg_a1 <- left_join(s_reg_a1, dist_cand_a1_sum, 
                      by = join_by("orig_id" == "focal_hdm"))

#Plot again but this time colouring by average distance and adding labels
#Create label column that just includes hdm sites
s_reg_a1 <- s_reg_a1 %>% 
  mutate(lab_hdm = if_else(dataset == "hdm", orig_id, NA))
p1 <- ggplot(s_reg_a1, 
             aes(x = n_stem_ha, y = mean_cd_hw_ht, colour = mean_eu_dist)) +
  geom_point() + 
  geom_text(aes(label = lab_hdm), color = "deepskyblue") + 
  scale_color_viridis()
p2 <- ggplot(s_reg_a1, 
             aes(x=n_stem_ha, y = r_cd_hw_htdbh, colour = mean_eu_dist)) + 
  geom_point() + 
  geom_text(aes(label = lab_hdm), color = "deepskyblue") + 
  scale_color_viridis()
p3 <- ggplot(s_reg_a1, 
             aes(x = n_stem_ha, y = median_hw_dbh, colour = mean_eu_dist)) + 
  geom_point() + 
  geom_text(aes(label = lab_hdm), color = "deepskyblue") + 
  scale_color_viridis()
p4 <- ggplot(s_reg_a1, 
             aes(x = mean_cd_hw_ht, y = r_cd_hw_htdbh, colour = mean_eu_dist)) + 
  geom_point() + 
  geom_text(aes(label = lab_hdm), color = "deepskyblue") + 
  scale_color_viridis()
p5 <- ggplot(s_reg_a1, 
             aes(x = mean_cd_hw_ht, y = median_hw_dbh, colour = mean_eu_dist)) + 
  geom_point() + 
  geom_text(aes(label = lab_hdm), color = "deepskyblue") + 
  scale_color_viridis()
p6 <- ggplot(s_reg_a1, 
             aes(x = r_cd_hw_htdbh, y = median_hw_dbh, colour = mean_eu_dist)) + 
  geom_point() + 
  geom_text(aes(label = lab_hdm), color = "deepskyblue") + 
  scale_color_viridis()
ggarrange(p1, p2, p3, p4, p5, p6, common.legend = TRUE)

#########################################
####Select candidates for each hdm site component
#Do this by comparing diameter distributions and the site level summary metrics

#Ids of the each hdm site and its candidate sites are stored as vectors in: 
cand_ids_a1

#Plot of diameter distribution
ids <- cand_ids_a1[[11]]
dbh_dist <- t_reg_dbh_bin %>% filter(orig_id %in% ids)
ggplot(dbh_dist,
       aes(x=dbh_bin, y=n_trees_ha, fill = hw)) + 
  geom_bar(position = "stack", stat = "identity") + 
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5)) +
  facet_wrap(~orig_id)

#Compare site level characteristics of these
#ids
ids
#Bec, site age (if avaialble)
s_reg_a1 %>% filter(orig_id %in% ids) %>% 
  select(orig_id, bec, age)
#Stem density, basal area of hw
s_reg_a1 %>% filter(orig_id %in% ids) %>% 
  select(orig_id, n_stem_ha, ba_m2_hw)
#codominant/dominant Hw height and dbh
s_reg_a1 %>% filter(orig_id %in% ids)%>% 
  select(orig_id, mean_cd_hw_dbh, mean_cd_hw_ht:sd_cd_hw_ht)
#codominant/dominant hw height:dbh ratio
s_reg_a1 %>% filter(orig_id %in% ids)%>% select(orig_id, r_cd_hw_htdbh)
```

#Align regen sites, approach 2
```{r}
#Use two variables:
#top height estimated from top trees and leading species trees in psp database
#stem density (# trees/ha)

#Subset dataframe to the two variables + ids
s_reg_a2 <- s_reg %>% as_data_frame() %>% 
  select(orig_id, dataset, n_stem_ha, mean_th_hw_ht) %>%
    filter_at(vars(n_stem_ha, mean_th_hw_ht),
            all_vars(!is.na(.)))

#Graph two variables against eachother
clrs <- c("chocolate1", "grey")
ggplot(s_reg_a2 %>% arrange(desc(dataset)), 
             aes(x = n_stem_ha, y = mean_th_hw_ht, colour = dataset)) + 
  geom_point() + scale_color_manual(values = clrs)

###Observations###
#Not too promising. Not many psp plots with small top trees. There jsut isn't
#much of a sample to work with here. Good news for mature plots. 

#Can get rid of a whole bunch of psp sites here. 
#psp sites with top height > 30m aren't going to be good pairs. Remove these. 
s_reg_a2 <- s_reg_a2 %>% filter(mean_th_hw_ht < 30)

######
#Calculate scaled Euclidean distance between each pair of these sites based
#on these two variables)

#Subset dataframe again to one with just the numerics to feed into 
#distance function
s_reg_a2_n <- s_reg_a2 %>%  
  select(n_stem_ha, mean_th_hw_ht)

#Calculate distance matrix
dist_a2 <- dist(scale(s_reg_a2_n))
dist_a2 <- as.matrix(dist_a2) %>% as_data_frame()
colnames(dist_a2) <- s_reg_a2$orig_id
dist_a2 <- dist_a2 %>% 
  mutate(orig_id = s_reg_a2$orig_id,
         dataset = s_reg_a2$dataset) %>% 
  relocate(orig_id, dataset)

#Each hdm site is represented by one column
#Select 5 psp plots most similar (smallest dissimilarity/distance values) for
#each hdm sites
#Create a dataframe that has the dissimilarity values for each of the five 
#closest sites. Use this as a proxy of how well each site is represented by
#psp sites relative to other hdm sites. 
#Save the ids of the focal hdm site and the psp sites in a vector, then store
#those vector as a list. It will be a list of lists. 
hdm_ids <- site %>% arrange(site_id) %>% pull(site_id)
results <- list()
cand_ids_a2 <- list()

for (i in hdm_ids) {
#Subset dataframe to id column, dataset column and the column with distance
#values to the hdm focal site (i)
d1 <- dist_a2 %>% select(orig_id, dataset, !!i) %>% 
  filter(dataset == "psp" | (dataset == "hdm" & orig_id == i))

#Sort the dataframe by distance to the focal hdm site
d1 <- arrange(d1, !!sym(i))

#Save the ids of the hdm site and the closest psp sites in a vector
ids <- d1 %>% slice(1:6) %>% pull(orig_id)

#Pull out the distance values of the 5 closest psp sites
d2 <- d1 %>% slice(2:6)

#Rename column to identify that it is a distance measure and add a column 
#to identify the focal site being compared
d2 <- d2 %>% rename(dist_eu = !!i) %>% mutate(focal_hdm = i)

#Save the final results to the list objects created above 
results[[i]] <- d2
cand_ids_a2[[i]] <- ids
}

#Bind the distance values for the candidate psp matches for each hdm site into
#a single dataframe
dist_cand_a2 <- bind_rows(results)
#Find mean distance
dist_cand_a2_sum <- dist_cand_a2 %>% group_by(focal_hdm) %>% 
  summarise(mean_eu_dist = mean(dist_eu))
#Inspect it. Sites with a high distance value, don't have a good psp match
#(At least across these variables)
print(arrange(dist_cand_a2_sum, mean_eu_dist))

#Join this back to the site level dataframe that has other atrributes
s_reg_a2 <- left_join(s_reg_a2, dist_cand_a2_sum, 
                      by = join_by("orig_id" == "focal_hdm"))

##########################
#Plot again but this time colouring by average distance and adding labels
#Create label column that just includes hdm sites
s_reg_a2 <- s_reg_a2 %>% 
  mutate(lab_hdm = if_else(dataset == "hdm", orig_id, NA))

ggplot(s_reg_a2, aes(x = n_stem_ha, y = mean_th_hw_ht, 
                  colour = mean_eu_dist)) +
  geom_point() + 
  geom_text(aes(label = lab_hdm), color = "deepskyblue") +
  scale_colour_viridis()
###Observations###
#Potential matches with this alignment: cr_2, cr_1, cr_3, mi_1, mk_2

#########################################
####Select candidates for each hdm site component
#Do this by comparing diameter distributions and the site level summary metrics

#Ids of the each hdm site and its candidate sites are stored as vectors in: 
cand_ids_a2

#Plot of diameter distribution
ids <- cand_ids_a2[[1]]
dbh_dist <- t_reg_dbh_bin %>% filter(orig_id %in% ids)
ggplot(dbh_dist,
       aes(x=dbh_bin, y=n_trees_ha, fill = hw)) + 
  geom_bar(position = "stack", stat = "identity") + 
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5)) +
  facet_wrap(~orig_id)

#Compare site level characteristics of these
#ids
ids
#Bec, site age (if avaialble)
s_reg %>% filter(orig_id %in% ids) %>% 
  select(orig_id, bec, age)
#Stem density, basal area of hw
s_reg %>% filter(orig_id %in% ids) %>% 
  select(orig_id, n_stem_ha, ba_m2_hw)
#codominant/dominant Hw height, dbh and ht:dbh ratio
s_reg %>% filter(orig_id %in% ids)%>% 
  select(orig_id, mean_cd_hw_dbh, mean_cd_hw_ht, r_cd_hw_htdbh)
#top height tree heights and ht:dh ratio
s_reg %>% filter(orig_id %in% ids)%>% 
  select(orig_id, mean_th_hw_ht, r_th_hw_htdbh)
```


#Regen PCA
```{r}
#####################
####PART 1: Run the PCA
#Run a pca to explain variation in dbh stats and find similar sites
#Create a dataframe consisting of only the numeric columns to be used in pca
#Remove site index and age
pca_stat_reg_numeric <- pca_stat_reg %>% 
  select(mean_dbh:max_hw_dbh)
#Remove the rest of the columns by selectin only numerics
pca_stat_reg_numeric <- pca_stat_reg_numeric %>% select_if(is.numeric)
#Check for infinite values
sum(is.infinite(as.matrix(pca_stat_reg_numeric)))
#Check for missing values
sum(is.na(as.matrix(pca_stat_reg_numeric)))

#Run the pca
#prcomp() function uses singular value decomposition
#because scale. = TRUE, this is will produce a correlation biplot
pca_reg <- prcomp(pca_stat_reg_numeric, scale. = TRUE)

#Inspect the pca object
pca_reg$sdev #the Eigenvalues (=proportional to the percent of variation explained)
head(pca_reg$x) #the actual scores for each site on the each axis
summary(pca_reg) #summary of the percent of variation explained by each axis

#Create a scree plot = shows how much variation is explained by each axis
scree.data <- tibble(axis = as.integer(1:length(pca_reg$sdev)), 
                     ev = pca_reg$sdev) %>% 
  mutate(var = ev^2) %>% mutate(tot_var = sum(var)) %>% 
  mutate(prop_ex = var/tot_var)
ggplot(scree.data, aes(x= axis, y=prop_ex)) + geom_col() + 
  geom_point(col="lightblue") +
  geom_line(col="lightblue")
#axis one and two explain 86% of the variation cumulatively

#Add the scores back to the initial dataframe
pca_stat_reg <- pca_stat_reg %>% bind_cols(pca_reg$x)

#Plot the first two PCA axes. We will use these axes to select potential pairs of sites
pca_stat_reg <- pca_stat_reg %>% mutate(dataset = as.factor(dataset))
levels(pca_stat_reg$dataset)
colors_r <- c("hdm" = "#FF0000",
            "psp" = "#00FF0070")  # Green with 80% transparency 

ggplot(pca_stat_reg, aes(x=PC1, y=PC2, color = dataset)) + 
  geom_point() + scale_color_manual(values = colors_r)

#Plot a covariance biplot to see which variables are driving each axes
#See Section 12.5 of Zuur et al (2007) for comparison of correlation
#vs distance biplot
ggbiplot(pca_reg, scale = 1, varname.color = "brown", varname.size = 2)
#Axis 1: driven by DBH stats, # of stems/ha
#Axis 2 driven by # stems/ha

######################
####PART 2: Identify candidate sites based on PCA Results
#Add bec zone to the pca_stat dataframes
#Filter visit dataframe to remaining sites
v_psp_reg <- v_psp %>% semi_join(t_psp_reg, by="CLSTR_ID")
#Add bec variable from site level dataset
v_psp_reg <- v_psp_reg %>% 
  left_join(select(s_psp, SITE_IDENTIFIER, bec), by="SITE_IDENTIFIER")
#Create a dataframe that has bec info for both psp and hdm sites
v_psp_reg_bec <- v_psp_reg %>% select(CLSTR_ID, bec) %>% 
  rename(orig_id = CLSTR_ID)
site_reg_bec <- site %>% select(site_id, bec) %>% 
  rename(orig_id = site_id)
reg_bec <- rbind(v_psp_reg_bec, site_reg_bec)
#Join this to the pca.stat dataframe
pca_stat_reg <- left_join(pca_stat_reg, reg_bec, by = "orig_id")

#Plot the PCA plot again, this time coloured by bec
pca_stat_reg <- pca_stat_reg %>% 
  mutate(site_id_lab = if_else(dataset == "hdm", orig_id, NA))
ggplot(pca_stat_reg, aes(x=PC1, y=PC2, shape = dataset, 
                         color = bec, label = site_id_lab)) + 
  geom_point() + geom_text()
#Sites without any close reference psp plots:
#CWHdm- sites (mk_1, mk_3, mi_1, mi_2), cluster in bottom left
#CWHvm2 site (mk_2)

############ Loops to identify paired hdm-psp sites ###########
#With help from ChatGPT

#Add weighting variaable for first two axes = percent of variation explained
pca_stat_reg <- pca_stat_reg %>% mutate(PC1_wt = scree.data$prop_ex[1],
                                PC2_wt = scree.data$prop_ex[2])

#Save the column of ids of hdm sites
hdm_r_ids <- pca_stat_reg %>% 
  filter(dataset == "hdm") %>% 
  pull(orig_id)

#Create an empty list to store results
results <- list()

####Loop 1: hdm-psp pairs within bec zones
for (i in hdm_r_ids) {
#Create a new variable for each hdm site component that calculates the
#difference in PCA axis scores between it and the psp sites. 
#Weight each PCA axis by the amount of variation it explains. 
pca_stat_reg <- pca_stat_reg %>% 
  mutate(!!i := abs(PC1 - PC1[orig_id == i])*PC1_wt + 
           abs(PC2 - PC2[orig_id == i])*PC2_wt)

#Create an object that is just the hdm site in question
hdm_site <- pca_stat_reg %>% 
  filter(orig_id == i) %>% mutate(restr ="hdm_site")

#Create a sub dataframe that contains  the three psp sites that are:
#have a mean hw ht within 2m
#have a stem density within 250 stems
#and have the closest PCA scores
cand_1 <- pca_stat_reg %>% 
  filter(((mean_cd_hw_ht <= mean_cd_hw_ht[orig_id == i] + 3) &
              (mean_cd_hw_ht >= mean_cd_hw_ht[orig_id == i] - 3)) &
           ((n_stem_ha <= n_stem_ha[orig_id == i] + 300) &
              (n_stem_ha >= n_stem_ha[orig_id == i] - 300))) %>% 
  arrange(!!sym(i)) %>% 
  filter(dataset =="psp") %>% 
  slice(1:3) %>% 
  mutate(restr ="ht_den")

#Store each sub dataframe in list. Name each dataframe with the target hdm site
#ID
results[[i]] <- rbind(hdm_site, cand_1)
}

#Combine the output into a single dataframe
reg_candidates <- bind_rows(results, .id = "hdm_site")

#Get a sense of the range of PCA score differences - a first indicator of 
#whether hdm sites are equally or unequally well matched with psp sites
reg_candidates <- reg_candidates %>% 
  pivot_longer(cols = all_of(hdm_r_ids), names_to = "sim_site", 
               values_to = "pca_diff") %>% 
  filter(hdm_site == sim_site)
summary(reg_candidates$pca_diff)

#Look at PCA differences for psp pairs restricted to being in the same
#bec zone
ggplot(filter(reg_candidates, restr == "w_bec"), 
       aes(x=bec, y=pca_diff, colour = bec)) + 
  geom_point()
#Sites in the CWHdm- have disproportionately higher values. These are the sites
#where we might have to relax bec restriction

#Create a single dataset of tree level data from hdm and psp datasets
#Variables that should be present: orig_id (site_id or CLSTR_id), species,
#PHF_TREE, dbh, dbh_bin, height, height source (from psps data), crown_class

#Start with hdm data
#Select variables
#Going to add extra height trees; add a variable to identify these
#Also add a varaible to identify this as from the hdm dataset
t_hdm_reg_int <- t_hdm_reg %>% 
  mutate(spp = str_to_upper(spp), 
         ex_ht_t = "N",
         dataset = "hdm",
         HEIGHT_SOURCE = if_else(is.na(ht_corr),NA, "Field measured")) %>% 
  rename(orig_id = site_id)%>% 
  select(orig_id, dataset, spp, PHF_TREE, dbh, dbh_bin, ht_corr, HEIGHT_SOURCE, 
         crown_class, ex_ht_t)

#Filter out extra height trees that don't have dbh (because the point is 
#estimating ht-dbh relationships)
#Add variables missing from above then select
ht_hdm_extra_int <- ht_hdm_extra %>% filter(!is.na(dbh)) %>% 
  rename(orig_id = site_id) %>% 
  mutate(spp = str_to_upper(spp),
         dbh_bin = cut(dbh, breaks = c(4, 10, 15, 20, 25, 30, 35, 40, 45,
                                       50, 55, 60, 65, 70, 75, 80,
                                       85, 90, 95, 100, 105, 110, 115, 120,
                                       125, 130, 135, 140, 145, 150, 155, 
                                       160, 165, 170, 175, 180, 185, 190, 
                                       195, 200, 500), 
                                        include.lowest = TRUE),
         ex_ht_t = "Y",
         dataset = "hdm",
         PHF_TREE = NA,
         HEIGHT_SOURCE = "Field measured") %>% 
  select(orig_id, dataset, spp, PHF_TREE, dbh, dbh_bin, ht_corr, HEIGHT_SOURCE,
         crown_class, ex_ht_t)
#Bind extra height tree observations to rest of hdm tree level data
identical(names(t_hdm_reg_int), names(ht_hdm_extra_int))
t_hdm_reg_int <- rbind(t_hdm_reg_int, ht_hdm_extra_int)

#Now format tree level psp data
t_psp_reg_int <- t_psp_reg %>% 
  rename(orig_id = CLSTR_ID, dbh = DBH, spp = SPECIES, ht_corr = HEIGHT, 
         crown_class = CR_CL) %>% 
  mutate(ex_ht_t = "N",
         dataset = "psp") %>% 
  select(orig_id, dataset, spp, PHF_TREE, dbh, dbh_bin, ht_corr, HEIGHT_SOURCE,
         crown_class, ex_ht_t)

#Bind the datasets
identical(names(t_hdm_reg_int), names(t_psp_reg_int))
t_reg <- rbind(t_hdm_reg_int, t_psp_reg_int)

#Create a binary variable for whether a tree is a Hw
t_reg <- t_reg %>% 
  mutate(hw = if_else(spp == "HW", "HW", "non-HW"))

#Add bec zone and then create a faceting variable that combines orig_id and bec 
#to have at the head of each plot 
t_reg <- left_join(t_reg, reg_bec, 
                     by = "orig_id")
t_reg <- t_reg %>% 
  unite(col = id_bec, sep = ";", c("orig_id", "bec"), remove = FALSE)

#Create a subdataframe for modeling later that just contains the Hw trees
t_reg_hw <- t_reg %>% filter(spp == "HW")

#Summarize the number of trees in each dbh bin
#Filter out the extra ht trees because they shouldn't be considered here
t_reg_dbh_bin <- t_reg %>% filter(ex_ht_t == "N") %>% 
  group_by(orig_id, id_bec, hw, dbh_bin) %>% 
  summarise(n_trees_ha = sum(PHF_TREE))

#Plot the size class distributions of candidate sites and their matched
#hdm site. 
#To look at the candidate sites for a given hdm site, subset the size class 
#dataframe (dbh_reg_bin) by the ids in the candidate site dataframe 
#(reg_candidates). The column "hdm_site" identifies the hdm site the candidate 
#psp sites are being compared to. Use this column to pull a vector of IDs,
#then filter dbh_reg_bin by those IDs. To move to next site, just change
#ID of hdm site in first line below. The hdm site IDs are in the vector 
#hdm_r_ids. 
#ASSESSMENT DATE: 15 Aug (old, switched selection criteria in loop)
#cr_1: Good. 1 good and 1 okay psp pair bec, another good in vm1
#cr_2: Okay. 1 good within bec, another okay in vm1. This site thinned, which 
#is likely the cause for differences. 
#cr_3: Okay, 1 or 2 potentials within bec zone. 
#mi_1: Good, two reasonable candidates within bec zone. 
#mi_2: Okay, 1 reasonable bec in vm1 and one in xm2. 
#mk_1: Okay, outside of bec there is 1 reasonable site in xm2 and 1 in vm2
#mk_2: Okay, outside of bec there is 1 reasonable site in xm2 and one in vm1
#mk_3: Okay, outside of bec, there is 1 reasoanble site in vm1 and one in xm2
#ph_1: Good: 1 reasonable site in bec and one in vm2
#ph_2: Okay: 1 reasonable site in bec and one in vm2
#ph_3: Good: A couple pretty good matches in bec
hdm_r_ids
focal_hdm_site <- reg_candidates %>% filter(hdm_site == hdm_r_ids[1])
plot_reg <- t_reg_dbh_bin %>% filter(orig_id %in% focal_hdm_site$orig_id)
plot_reg <- left_join(plot_reg, 
                      select(focal_hdm_site, orig_id, restr),
                      by = "orig_id")
ggplot(plot_reg,
       aes(x=dbh_bin, y=n_trees_ha, fill = hw)) + 
  geom_bar(position = "stack", stat = "identity") + 
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5)) +
  facet_wrap(restr~id_bec)

####################
####Exploratory plots of dbh:ht and stem_ha:ht
#Join some informative plot level variables
t_reg <- left_join(t_reg, 
                   select(pca_stat_reg, orig_id, n_stem_ha, ba_m2_hw,
                          age, SITE_INDEX, mean_cd_hw_ht), by = "orig_id")

#Calculate ht:dbh ratio
t_reg <- t_reg %>% mutate(ht_dbh = ht_corr/dbh)

#Calculate ht:stem density ratio
t_reg <- t_reg %>% mutate(ht_stemha = ht_corr/n_stem_ha)

#Graph this. Filtered to only trees with a field measured height. 
g <- t_reg %>% filter(HEIGHT_SOURCE == "Field measured")
ggplot(g, aes(x = dataset, y = ht_dbh, colour = n_stem_ha)) + geom_jitter()
ggplot(g, aes(x = dataset, y = ht_dbh, colour = mean_cd_hw_ht)) + geom_jitter()

#Graph 2: top ht vs stem_ha
ggplot(pca_stat_reg, aes(x = n_stem_ha, y = mean_cd_hw_ht, 
                         colour = dataset)) + 
  geom_point() + geom_text(aes(label = orig_id))

```

```{r}
#Calculate chord distances 
c1 <- pca_stat_reg %>% select(n_stem_ha, mean_cd_hw_ht)
c1 <- decostand(c1, method = "norm")
chord_dist <- as.matrix(dist(c1))

?dist

?decostand()
```



#cr_1 regen height curves
```{r}
####################
####################
####Compare these sites in more detail
#Best three psp plots for cr_1 regen: "4001802-PSP4", "4001712-PSP2", 
#"4002547-PSP1"
reg_candidates %>% filter(hdm_site =="cr_1") %>% pull(orig_id)
s_cr1r <- reg_candidates %>% 
  filter(hdm_site == "cr_1" & 
           (orig_id %in% c("cr_1", "4001802-PSP4", 
                           "4001712-PSP2", "4002547-PSP1")))

#Compare site level characteristics of these
#Stem density, basal area of hw
s_cr1r %>% select(orig_id, n_stem_ha, ba_m2_hw)
#All species dbh
s_cr1r %>% select(orig_id, mean_dbh:max_dbh)
#Hw dbh
s_cr1r %>% select(orig_id, mean_hw_dbh:max_hw_dbh)
#codominant/dominant Hw height
s_cr1r %>% select(orig_id, mean_cd_hw_ht:sd_cd_hw_ht)
#Report: Not bad. psp trees generally bigger but have smaller hieghts. Not 
#sure what that is about. 

#See how many field measured heights these psp sites have
#Filter tree level hdm+psp regen dataset to cr_1 and candidates
t_cr1r <- t_reg_hw %>% 
  filter(orig_id %in% c("cr_1", "4001802-PSP4", "4001712-PSP2", "4002547-PSP1"))

#See how many hw trees these sites have that
#have field measured heights
#have crown class info
t_cr1r %>% group_by(orig_id) %>% 
  summarise(n_hw = n(),
            n_fm_ht = sum(HEIGHT_SOURCE == "Field measured", na.rm=T), 
            n_cr_cl = sum(!is.na(crown_class)))

#Create a dataset for modelling by restriction to only those with field
#measured heights. 
t_cr1r_mod <- t_cr1r %>% filter(HEIGHT_SOURCE == "Field measured")

#Leaves us with this many heights
dim(t_cr1r_mod)
#Look at how many trees by crown class
#Suppressed trees not represented, unfortunate
t_cr1r_mod %>% group_by(crown_class) %>% 
  summarise(n_trees = n())

#Graph raw dbh-height plot
#Clear site effect
ggplot(t_cr1r_mod, aes(x=dbh, y=ht_corr, colour = orig_id)) + 
  geom_point()

#What is the range of dbh covered here? 
range(t_cr1r_mod$dbh)

####################
####################
####Fit dbh height curves with the MÃ¸nness equation
#For sites with a sample of measured co dominant heights, fit a multiple 
#linear regression model with site as a predictor. 
#For sites without, fit simple linear regression (i.e. ignore the site effect)

#Equation can be rearranged to be linear. To do this calculate transformed 
#height (response) and predictor (1/DBH).
t_cr1r_mod <- t_cr1r_mod %>% 
  mutate(ht_tran = (ht_corr - 1.3)^(-1/3),
         dbh_inv = 1/dbh)

#Plot the linear model
ggplot(t_cr1r_mod, aes(x=dbh_inv, y=ht_tran)) + 
  geom_point() + geom_smooth(method = "lm", se=F) +
  labs(x= "1/dbh", y="(ht-1.3)^-1/3")

#Model 1: lm with just dbh as predictor
m1_cr1r <- lm(ht_tran ~ dbh_inv, data = t_cr1r_mod)
summary(m1_cr1r)

#Add predicted values and residuals to dataframe
t_cr1r_mod$m1_yhat <- fitted(m1_cr1r)
t_cr1r_mod$m1_resid <- residuals(m1_cr1r)

#Get diagnostic plots for the OLS Model
par(mfrow=c(2,2),mai=c(0.6,0.6,0.6,0.6),cex=0.55)
plot(t_cr1r_mod$m1_yhat, t_cr1r_mod$m1_resid, main="OLS Model, Residual Plot",
     xlab="yhat", ylab="residual")
abline(h=0, col="red")
plot(t_cr1r_mod$ht_tran, t_cr1r_mod$m1_yhat, main="OLS Model, Fitted Line Plot",
     ylab="yhat", xlab="transformed ht")
abline(a=0, b=1)
qqnorm(t_cr1r_mod$m1_resid, main="OLS Model, Normality Plot")
qqline(t_cr1r_mod$m1_resid, col="red")
hist(t_cr1r_mod$m1_resid, breaks =8 , density=10,col="green", border="black",
     main="OLS Model, Error Distribution") 
par(mfrow=c(1,1),mai=c(1.0,1.0,1.0,1.0),cex=1.0)

#Model 2: lm with dbh + site as predictors
#Make orig_id a factor
t_cr1r_mod <- t_cr1r_mod %>% mutate(orig_id = as.factor(orig_id))
m2_cr1r <- lm(ht_tran ~ dbh_inv + orig_id, data = t_cr1r_mod)
summary(m2_cr1r)
 
#Add predicted values and residuals to dataframe
t_cr1r_mod$m2_yhat <- fitted(m2_cr1r)
t_cr1r_mod$m2_resid <- residuals(m2_cr1r)

#Get diagnostic plots for the OLS Model
#Problems: normality slightly right skewed
par(mfrow=c(2,2),mai=c(0.6,0.6,0.6,0.6),cex=0.55)
plot(t_cr1r_mod$m2_yhat, t_cr1r_mod$m2_resid, main="OLS Model, Residual Plot",
     xlab="yhat", ylab="residual")
abline(h=0, col="red")
plot(t_cr1r_mod$ht_tran, t_cr1r_mod$m2_yhat, main="OLS Model, Fitted Line Plot",
     ylab="yhat", xlab="transformed ht")
abline(a=0, b=1)
qqnorm(t_cr1r_mod$m2_resid, main="OLS Model, Normality Plot")
qqline(t_cr1r_mod$m2_resid, col="red")
hist(t_cr1r_mod$m2_resid, breaks =8 , density=10,col="green", border="black",
     main="OLS Model, Error Distribution") 
par(mfrow=c(1,1),mai=c(1.0,1.0,1.0,1.0),cex=1.0)

#Is the random site effect significant? 
anova(m1_cr1r, m2_cr1r)

#Compare R2s of the two models. Model 2 much much better
summary(m1_cr1r); summary(m2_cr1r); 

#Now use this equation to predict ht for all trees in this set 
#of sites (an hdm site and three psp sites)
#First calculate the transformed variables
t_cr1r <- t_cr1r %>% 
  mutate(ht_tran = (ht_corr - 1.3)^(-1/3),
         dbh_inv = 1/dbh)
#Then use predict function to estimate transformed ht
t_cr1r <- t_cr1r %>% 
  mutate(pred_ht_tran = predict(m2_cr1r, newdata = t_cr1r))
#THen backtransform to get height in units of m
t_cr1r <- t_cr1r %>% mutate(pred_ht = (1/pred_ht_tran^3) + 1.3)

#Do this manually also to check
coef <- m2_cr1r$coefficients
levels(t_cr1r_mod$orig_id)
t_cr1r <- t_cr1r %>% 
  mutate(man_ht_tran = case_when(orig_id == "4001712-PSP2" ~ 
                                   coef[1] + dbh_inv*coef[2],
                                 orig_id == "4001802-PSP4" ~ 
                                   coef[1] + dbh_inv*coef[2] + coef[3],
                                 orig_id == "4002547-PSP1" ~ 
                                   coef[1] + dbh_inv*coef[2] + coef[4],
                                 orig_id == "cr_1" ~ 
                                   coef[1] + dbh_inv*coef[2] + coef[5]))
#Calculate the bias (pred - observed)
#Then graph it. Seems as if there is an issue of overprediction
t_cr1r <- t_cr1r %>% mutate(bias = pred_ht_tran - ht_tran)
ggplot(t_cr1r, aes(x=dbh, y=bias, colour = orig_id, shape = HEIGHT_SOURCE)) + 
  geom_point() + 
  facet_wrap(~dataset)
ggplot(t_cr1r, aes(x=ht_corr, y=pred_ht, colour = dataset)) + geom_point() +
  geom_abline(slope = 1, intercept = 0)

#Compare this against a model that uses trees with estimated heights and 
#includes crown class as a predictor
t_cr1r <- t_cr1r %>% mutate(crown_class = as.factor(crown_class))
levels(t_cr1r$crown_class)
t_cr1r_mod2 <- t_cr1r %>% filter(!is.na(ht_corr),
                                 crown_class %in% c("C", "D", "I", "S")) %>% 
  mutate(crown_class = as.character(crown_class)) %>% 
  mutate(crown_class = as.factor(crown_class))

#Calculate transfromed variables
t_cr1r_mod2 <- t_cr1r_mod2 %>% 
  mutate(ht_tran = (ht_corr - 1.3)^(-1/3),
         dbh_inv = 1/dbh)
t_cr1r_mod <- t_cr1r_mod %>% mutate(orig_id = as.factor(orig_id))

m3_cr1r <- lm(ht_tran ~ dbh_inv + orig_id + crown_class, data = t_cr1r_mod2)
summary(m3_cr1r)
 
#Add predicted values and residuals to dataframe
t_cr1r_mod2$m3_yhat <- fitted(m3_cr1r)
t_cr1r_mod2$m3_resid <- residuals(m3_cr1r)

#Get diagnostic plots for the OLS Model
#Problems: normality slightly right skewed
par(mfrow=c(2,2),mai=c(0.6,0.6,0.6,0.6),cex=0.55)
plot(t_cr1r_mod2$m3_yhat, t_cr1r_mod2$m3_resid, main="OLS Model, Residual Plot",
     xlab="yhat", ylab="residual")
abline(h=0, col="red")
plot(t_cr1r_mod2$ht_tran, t_cr1r_mod2$m3_yhat, main="OLS Model, Fitted Line Plot",
     ylab="yhat", xlab="transformed ht")
abline(a=0, b=1)
qqnorm(t_cr1r_mod2$m3_resid, main="OLS Model, Normality Plot")
qqline(t_cr1r_mod2$m3_resid, col="red")
hist(t_cr1r_mod2$m3_resid, breaks =8 , density=10,col="green", border="black",
     main="OLS Model, Error Distribution") 
par(mfrow=c(1,1),mai=c(1.0,1.0,1.0,1.0),cex=1.0)

#
#Then use predict function to estimate transformed ht
t_cr1r_mod2 <- t_cr1r_mod2 %>% 
  mutate(m3_pred = predict(m3_cr1r, newdata = t_cr1r_mod2))
#Then backtransform to get height in units of m
t_cr1r_mod2 <-  t_cr1r_mod2 %>% mutate(pred_ht = (1/m3_pred^3) + 1.3)

#Calculate the bias (pred - observed)
#Then graph it. Seems as if there is an issue of overprediction
t_cr1r_mod2 <-t_cr1r_mod2 %>% mutate(bias = pred_ht  - ht_corr)
ggplot(t_cr1r_mod2, aes(x=dbh, y=bias, colour = orig_id, shape = HEIGHT_SOURCE)) + 
  geom_point() + 
  facet_wrap(~dataset)
ggplot(t_cr1r_mod2, aes(x=ht_corr, y=pred_ht, colour = dataset)) + geom_point() +
  geom_abline(slope = 1, intercept = 0)
ggplot(t_cr1r_mod2, aes(x=dbh, y=pred_ht, colour = orig_id)) + geom_point()
```

#Mature candidate sites
```{r}
################ PART 1: Run the PCA
#Run a pca to explain variation in dbh stats and find similar sites
#Check for infinite values
sum(is.infinite(as.matrix(pca_stat_mat)))
#Check for missing values
sum(is.na(as.matrix(pca_stat_mat)))
#Remove NA values if there are any
pca_stat_mat <- pca_stat_mat %>% drop_na()
#Select only nuermic columns
pca_stat_mat_numeric <- pca_stat_mat %>% select_if(is.numeric)

#Run the pca
#prcomp() function uses singular value decomposition
#because scale. = TRUE, this is will produce a correlation biplot
pca_mat <- prcomp(pca_stat_mat_numeric, scale. = TRUE)

#Inspect the pca object
pca_mat$sdev #the Eigenvalues (=proportional to the percent of variation explained)
head(pca_mat$x) #the actual scores for each site on the each axis
summary(pca_mat) #summary of the percent of variation explained by each axis

#Create a scree plot = shows how much variation is explained by each axis
scree.data <- tibble(axis = as.integer(1:length(pca_mat$sdev)), 
                     ev = pca_mat$sdev) %>% 
  mutate(var = ev^2) %>% mutate(tot_var = sum(var)) %>% 
  mutate(prop_ex = var/tot_var)
ggplot(scree.data, aes(x= axis, y=prop_ex)) + geom_col() + 
  geom_point(col="lightblue") +
  geom_line(col="lightblue")
#axis one and two explain 74% of the variation cumulatively

#Add the scores back to the initial dataframe
pca_stat_mat <- pca_stat_mat %>% bind_cols(pca_mat$x)

#Plot the first two PCA axes. We will use these axes to select potential pairs of sites
pca_stat_mat <- pca_stat_mat %>% mutate(site_type = as.factor(site_type))
levels(pca_stat_mat$site_type)
colors_r <- c("hdm_m" = "blue",
            "psp_m" = "#00FF0070")  # Green with 80% transparency 

ggplot(pca_stat_mat, aes(x=PC1, y=PC2, color = site_type)) + 
  geom_point() + scale_color_manual(values = colors_r)

#Plot a covariance biplot to see which variables are driving each axes
#See Section 12.5 of Zuur et al (2007) for comparison of correlation
#vs distance biplot
ggbiplot(pca_mat, scale = 1, varname.color = "brown", varname.size = 2)
#Axis 1: driven by DBH stats, # of stems/ha
#Axis 2 driven by basal area of hw, max dbh and standard deviation of 
#codominant, dominant hw height

####################PART 2: Identify candidate sites based on PCA Results
#Add bec zone to the pca_stat dataframe
#Filter visit dataframe to remaining sites
v_psp_mat <- v_psp %>% semi_join(t_psp_mat, by="CLSTR_ID") 
#Add bec variable from site level dataset
v_psp_mat <- v_psp_mat %>% 
  left_join(select(s_psp, SITE_IDENTIFIER, bec), by="SITE_IDENTIFIER")
#Create a dataframe that has bec info for both psp and hdm sites
v_psp_mat_bec <- v_psp_mat %>% select(CLSTR_ID, bec) %>% 
  rename(orig_id = CLSTR_ID)
site_mat_bec <- site %>% select(site_id, bec) %>% 
  rename(orig_id = site_id)
bec_mat <- rbind(v_psp_mat_bec, site_mat_bec)
#Join this to the pca.stat dataframe
pca_stat_mat <- left_join(pca_stat_mat, bec_mat, by = "orig_id")

#Plot the PCA plot again, this time coloured by bec
pca_stat_mat <- pca_stat_mat %>% 
  mutate(site_id_lab = if_else(site_type == "hdm_m", orig_id, NA))
ggplot(pca_stat_mat, aes(x=PC1, y=PC2, shape = site_type, 
                         color = bec, label = site_id_lab)) + 
  geom_point() + geom_text()
#Sites without any close reference psp plots:
#ph_2 (big trees?), ph_3 (rocky bluff?)
#mk_1 (also big trees?)
#mk_2 (not many vm2 sites)

############ Loops to identify paired hdm-psp sites ###########
#With help from ChatGPT

#Add weighting variaable for first two axes = percent of variation explained
pca_stat_mat <- pca_stat_mat %>% mutate(PC1_wt = scree.data$prop_ex[1],
                                PC2_wt = scree.data$prop_ex[2])

#Save the column of ids of hdm sites
hdm_m_ids <- pca_stat_mat %>% 
  filter(site_type == "hdm_m") %>% 
  pull(ID)

#Create an empty list to store results
results <- list()

####Loop 1: hdm-psp pairs within bec zones
for (i in hdm_m_ids) {
#Create a new variable for each hdm site component that calculates the
#difference in PCA axis scores between it and the psp sites. 
#Weight each PCA axis by the amount of variation it explains. 
pca_stat_mat <- pca_stat_mat %>% 
  mutate(!!i := abs(PC1 - PC1[ID == i])*PC1_wt + 
           abs(PC2 - PC2[ID == i])*PC2_wt)

#Create an object that is just the hdm site in question
hdm_site <- pca_stat_mat %>% 
  filter(ID == i) %>% mutate(restr ="hdm_site")

#Create a sub dataframe that contains  the three psp sites that are:
#in the same bec subzone 
#have a greater max hw dbh
#and have the closest PCA scores
cand_1 <- pca_stat_mat %>% 
  filter(bec == bec[ID == i] & max_hw_dbh >= max_hw_dbh[ID == i]) %>% 
  arrange(!!sym(i)) %>% 
  filter(ID == i | site_type =="psp_m") %>% 
  slice(2:4) %>% 
  mutate(restr ="w_bec")

#Create a second sub dataframe with the same criteria but this time relaxing
#the bec requirement
#Filter out psp sites already identified as top candidates from selecting from
#within bec zones
cand_2 <- pca_stat_mat %>% 
  filter(max_hw_dbh >= max_hw_dbh[ID == i]) %>% 
  arrange(!!sym(i)) %>% 
  filter(ID == i | (site_type =="psp_m" & !ID %in% cand_1$ID)) %>% 
  slice(2:4) %>% 
  mutate(restr ="wo_bec")

#Store each sub dataframe in list. Name each dataframe with the target hdm site
#ID
results[[i]] <- rbind(hdm_site, cand_1, cand_2)
}

#Combine the output into a single dataframe
mat_candidates <- bind_rows(results, .id = "hdm_site")

#Get a sense of the range of PCA score differences - a first indicator of 
#whether hdm sites are equally or unequally well matched with psp sites
mat_candidates <- mat_candidates %>% 
  pivot_longer(cols = all_of(hdm_m_ids), names_to = "sim_site", 
               values_to = "pca_diff") %>% 
  filter(hdm_site == sim_site)
summary(mat_candidates$pca_diff)

#Look at PCA differences for psp pairs restricted to being in the same
#bec zone
ggplot(filter(mat_candidates, restr == "w_bec"), 
       aes(x=bec, y=pca_diff, colour = bec)) + 
  geom_point()

#Sites in the CWHdm- have somewhat higher differences. vm2 site (mk_2) has 
#highest differences (maybe just because there isn't many psp sites to 
#compare against?)

#Create a single dataset of tree level dbh data from hdm and psp datasets
#Create ID variable (but also keep IDs from respective dataset)
#Rename variables so they are consistent between datasets
#shared across the datasets
t_hdm_mat <- t_hdm_mat %>% mutate(site_type = "hdm_m") %>% 
  unite(col = ID, sep = "_", c("site_id", "site_type"), remove = FALSE) %>% 
  rename(orig_id = "site_id")
t_psp_mat <- t_psp_mat %>% mutate(site_type = "psp_m") %>% 
  unite(col = ID, sep = "_", c("CLSTR_ID", "site_type"), remove = FALSE) %>% 
  rename(orig_id = CLSTR_ID, dbh = DBH, spp = SPECIES)
#Bind the datasets
dbh_mat <- rbind(select(t_hdm_mat, ID, orig_id, spp, PHF_TREE, dbh, dbh_bin),
                 select(t_psp_mat, ID, orig_id, spp, PHF_TREE, dbh, dbh_bin))

#Create a binary variable for whether a tree is a Hw
dbh_mat <- dbh_mat %>% 
  mutate(hw = if_else(spp %in% c("Hw", "HW"), "Hw", "non-Hw"))

#Add bec zone and then create a faceting variable that combines orig_id and bec 
#to have at the head of each plot 
dbh_mat <- left_join(dbh_mat, select(pca_stat_mat, ID, bec), 
                     by = "ID")
dbh_mat <- dbh_mat %>% 
  unite(col = id_bec, sep = ";", c("orig_id", "bec"), remove = FALSE)

#Summarize the number of trees in each dbh bin
dbh_mat_bin <- dbh_mat %>% group_by(ID, id_bec, hw, dbh_bin) %>% 
  summarise(n_trees_ha = sum(PHF_TREE))

#Plot the size class distributions of candidate sites and their matched
#hdm site. 
#To look the candidate sites for a given hdm site, subset size class 
#dataframe(dbh_reg_bin) by ids in the candidate site dataframe 
#(mat_candidates). The column "hdm_site" identifies the hdm site the candidate 
#psp sites are being compared to. Use this column to pull a vector of IDs,
#then filter dbh_reg_bin by those IDs. To move to next site, just change
#ID of hdm site in first line below. The hdm site IDs are in the vector 
#hdm_r_ids
#cr_1: Okay. One reasonable site in bec. One outside in vm1. 
#cr_2: Good. Two reasonable ons wihtin bec. One good match in vm1. 
#cr_3: Okay. Some okay matches in bec and one good one in vm1.  
#mi_1: Not awesome. Only one candidate within bec zone. Others likely filtered 
#out by criteria requiring max hw dbh being greater than that of hdm site.
#mi_2: Okay. One reasonable site within bec and another in xm2. 
#mk_1: PRetty good. This site has a clear change in timber type in mature 
#component, which makes its dbh distribution hard to match. 
#mk_2: Okay. Site within bec (vm2) not great. cm1 and xm2 site that are 
#reasonable. 
#mk_3: Good, a couple good matches within bec. 
#ph_1: Okay. Sites within bec (vm1) are okay matches but lack continuous 
#coverage in upper dbh classes. 
#ph_2: Okay. No obvious matches but some reasonable matches in and outside
#Of bec. 
#ph_3: Okay. One close-ish site in bec (vm1). WOnder if this is the right bec 
#for this site?
hdm_m_ids
focal_hdm_site <- mat_candidates %>% filter(hdm_site == hdm_m_ids[11])
plot_mat <- dbh_mat_bin %>% filter(ID %in% focal_hdm_site$ID)
plot_mat <- left_join(plot_mat, 
                      select(focal_hdm_site, ID, restr),
                      by = "ID")
ggplot(plot_mat,
       aes(x=dbh_bin, y=n_trees_ha, fill = hw)) + 
  geom_bar(position = "stack", stat = "identity") +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5)) +
  facet_wrap(restr~id_bec)

#Plot dbh-height relationships for psp sites and hdm sites
#Create a single dataset of tree level dbh-ht data from hdm and psp datasets

# #Filter trees dataset to those with height recorded
# ht_hdm <- trees %>% filter(!is.na(ht_corr))
# 
# #Read in dataset with extra heights
# ht_hdm_extra <- read_csv(here("./data/cleaned/regen_extra_ht_c.csv"))
# summary(ht_hdm_extra)
# 
# #Merge the two datasets
# #Create variable in ht_hdm_extra that identifies it as all regen trees
# ht_hdm_extra <- ht_hdm_extra %>% mutate(tree_type = "regen")
# #Only keep variables present in both
# ht_comm_var <- intersect(names(ht_hdm), names(ht_hdm_extra))
# ht_hdm <- ht_hdm %>% select(all_of(ht_comm_var))
# ht_hdm_extra <- ht_hdm_extra %>% select(all_of(ht_comm_var))
# #Bind datasets
# ht_hdm <- rbind(ht_hdm, ht_hdm_extra)
# 
# #Filter out observations with missing dbh and to just regen
# t_ht_hdm_reg <- ht_hdm %>% filter(!is.na(dbh) & tree_type == "regen")
# 
# #Then create an aligned dataset from psp data
# t_ht_cd_psp_reg <- t_psp %>% 
#   filter(SPECIES == "HW" &
#            CR_CL %in% c("C", "D") &
#            HEIGHT_SOURCE == "Field measured")
# 
# t_ht_hdm_reg <- t_ht_hdm_reg %>% 
#   mutate(site_type = "hdm_r") %>% 
#   unite(col = ID, sep = "_", c("site_id", "site_type"), remove = FALSE)
# t_ht_cd_psp_reg <- t_ht_cd_psp_reg %>% mutate(site_type = "psp_r") %>% 
#   unite(col = ID, sep = "_", c("CLSTR_ID", "site_type"), remove = FALSE) %>% 
#   rename(dbh = DBH, ht_corr = HEIGHT)
# 
# #bind the two datasets
# t_ht_reg <- rbind(select(t_ht_hdm_reg, ID, dbh, ht_corr),
#                  select(t_ht_cd_psp_reg, ID, dbh, ht_corr))
# 
# ggplot(filter(t_ht_reg, ID %in% (reg_candidates$ID[13:16])),
#        aes(x=dbh, y=ht_corr, color = ID)) + 
#   geom_point()
```


#Height to live crown
```{r}
#How many trees have height to crown base measurments in the psp plots that
#were potential candidates for the regen sites?
htcb <- t_psp_reg %>% semi_join(reg_candidates, by = "orig_id") %>% 
  filter(!is.na(HT_BRCH))

ggplot(htcb, aes(x=HEIGHT, y=HT_BRCH)) + 
  geom_point(aes(color = CR_CL)) +
  geom_smooth(method = "lm")
```

